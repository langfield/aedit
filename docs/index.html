<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>ki API documentation</title>
<meta name="description" content="Ki is a command-line interface for the version control and editing of `.anki2`
collections as git repositories of markdown files.
Rather than â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:20%;max-height:5em;margin:auto;margin-bottom:.3em}</style>
<link rel="canonical" href="ki/">
<link rel="icon" href="u1F367-shavedice.svg">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>ki</code></h1>
</header>
<section id="section-intro">
<p>Ki is a command-line interface for the version control and editing of <code>.anki2</code>
collections as git repositories of markdown files.
Rather than providing an
interactive UI like the Anki desktop client, ki aims to allow natural editing
<em>in the filesystem</em>.</p>
<p>In general, the purpose of ki is to allow users to work on large, complex Anki
decks in exactly the same way they work on large, complex software projects.</p>
<p>Ki provides command-line functions to:</p>
<ol>
<li><strong>clone</strong> a <code>.anki2</code> collection into a directory as a git repository.</li>
<li><strong>pull</strong> changes from the Anki desktop client (and AnkiWeb) into an existing
repository.</li>
<li><strong>push</strong> changes (safely!) back to Anki.</li>
</ol>
<p>This is documentation for the ki
<a href="https://github.com/langfield/ki">repository</a>. </p>
<h1 id="installation">Installation</h1>
<p>Ki is tested on Python 3.9 and 3.10. You'll need to install Python and Git, and
then run the following command in a terminal:</p>
<ol>
<li>Install the <code><a title="ki" href="#ki">ki</a></code> package:</li>
</ol>
<pre><code class="language-bash">pip install git+https://github.com/langfield/ki.git@main
</code></pre>
<h1 id="getting-started">Getting started</h1>
<p>This section will walk through the following example workflow:</p>
<ol>
<li><a href="#cloning-a-collection"><strong>Cloning</strong></a> an existing collection into a <code><a title="ki" href="#ki">ki</a></code> repository.</li>
<li><a href="#editing-notes"><strong>Editing</strong></a> the note files in the repository.</li>
<li><a href="#pushing-committed-changes"><strong>Pushing</strong></a> those edits back to Anki.</li>
<li><a href="#pulling-changes-from-anki"><strong>Pulling</strong></a> changes made in Anki into the repository.</li>
</ol>
<p>Before cloning, we'll need to find our <code>.anki2</code> collection file.
This is where Anki stores the data for all our notes.</p>
<blockquote>
<p><strong>Note.</strong> If you're new to Anki, or are unfamiliar with the terms <em>collection</em>,
<em>profile</em>, <em>note</em>, or <em>card</em>, you may wish to take a look at the Anki
<a href="https://docs.ankiweb.net/intro.html">documentation</a>.</p>
</blockquote>
<p>If you already know the path to the <code>.anki2</code> collection file you want to clone,
skip to the section on <a href="#running-the-ki-clone-command">running the clone command</a>.</p>
<h3 id="finding-the-anki2-collection-file">Finding the <code>.anki2</code> collection file</h3>
<p>To find our collection file, we must first find our Anki data directory. The
location of this varies by operating system.</p>
<p>In most cases, you should be able to find your data directory at the path given
below for your respective OS:</p>
<h4 id="macos">MacOS</h4>
<pre><code class="language-bash">~/Library/Application Support/Anki2
</code></pre>
<h4 id="windows">Windows</h4>
<pre><code class="language-bash">%APPDATA%\Anki2
</code></pre>
<h4 id="gnulinux">GNU/Linux</h4>
<pre><code class="language-bash">~/.local/share/Anki2
</code></pre>
<blockquote>
<p><strong>Note.</strong> You can read more about the default Anki data directory locations
<a href="https://docs.ankiweb.net/files.html#file-locations">here</a>.</p>
</blockquote>
<hr>
<p>If you are running Anki 2.1 (which you should be, because <code><a title="ki" href="#ki">ki</a></code> is not tested
with lower versions), opening this directory will reveal several files and
subdirectories. The following example output is from a machine running Debian
GNU/Linux:</p>
<pre><code>user@host:~/.local/share/Anki2$ ls
 addons21   crash.log   prefs21.db   README.txt  'User 1'
</code></pre>
<p>In particular, there is a subdirectory for each <strong>profile</strong>. In the above
example, there is only one profile, <code>User 1</code>. But, in general, there may be
many profiles associated with a given Anki installation.</p>
<h4 id="multiple-profiles">Multiple profiles</h4>
<p>Below we can see a visual representation of the directory structure of an
Anki data directory with two profiles, <code>User 1</code>, and <code>User 2</code>:</p>
<pre><code class="language-bash">Anki2/
â”œâ”€â”€ addons21
â”‚Â Â  â”œâ”€â”€ 1046608507
â”‚Â Â  â”œâ”€â”€ 109531687
â”‚Â Â  â”œâ”€â”€ 1097423555
â”‚Â Â  â””â”€â”€ 1972239816
â”œâ”€â”€ crash.log
â”œâ”€â”€ prefs21.db
â”œâ”€â”€ README.txt
â”œâ”€â”€ User 1
â”‚Â Â  â”œâ”€â”€ backups
â”‚Â Â  â”œâ”€â”€ collection2.log
â”‚Â Â  â”œâ”€â”€ collection.anki2
â”‚Â Â  â”œâ”€â”€ collection.log
â”‚Â Â  â”œâ”€â”€ collection.media
â”‚Â Â  â”œâ”€â”€ collection.media.db2
â”‚Â Â  â””â”€â”€ deleted.txt
â””â”€â”€ User 2
    â”œâ”€â”€ collection.anki2
    â”œâ”€â”€ collection.anki2-wal
    â””â”€â”€ collection.media
</code></pre>
<p>Note that there is a <code>collection.anki2</code> file in each profile subdirectory.</p>
<p>If you're not sure of the name of your user profile, it can be seen in the
title bar of the Anki desktop client:</p>
<p align="center">
<img width="460" src="anki.png">
</p>
<p>Most Anki installations will only have one profile, and if you haven't changed
the default profile name, it will probably be called <code>User 1</code>. Let's enter the
profile directory for <code>User 1</code> and list its contents:</p>
<pre><code>user@host:~/.local/share/Anki2$ cd User\ 1/
user@host:~/.local/share/Anki2/User 1$ ls
backups  collection2.log  collection.anki2  collection.log  collection.media  collection.media.db2  deleted.txt
</code></pre>
<p>So if we want to clone <code>User 1</code>'s collection, the path that we want is:</p>
<pre><code>~/.local/share/Anki2/User\ 1/collection.anki2
</code></pre>
<p>We'll pass this as a command-line argument to the <code><a title="ki" href="#ki">ki</a></code> executable in the next
section.</p>
<h3 id="running-the-clone-command">Running the clone command</h3>
<p>Now we're ready to actually clone the collection into a repository. The <code><a title="ki" href="#ki">ki</a> clone</code>
command works similarly to <code>git clone</code>, in that it will create a new directory
for the repository <em>within</em> the current working directory. So if we want to
clone our collection into a new subdirectory in <code>~/</code> (the home directory on
macOS and GNU/Linux), we would first make sure we're in the home directory.
Second, we need to check that <strong>Anki is closed</strong> before cloning. Nothing bad
will happen if we clone while Anki is open, but the command will fail because
the database is locked. Once we've done that, we can run the command:</p>
<pre><code class="language-bash">ki clone ~/.local/share/Anki2/User 1/collection.anki2
</code></pre>
<p>And we should see output that looks similar to this:</p>
<pre><code class="language-bash">lyra@oxford$ ki clone ~/.local/share/Anki2/User 1/collection.anki2
Found .anki2 file at '/home/lyra/.local/share/Anki2/User 1/collection.anki2'
Computed md5sum: ad7ea6d486a327042cf0b09b54626b66
Wrote md5sum to '/home/lyra/collection/.ki/hashes'
Cloning into '/home/lyra/collection/'...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28886/28886 [00:10&lt;00:00, 2883.78it/s]
</code></pre>
<p>If we list the contents of the home directory, we can see that <code><a title="ki" href="#ki">ki</a></code> did
indeed create a new directory called <code>collection</code>:</p>
<pre><code class="language-bash">lyra@oxford:~$ ls
collection  pkgs
</code></pre>
<h2 id="editing-notes">Editing notes</h2>
<p>Now that we've successfully cloned our Anki collection into a <code><a title="ki" href="#ki">ki</a></code> repository,
we can start editing notes! Our home directory looks like this:</p>
<pre><code class="language-bash">lyra@oxford:~$ ls
collection  pkgs
</code></pre>
<p>And we see the repo we cloned, which is called <code>collection</code>.</p>
<p>Let's change directories to the newly cloned <code><a title="ki" href="#ki">ki</a></code> repo and take a look at
what's inside:</p>
<pre><code class="language-bash">lyra@oxford:~$ cd collection/
lyra@oxford:~/collection$ ls --classify
algebras/ manifolds/ rings/
</code></pre>
<p>We see that we have three directories, which represent three Anki decks. This
is just an example; you'll see directories corresponding to the top-level decks
in your Anki collection.</p>
<blockquote>
<p><strong>Note.</strong> The <code>ls --classify</code> command adds a trailing <code>/</code> to the end of
directories to distinguish them from ordinary files.</p>
</blockquote>
<p>Lets enter the <code>manifolds</code> directory and see what's inside.</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ cd manifolds/
lyra@oxford:~/collection/manifolds$ ls
MANIFOLDS.md
</code></pre>
<p>So we see a single markdown file called <code>MANIFOLDS.md</code>, which contains the
notes for the manifolds deck. If we had subdecks of the manifolds deck, we
would see more subdirectories here, and each one would have a markdown file in
it as well. Lets open this file and see what's inside.</p>
<p>We'll use vim to open the markdown file in this example, but any text editor
will work.</p>
<pre><code class="language-bash">lyra@oxford:~/collection/manifolds$ vi MANIFOLDS.md
</code></pre>
<pre><code class="language-markdown"># Note
nid: 1622849751948
model: Basic
deck: manifolds
tags:
markdown: false

## Front
Diffeomorphism

## Back
A smooth surjective map between manifolds which has a smooth inverse.

# Note
nid: 1566621764508
model: Basic
deck: manifolds
tags:
markdown: false

## Front
distribution (on a smooth manifold)

## Back
A distribution on \(M\) of rank \(k\) is a rank-\(k\) subbundle of \(TM\)
</code></pre>
<p>So we see the structure of two notes inside this file. For each note, there is
a section for note metadata, and a section for each field.</p>
<p>There is a typo in the first note. It says <code>smooth surjective map</code>, but it
should say <code>smooth bijective map</code>. Lets fix it, save our changes, and go back
to the terminal. When we go back up to the root of the repository and run <code>git
status</code>, we can see which files we've changed.</p>
<blockquote>
<p><strong>INTERNAL.</strong> Add the output of git status here.</p>
</blockquote>
<p>And running <code>git diff</code> shows us the content of the unstaged changes:</p>
<blockquote>
<p><strong>INTERNAL.</strong> Add the output of git diff here.</p>
</blockquote>
<p>Then we can commit our changes as usual.</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ git add manifolds/MANIFOLDS.md
lyra@oxford:~/collection$ git commit -m &quot;Fix typo in diffeomorphism definition: 'surjective' -&gt; 'bijective'&quot;
</code></pre>
<p>At this point we would usually <code>git push</code>, but if we try that in a <code><a title="ki" href="#ki">ki</a></code>
repository, we'll see this:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ git push
fatal: No configured push destination.
Either specify the URL from the command-line or configure a remote repository using

    git remote add &lt;name&gt; &lt;url&gt;

and then push using the remote name

    git push &lt;name&gt;

</code></pre>
<p>Since we're not pushing to an ordinary <code>git</code> remote, but to the Anki SQLite3
database, we must use <code><a title="ki" href="#ki">ki</a> push</code> instead, which is covered briefly in the next
section.</p>
<h2 id="pushing-committed-changes-back-to-anki">Pushing committed changes back to Anki</h2>
<p>This part is super easy! Similar to when we cloned, we must remember to <strong>close
Anki</strong> before pushing, or the command will fail (gracefully). All right, now we
just run the command:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ ki push
Pushing to '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
Computed md5sum: 199216c39eeabe23a1da016a99ffd3e2
Verified md5sum matches latest hash in '/home/lyra/decks/.ki/hashes'
Generating local .anki2 file from latest commit: 2aa009729b6dd337dd1ce795df611f5a49
Writing changes to '/tmp/tmpyiids2qm/original.anki2'...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00&lt;00:00, 1081.56it/s]
Database was modified.
Writing backup of .anki2 file to '/home/lyra/decks/.ki/backups'
Overwrote '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
</code></pre>
<p>As the output suggests, <code><a title="ki" href="#ki">ki</a></code> saves a backup of our collection each time we
<code>push</code>, just in case we wish to hard-revert a change you've made.</p>
<p>Now we can open Anki and view the changes we've made in the note browser!</p>
<h2 id="pulling-changes-from-anki-into-the-repository">Pulling changes from Anki into the repository</h2>
<p>So now we know how to make changes from the filesystem and push them back to
Anki, but suppose that after we cloned our repository, we made some edits
<em>within</em> Anki, and we'd like those to show up in our repository? For this,
we'll need to <strong>close Anki</strong>, and then run the following command:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ ki pull
Pulling from '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
Computed md5sum: 199216c39eeabe23a1da016a99ffd3e2
Updating 5a9ef09..9c30b73
Fast-forward
 note1645010162168.md |  4 ++--
 note1645222430007.md | 11 +++++++++++
 2 files changed, 13 insertions(+), 2 deletions(-)
 create mode 100644 note1645222430007.md

From /tmp/tmpt5a3yd9a/ki/local/199216c39eeabe23a1da016a99ffd3e2/
 * branch            main       -&gt; FETCH_HEAD
 * [new branch]      main       -&gt; anki/main

Wrote md5sum to '/home/lyra/decks/.ki/hashes'
</code></pre>
<p>And we're done! Our repository is up to date, as <code><a title="ki" href="#ki">ki</a></code> will tell us if we try to pull again:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ ki pull
ki pull: up to date.
</code></pre>
<h3 id="merge-conflicts">Merge conflicts</h3>
<p>Occasionally, when we edit the same lines in the same note fields in both Anki
and our local repository, we may encounter a merge conflict:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ ki pull
Pulling from '/home/lyra/.local/share/Anki2/User 1/collection.anki2'
Computed md5sum: debeb6689f0b83d520ff913067c598e9
Auto-merging note1645788806304.md
CONFLICT (add/add): Merge conflict in note1645788806304.md
Automatic merge failed; fix conflicts and then commit the result.

From /tmp/tmpgkq4ilfy/ki/local/debeb6689f0b83d520ff913067c598e9/
 * branch            main       -&gt; FETCH_HEAD
 * [new branch]      main       -&gt; anki/main

Wrote md5sum to '/home/mal/collection/.ki/hashes'
</code></pre>
<p>This is expected behavior, and since the process of resolving merge conflicts
is the same for <code><a title="ki" href="#ki">ki</a></code> repositories as <code>git</code> repositories (since <code><a title="ki" href="#ki">ki</a></code>
repositories <em>are</em> git repositories), we refer to
<a href="https://stackoverflow.com/questions/161813/how-to-resolve-merge-conflicts-in-a-git-repository">StackOverflow</a>
for how to proceed.</p>
<h1 id="usage-reference">Usage reference</h1>
<h2 id="clone">Clone</h2>
<p>The <code><a title="ki" href="#ki">ki</a> clone</code> command takes one required argument (the path to a <code>.anki2</code>
file) and one optional argument (a path to a target directory). The usage is
meant to mirror that of <code>git clone</code>.</p>
<p>An example of the <code>clone</code> subcommand usage and its output is given below.</p>
<pre><code class="language-bash">$ ki clone ~/.local/share/Anki2/lyra/collection.anki2 decks
</code></pre>
<pre><code class="language-bash">Found .anki2 file at '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
Computed md5sum: ad7ea6d486a327042cf0b09b54626b66
Wrote md5sum to '/home/lyra/decks/.ki/hashes'
Cloning into '/home/lyra/decks/'...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28886/28886 [00:10&lt;00:00, 2883.78it/s]
</code></pre>
<h2 id="pull">Pull</h2>
<p>Once an Anki collection has been cloned, we can <code>pull</code> changes made by the Anki
desktop client into our repository.</p>
<p>An example of the <code>pull</code> subcommand usage and its output is given below.</p>
<pre><code class="language-bash">$ ki pull
</code></pre>
<pre><code class="language-bash">Pulling from '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
Computed md5sum: 199216c39eeabe23a1da016a99ffd3e2
Updating 5a9ef09..9c30b73
Fast-forward
 note1645010162168.md |  4 ++--
 note1645222430007.md | 11 +++++++++++
 2 files changed, 13 insertions(+), 2 deletions(-)
 create mode 100644 note1645222430007.md

From /tmp/tmpt5a3yd9a/ki/local/199216c39eeabe23a1da016a99ffd3e2/
 * branch            main       -&gt; FETCH_HEAD
 * [new branch]      main       -&gt; anki/main

Wrote md5sum to '/home/lyra/decks/.ki/hashes'
</code></pre>
<p><code><a title="ki" href="#ki">ki</a></code> first deletes any residual ephemeral repositories in <code>/tmp/ki/remote/</code>.
These would only remain here if a previous pull command failed.</p>
<p>It then verifies that the path to the <code>.anki2</code> file specified in the <code>.ki/</code>
directory (analogous to the <code>.git/</code> directory) still exists.</p>
<p>It computes and records the hash of the collection file. In this way, <code><a title="ki" href="#ki">ki</a></code>
keeps track of whether the collection database has changed since the last
<code>clone</code>/<code>pull</code>.</p>
<p>Finally, the collection is then cloned into an ephemeral repository in a temp
directory, which is then <code>git pull</code>-ed into the current repository.</p>
<p>At this point, if the git operation fails, the user can take over and manage
the merge themselves.</p>
<h2 id="push">Push</h2>
<p>When we want to push our changes back to the Anki desktop client, we can use
<code><a title="ki" href="#ki">ki</a> push</code> to do that.</p>
<p>An example of the <code>push</code> subcommand usage and its output is given below.</p>
<pre><code class="language-bash">$ ki push
</code></pre>
<pre><code class="language-bash">Pushing to '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
Computed md5sum: 199216c39eeabe23a1da016a99ffd3e2
Verified md5sum matches latest hash in '/home/lyra/decks/.ki/hashes'
Generating local .anki2 file from latest commit: 2aa009729b6dd337dd1ce795df611f5a49
Writing changes to '/tmp/tmpyiids2qm/original.anki2'...
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00&lt;00:00, 1081.56it/s]
Database was modified.
Writing backup of .anki2 file to '/home/lyra/decks/.ki/backups'
Overwrote '/home/lyra/.local/share/Anki2/lyra/collection.anki2'
</code></pre>
<p>We store 5 backups of the collection prior to a push.</p>
<h1 id="collaborative-decks">Collaborative decks</h1>
<p>This section assumes knowledge of the basic <code><a title="ki" href="#ki">ki</a></code> operations and familiarity
with <code>git</code>. If you haven't yet cloned your Anki collection into a <code><a title="ki" href="#ki">ki</a></code>
repository, read the <a href="#getting-started">getting started</a> section.</p>
<ol>
<li><a href="#cloning-a-collaborative-deck-from-github"><strong>Cloning</strong></a> a collaborative deck from <a href="https://github.com/">GitHub</a>.</li>
<li><a href="#editing-a-collaborative-deck"><strong>Editing</strong></a> the collaborative deck.</li>
<li>[<strong>Pulling</strong>][pulling other users' changes from github] other users' changes to the deck from <a href="https://github.com/">GitHub</a>.</li>
<li>[<strong>Pushing</strong>][pushing edits back to github] edits back to <a href="https://github.com/">GitHub</a>.</li>
</ol>
<h2 id="cloning-a-collaborative-deck-from-github">Cloning a collaborative deck from GitHub</h2>
<p>Now that we've created our first <code><a title="ki" href="#ki">ki</a></code> repository, we might want to try our hand
at collaborating on a deck with other Anki users. We won't actually need to
make use of the <code><a title="ki" href="#ki">ki</a></code> program to do this, because <strong><code><a title="ki" href="#ki">ki</a></code> repositories are also
git repositories</strong>, and so we can clone collaborative decks from GitHub as
<code>git-submodules</code> of our collection repo.</p>
<blockquote>
<p><strong>Note.</strong> If you're completely unfamiliar with <code>git</code>, consider reading this
short
<a href="https://blog.teamtreehouse.com/git-for-designers-part-1">introduction</a>.</p>
</blockquote>
<p>Suppose we've cloned an Anki collection into a <code><a title="ki" href="#ki">ki</a></code> repository in our home
directory, just like we did in the <a href="#getting-started">getting started</a> section,
and we want to add a collaborative deck from GitHub to our collection. Let's
walk through an example. Our home directory looks like this:</p>
<pre><code class="language-bash">lyra@oxford:~$ ls
collection  pkgs
</code></pre>
<p>And we see the repo we cloned, which is called <code>collection</code>.</p>
<p>To add a collaborative deck repo as a submodule, we'll first need to change
directories to the newly cloned <code><a title="ki" href="#ki">ki</a></code> repo:</p>
<pre><code class="language-bash">lyra@oxford:~$ cd collection/
lyra@oxford:~/collection$ ls --classify
algebras/ groups/ rings/
</code></pre>
<p>We see that we have three directories, which represent three Anki decks. This
is just an example; you'll see directories corresponding to the top-level decks
in your Anki collection.</p>
<blockquote>
<p><strong>Note.</strong> The <code>ls --classify</code> command adds a trailing <code>/</code> to the end of
directories to distinguish them from ordinary files.</p>
</blockquote>
<h3 id="adding-the-repository-as-a-git-submodule">Adding the repository as a git submodule</h3>
<p>Suppose we want to add the collaborative deck
<a href="https://github.com/langfield/manifolds.git">https://github.com/langfield/manifolds.git</a>
to our collection. We can do that by running the command:</p>
<pre><code class="language-bash">git-submodule add https://github.com/langfield/manifolds.git
</code></pre>
<p>which yields the output:</p>
<pre><code class="language-bash">lyra@oxford~/collection$ git-submodule add https://github.com/langfield/manifolds.git
Cloning into 'manifolds'...
remote: Counting objects: 11, done.
remote: Compressing objects: 100% (10/10), done.
remote: Total 11 (delta 0), reused 11 (delta 0)
Unpacking objects: 100% (11/11), done.
Checking connectivity... done.
</code></pre>
<p>And we can see that the command was successful because we have a new
directory/deck called <code>manifolds</code> in our repo:</p>
<pre><code class="language-bash">lyra@oxford:~/collection$ ls --classify
algebras/ groups/ manifolds/ rings/
</code></pre>
<p>Nice!</p>
<h2 id="editing-a-collaborative-deck">Editing a collaborative deck</h2>
<p>There are two ways to edit a collaborative deck locally:</p>
<ol>
<li>Edit the markdown files in the <code><a title="ki" href="#ki">ki</a></code> repository.</li>
<li>Edit the deck inside the Anki desktop client.</li>
</ol>
<hr>
<p>After we've cloned the <code>manifolds</code> deck repository into a submodule of our <code><a title="ki" href="#ki">ki</a></code>
repository, we may want to make some edits to the deck.</p>
<h1 id="how-it-works">How it works</h1>
<p><code><a title="ki" href="#ki">ki</a></code> is built on top of existing tooling implemented in the python package
<a href="https://github.com/lervag/apy"><code>apy</code></a>, which is used to parse the Anki
collection SQLite file and convert its contents to human-readable markdown
files.</p>
<p>These files (one per Anki note) are then dumped to a configurable location in
the filesystem as a git repository, whose structure mirrors that of the decks
in the collection. In effect, <code><a title="ki" href="#ki">ki</a></code> treats the git repo it generates as a local
copy of the collection, and the <code>.anki2</code> collection file as a remote.</p>
<p>All operations like pulling updates to the collection into <code><a title="ki" href="#ki">ki</a></code> and pushing
updates from <code><a title="ki" href="#ki">ki</a></code> into Anki are handled by git under the hood.</p>
<p>This appproach has several advantages:</p>
<ol>
<li>Merge conflicts can be handled in the usual, familiar way.</li>
<li>Additional remotes (e.g. a human-readable backup of a collection on github)
can be added easily.</li>
<li>Users are free to pick the editor of their choice, perform batch editing
with command line tools like <code>awk</code> or <code>sed</code>, and even add CI actions.</li>
</ol>
<h1 id="model">Model</h1>
<p>The following diagram shows the dataflow of a typical Anki/<code><a title="ki" href="#ki">ki</a></code> stack.</p>
<pre><code>                 +-------------+          +--------------+
                 |             |          |              |
                 |   AnkiWeb  -------------  AnkiMobile  |
                 |             |   sync   |              |
                 +------|------+          +--------------+
                        |
                        | sync
                        |
                 +------|------+
                 |             |
                 |    Anki     |
                 |             |
                 +------|------+
                        |
                        | deck edits
                        |
               +--------|--------+               +------------------+
               |                 |    ki clone   |                  |
               |                 ----------------&gt;                  |
               | Collection file |               |     ~/decks/     |
               |    (.anki2)     |    ki push    | (git repository) |
               |                 &lt;----------------                  |
               |                 |               |                  |
               +--------|--------+               +---------^--------+
                        |                                  |
                        | ki pull                          |
                        |                                  |
                        |                                  |
             +----------v----------+                       |
             |                     |                       |
             | /tmp/ki/remote/AAA  |           ki pull     |
             |  (git repository)   -------------------------
             |    [ephemeral]      |
             |                     |
             +---------------------+
</code></pre>
<p>The node labeled Anki is the Anki desktop client on the localhost. It
communicates with the AnkiWeb servers via Anki's sync feature. Other clients
(e.g. AnkiDroid and AnkiMobile) are able to (1) pull changes made by the
desktop client into their local collections via AnkiWeb, and (2) push changes
made locally back to AnkiWeb.</p>
<p>When the Anki desktop client is started on the localhost, it opens and places a
lock on the <code>.anki2</code> SQLite file. During the session, changes are possibly made
to the deck, and the SQLite file is unlocked when the program is closed.</p>
<p>Since <code><a title="ki" href="#ki">ki</a></code> must read from this database file, that means that <code><a title="ki" href="#ki">ki</a></code> commands
will not work while Anki is running. This is <strong>by design</strong>: the database is
locked for a reason, and enforcing this constraint lowers the likelihood that
users' decks become corrupted.</p>
<p>An ephemeral repository is used as an auxiliary step during the <code><a title="ki" href="#ki">ki</a> pull</code>
operation so that we can merge the Anki desktop client's changes into our
repository via git.</p>
<h1 id="generating-html">Generating html</h1>
<p>By default, <code><a title="ki" href="#ki">ki</a></code> parses the html of each field and dumps the content only,
insofar as that is possible. It also supports parsing arbitrary html elements
autogenerated by addons and regenerated the updated content. In the following
subsection, we walk through an example.</p>
<h2 id="example-generating-syntax-highlighted-code-blocks">Example: generating syntax-highlighted code blocks</h2>
<p>The anki addon developer Glutanimate has an addon called <code>syntax-highlighting</code>,
which adds UI elements to the Anki note editor that automatically generates a
syntax highlighted version of a code block from the clipboard. In effect, it
generates a formatted HTML table for the code listing that gets dumped into the
source of relevant note field.</p>
<p>A fork of this addon is available here:
<a href="https://ankiweb.net/shared/info/1100811177">https://ankiweb.net/shared/info/1100811177</a></p>
<p>And the source tree for the original addon is on github:
<a href="https://github.com/glutanimate/syntax-highlighting">https://github.com/glutanimate/syntax-highlighting</a></p>
<p>For example, consider the following python code block:</p>
<pre><code class="language-python">n = 1
n &gt;&gt; 1
print(n)
</code></pre>
<p>Given the above code, the addon generates the following HTML:</p>
<pre><code class="language-html">&lt;table class=&quot;highlighttable&quot;&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td class=&quot;linenos&quot;&gt;
                &lt;div class=&quot;linenodiv&quot;&gt;
                    &lt;pre&gt;
                        &lt;span class=&quot;normal&quot;&gt;1&lt;/span&gt;
                        &lt;span class=&quot;normal&quot;&gt;2&lt;/span&gt;
                        &lt;span class=&quot;normal&quot;&gt;3&lt;/span&gt;
                    &lt;/pre&gt;
                &lt;/div&gt;
            &lt;/td&gt;
            &lt;td class=&quot;code&quot;&gt;
                &lt;div class=&quot;highlight&quot;&gt;
                    &lt;pre&gt;
                        &lt;code&gt;
                            &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
                            &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                            &lt;br&gt;
                                &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
                                &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
                                &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                                &lt;br&gt;
                                    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;
                                    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                                    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
                                    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                                    &lt;br&gt;
                                    &lt;/code&gt;
                                &lt;/pre&gt;
                &lt;/div&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
</code></pre>
<p>Editing fields like this could become annoying very quickly. It would be better
if <code><a title="ki" href="#ki">ki</a></code> just gave us the markdown version above (only 3 lines), and then
regenerated the note field HTML when converting the repository back into a
<code>.anki2</code> deck.</p>
<h3 id="adding-ki-html-attributes">Adding <code><a title="ki" href="#ki">ki</a></code> HTML attributes</h3>
<p>And in fact, this is possible. We first fork the addon so we can add some extra
data to our generated HTML. In particular, we'd like to add an attribute
<code>ki-src</code> whose value is the UTF-8 encoded source code. In general, this will be
the encoded version of the source of whatever we'd like to autoformat.</p>
<p>We also add a <code>ki-formatter</code> attribute, whose value is an identifier that
specifies a custom python module (we must implement this) that transforms the
(possibly edited) <code>ki-src</code> text back into a HTML element of the form seen
above.</p>
<p>So let's call our <code>ki-formatter</code> identifier <code>syntax-hl-python</code>. Then our addon
has to change the opening tag of the snippet above to look like:</p>
<pre><code class="language-html">&lt;table class=&quot;highlighttable&quot;; ki-src=&quot;n = 1\nn &gt;&gt; 1\nprint(n)\n&quot;; ki-formatter=&quot;syntax-hl-python&quot;&gt;
</code></pre>
<p>All <code><a title="ki" href="#ki">ki</a></code> needs is the original text of the code block prior to html formatting,
and a function that can reapply the formatting to the modified text. Since the
html table was generated by an addon, we already have a python function for
this, and in general we can provide a <code>~/.config/ki/ki.json</code> file that maps
implementation IDs to paths of python modules. The module must have a top-level
function defined of the form <code>format(text: str) -&gt; bs4.Tag</code>.</p>
<p>If we have an addon implementation, we can import it here and use it in our
<code>format()</code> implementation. We can add a <code><a title="ki" href="#ki">ki</a></code> attribute whose value is the
base64 encoding of the code block, and a <code>implementation</code> attribute whose value
is the name of a function. At import-time, <code><a title="ki" href="#ki">ki</a></code> will decode this and write the
human-readable source to the relevant markdown file instead.</p>
<h3 id="source-code">Source code</h3>
<p>If you have <code>git</code>, you can clone
a local copy of the source code by running the following command in a terminal:</p>
<pre><code class="language-bash">git clone git@github.com:langfield/ki.git
</code></pre>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Ki is a command-line interface for the version control and editing of `.anki2`
collections as git repositories of markdown files.  Rather than providing an
interactive UI like the Anki desktop client, ki aims to allow natural editing
*in the filesystem*.

In general, the purpose of ki is to allow users to work on large, complex Anki
decks in exactly the same way they work on large, complex software projects.
.. include:: ./DOCUMENTATION.md
&#34;&#34;&#34;

# pylint: disable=invalid-name, missing-class-docstring, broad-except
# pylint: disable=too-many-return-statements, too-many-lines, too-many-arguments
# pylint: disable=no-value-for-parameter, not-callable

import os
import re
import io
import gc
import sys
import time
import json
import copy
import shutil
import random
import logging
import secrets
import sqlite3
import hashlib
import datetime
import itertools
import traceback
import functools
import subprocess
import dataclasses
import configparser
from pathlib import Path
from itertools import chain, starmap, tee
from functools import reduce
from contextlib import redirect_stdout
from dataclasses import dataclass
from collections import namedtuple

import git
import click
import whatthepatch
from lark import Lark

# Required to avoid circular imports because the Anki pylib codebase is gross.
import anki.collection
from anki.cards import Card, TemplateDict
from anki.decks import DeckTreeNode
from anki.utils import ids2str
from anki.models import ChangeNotetypeInfo, ChangeNotetypeRequest, NotetypeDict
from anki.errors import NotFoundError
from anki.exporting import AnkiExporter
from anki.collection import Collection, Note, OpChangesWithId
from anki.importing.noteimp import NoteImporter

from beartype import beartype
from beartype.typing import (
    Set,
    List,
    Dict,
    Any,
    Optional,
    Callable,
    Union,
    TypeVar,
    Sequence,
    Tuple,
    Iterator,
    Iterable,
    FrozenSet,
)

import ki.maybes as M
import ki.functional as F
from ki.types import (
    MODELS_FILE,
    File,
    Dir,
    EmptyDir,
    NoPath,
    NoFile,
    Link,
    WindowsLink,
    PseudoFile,
    GitChangeType,
    Patch,
    Delta,
    KiRepo,
    Field,
    Template,
    Notetype,
    ColNote,
    KiRev,
    Rev,
    Deck,
    Root,
    DotKi,
    CardFile,
    NoteDBRow,
    DeckNote,
    NoteMetadata,
    PushResult,
    PlannedLink,
    Submodule,
    MediaBytes,
    AddedMedia,
    UpdatesRejectedError,
    TargetExistsError,
    CollectionChecksumError,
    MissingNotetypeError,
    MissingFieldOrdinalError,
    MissingNoteIdError,
    NotetypeMismatchError,
    NoteFieldValidationWarning,
    DeletedFileNotFoundWarning,
    DiffTargetFileNotFoundWarning,
    NotetypeCollisionWarning,
    NotetypeKeyError,
    UnnamedNotetypeError,
    SQLiteLockError,
    NoteFieldKeyError,
    MissingMediaDirectoryError,
    ExpectedNonexistentPathError,
    WrongFieldCountWarning,
    InconsistentFieldNamesWarning,
    MissingTidyExecutableError,
    AnkiDBNoteMissingFieldsError,
    GitFileModeParseError,
    RenamedMediaFileWarning,
    NonEmptyWorkingTreeError,
    EmptyNoteWarning,
    DuplicateNoteWarning,
    UnhealthyNoteWarning,
    MediaDirectoryDeckNameCollisionWarning,
    notetype_json,
)
from ki.maybes import (
    GIT,
    GITIGNORE_FILE,
    GITMODULES_FILE,
    KI,
    CONFIG_FILE,
    HASHES_FILE,
    BACKUPS_DIR,
)
from ki.transformer import NoteTransformer, FlatNote

curried = F.curried

logging.basicConfig(level=logging.INFO)

TQ = F.progressbar

T = TypeVar(&#34;T&#34;)
NoteId, DeckId, CardId = int, int, int
CardFileMap = Dict[DeckId, List[CardFile]]

UTF8 = &#34;UTF-8&#34;
URLS = &#34;(https?|ftp)://&#34;
MEDIA = M.MEDIA
DEV_NULL = &#34;/dev/null&#34;
BATCH_SIZE = 300
HTML_REGEX = r&#34;&lt;/?\s*[a-z-][^&gt;]*\s*&gt;|(\&amp;(?:[\w\d]+|#\d+|#x[a-f\d]+);)&#34;
REMOTE_NAME = &#34;anki&#34;
BRANCH_NAME = F.BRANCH_NAME
MAX_FILENAME_LEN = 60
IGNORE_DIRS = set([GIT, KI, MEDIA])
IGNORE_FILES = set([GITIGNORE_FILE, GITMODULES_FILE, MODELS_FILE])
HEAD_SUFFIX = Path(&#34;ki-head&#34;)
LOCAL_SUFFIX = Path(&#34;ki-local&#34;)
REMOTE_SUFFIX = Path(&#34;ki-remote&#34;)
FIELD_HTML_SUFFIX = Path(&#34;ki-fieldhtml&#34;)
LCA = &#34;last-successful-ki-push&#34;

TIDY_CMD = &#34;tidy -q -m -i -omit -utf8&#34;
TIDY_OPTS = &#34;--tidy-mark no --show-body-only yes --wrap 68 --wrap-attributes yes&#34;

MEDIA_FILE_RECURSIVE_PATTERN = f&#34;**/{MEDIA}/*&#34;

# This is the key for media files associated with notetypes instead of the
# contents of a specific note.
NOTETYPE_NID = -57

MD = &#34;.md&#34;

ALHPANUMERICS = &#34;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#34;
SYMBOLS = &#34;!#$%&amp;()*+,-./:;&lt;=&gt;?@[]^_`{|}~&#34;
BASE91_TABLE = list(ALHPANUMERICS + SYMBOLS)

ADDED = GitChangeType.ADDED
RENAMED = GitChangeType.RENAMED
DELETED = GitChangeType.DELETED
MODIFIED = GitChangeType.MODIFIED
TYPECHANGED = GitChangeType.TYPECHANGED


@beartype
def do(f: Callable[[Any], Any], xs: Iterable[Any]) -&gt; None:
    &#34;&#34;&#34;Perform some action on an iterable.&#34;&#34;&#34;
    set(map(f, xs))


@beartype
def stardo(f: Callable[[Any], Any], xs: Iterable[Any]) -&gt; None:
    &#34;&#34;&#34;Perform some action on an iterable of tuples, unpacking arguments.&#34;&#34;&#34;
    set(starmap(f, xs))


@beartype
def lock(col_file: File) -&gt; sqlite3.Connection:
    &#34;&#34;&#34;Check that lock can be acquired on a SQLite3 database given a path.&#34;&#34;&#34;
    try:
        con = sqlite3.connect(col_file, timeout=0.1)
        con.isolation_level = &#34;EXCLUSIVE&#34;
        con.execute(&#34;BEGIN EXCLUSIVE&#34;)
    except sqlite3.DatabaseError as err:
        raise SQLiteLockError(col_file, err) from err
    if sys.platform == &#34;win32&#34;:
        con.commit()
        con.close()
    return con


@beartype
def unlock(con: sqlite3.Connection) -&gt; None:
    &#34;&#34;&#34;Unlock a SQLite3 database.&#34;&#34;&#34;
    if sys.platform == &#34;win32&#34;:
        return
    con.commit()
    con.close()


@beartype
def cp_repo(rev: Rev, suffix: str) -&gt; git.Repo:
    &#34;&#34;&#34;Get a temporary copy of a git repository in /tmp/&lt;suffix&gt;/.&#34;&#34;&#34;
    # Copy the entire repo into a temp directory ending in `../suffix/`.
    target: NoFile = F.chk(F.mkdtemp() / suffix)
    ephem = git.Repo(F.copytree(F.root(rev.repo), target))

    # Do a reset --hard to the given SHA.
    ephem.git.reset(rev.sha, hard=True)
    return ephem


@beartype
def cp_ki(ki_rev: KiRev, suffix: str) -&gt; KiRepo:
    &#34;&#34;&#34;
    Given a KiRev, i.e. a pair of the form (kirepo, SHA), we clone
    `kirepo.repo` into a temp directory and hard reset to the given commit
    hash. Copies the .ki/ directory from `ki_rev.kirepo` without making any
    changes.

    Parameters
    ----------
    ki_rev : KiRev
        The ki repository to clone, and a commit for it.
    suffix : str
        /tmp/.../ path suffix, e.g. `ki/local/`.

    Returns
    -------
    KiRepo
        The copied ki repository.
    &#34;&#34;&#34;
    rev: Rev = F.ki_rev_to_rev(ki_rev)
    print(F.root(rev.repo))
    ephem: git.Repo = cp_repo(rev, suffix)
    F.force_mkdir(F.root(ephem) / KI / BACKUPS_DIR)
    kirepo: KiRepo = M.kirepo(F.root(ephem))
    return kirepo


@beartype
def is_anki_note(path: File) -&gt; bool:
    &#34;&#34;&#34;Check if file is a `ki`-style markdown note.&#34;&#34;&#34;
    # Ought to have markdown file extension.
    if path.suffix != &#34;.md&#34;:
        return False
    with open(path, &#34;r&#34;, encoding=UTF8) as md_f:
        lines = md_f.readlines()
    if len(lines) &lt; 8:
        return False
    if lines[0] != &#34;# Note\n&#34;:
        return False
    if lines[1] != &#34;```\n&#34;:
        return False
    if not re.match(r&#34;^guid: &#34;, lines[2]):
        return False
    return True


@beartype
def is_ignorable(root: Dir, path: Path) -&gt; bool:
    &#34;&#34;&#34;
    Filter out paths in a git repository diff that do not correspond to Anki
    notes.

    We could do this purely using calls to `is_anki_note()`, but these are
    expensive, so we try to find matches without opening any files first.
    &#34;&#34;&#34;
    # Ignore if `path` is an exact match for any of the patterns Since the
    # contents of a git repository diff are always going to be files, this
    # alone will not correctly ignore directory names given in `patterns`.
    #
    # If any of the patterns in `dirnames` resolve to one of the parents of
    # `path`, return a warning, so that we are able to filter out entire
    # directories.
    filenames, dirnames = IGNORE_FILES, IGNORE_DIRS
    if path.name in filenames | dirnames or len(set(path.parts) &amp; dirnames) &gt; 0:
        return True

    # If `path` is an extant file (not a directory) and *not* a note, ignore it.
    file = F.chk(root / path)
    if isinstance(file, File) and not is_anki_note(file):
        return True
    return False


@curried
@beartype
def mungediff(
    parse: Callable[[Delta], DeckNote], a_root: Dir, b_root: Dir, d: git.Diff
) -&gt; Iterable[Union[Delta, Warning]]:
    &#34;&#34;&#34;Extract deltas and warnings from a collection of diffs.&#34;&#34;&#34;
    a, b = d.a_path, d.b_path
    a, b = a if a else b, b if b else a
    if is_ignorable(a_root, Path(a)) or is_ignorable(b_root, Path(b)):
        return []

    # Get absolute and relative paths to &#39;a&#39; and &#39;b&#39;.
    AB = namedtuple(&#34;AB&#34;, &#34;a b&#34;)
    files = AB(F.chk(a_root / a), F.chk(b_root / b))
    rels = AB(Path(a), Path(b))

    if d.change_type == DELETED.value:
        if not F.isfile(files.a):
            return [DeletedFileNotFoundWarning(rels.a)]
        return [Delta(GitChangeType.DELETED, files.a, rels.a)]
    if not F.isfile(files.b):
        return [DiffTargetFileNotFoundWarning(rels.b)]
    if d.change_type == RENAMED.value:
        a_delta = Delta(GitChangeType.DELETED, files.a, rels.a)
        b_delta = Delta(GitChangeType.ADDED, files.b, rels.b)
        a_decknote, b_decknote = parse(a_delta), parse(b_delta)
        if a_decknote.guid != b_decknote.guid:
            return [a_delta, b_delta]
    return [Delta(GitChangeType(d.change_type), files.b, rels.b)]


@beartype
def diff2(
    repo: git.Repo,
    parse: Callable[[Delta], DeckNote],
) -&gt; Iterable[Union[Delta, Warning]]:
    &#34;&#34;&#34;Diff `repo` from `HEAD~1` to `HEAD`.&#34;&#34;&#34;
    # We diff from A~B.
    head1: Rev = M.rev(repo, repo.commit(&#34;HEAD~1&#34;).hexsha)
    uuid = hex(random.randrange(16**4))[2:]
    head1_repo = cp_repo(head1, suffix=f&#34;HEAD~1-{uuid}&#34;)
    a_root, b_root = F.root(head1_repo), F.root(repo)
    diffidx = repo.commit(&#34;HEAD~1&#34;).diff(repo.commit(&#34;HEAD&#34;))

    # Get the diffs for each change type (e.g. &#39;DELETED&#39;).
    return chain(*map(mungediff(parse, a_root, b_root), diffidx))


@beartype
def get_models_recursively(kirepo: KiRepo) -&gt; Dict[str, Notetype]:
    &#34;&#34;&#34;
    Find and merge all `models.json` files recursively. Returns a dictionary
    sending model names to Notetypes.
    &#34;&#34;&#34;

    @beartype
    def load(file: File) -&gt; Iterable[Notetype]:
        &#34;&#34;&#34;Load a models file.&#34;&#34;&#34;
        with open(file, &#34;r&#34;, encoding=UTF8) as f:
            return map(M.notetype, json.load(f).values())

    notetypes = F.cat(map(load, F.rglob(kirepo.root, MODELS_FILE)))
    return {notetype.name: notetype for notetype in notetypes}


@beartype
def check_fields_health(note: Note) -&gt; List[Warning]:
    &#34;&#34;&#34;Construct warnings when Anki&#39;s fields health check fails.&#34;&#34;&#34;
    health = note.fields_check()
    if health == 1:
        return [EmptyNoteWarning(note, health)]
    if health == 2:
        return [DuplicateNoteWarning(note, health, html_to_screen(note.fields[0]))]
    if health != 0:
        return [UnhealthyNoteWarning(note, health)]
    return []


@beartype
def get_guid(fields: List[str]) -&gt; str:
    &#34;&#34;&#34;Construct a new GUID for a note. Adapted from genanki&#39;s `guid_for()`.&#34;&#34;&#34;
    # Get the first 8 bytes of the SHA256 of `contents` as an int.
    m = hashlib.sha256()
    m.update(&#34;__&#34;.join(fields).encode(&#34;utf-8&#34;))
    x = reduce(lambda h, b: (h &lt;&lt; 8) + b, m.digest()[:8], 0)

    # convert to the weird base91 format that Anki uses
    chars = []
    while x &gt; 0:
        chars.append(BASE91_TABLE[x % len(BASE91_TABLE)])
        x //= len(BASE91_TABLE)
    return &#34;&#34;.join(reversed(chars))


@curried
@beartype
def parse_note(parser: Lark, transformer: NoteTransformer, delta: Delta) -&gt; DeckNote:
    &#34;&#34;&#34;Parse with lark.&#34;&#34;&#34;
    tree = parser.parse(delta.path.read_text(encoding=UTF8))
    flatnote: FlatNote = transformer.transform(tree)
    parts: Tuple[str, ...] = delta.relpath.parent.parts
    deck: str = &#34;::&#34;.join(parts)

    # Generate a GUID from the hash of the field contents if the `guid` field
    # in the note file was left blank.
    fields = list(flatnote.fields.values())
    guid = flatnote.guid if flatnote.guid != &#34;&#34; else get_guid(fields)

    return DeckNote(
        title=flatnote.title,
        guid=guid,
        deck=deck,
        model=flatnote.model,
        tags=flatnote.tags,
        fields=flatnote.fields,
    )


@beartype
def plain_to_html(plain: str) -&gt; str:
    &#34;&#34;&#34;Convert plain text to html&#34;&#34;&#34;
    # Minor clean up
    plain = plain.replace(r&#34;&amp;lt;&#34;, &#34;&lt;&#34;)
    plain = plain.replace(r&#34;&amp;gt;&#34;, &#34;&gt;&#34;)
    plain = plain.replace(r&#34;&amp;amp;&#34;, &#34;&amp;&#34;)
    plain = plain.replace(r&#34;&amp;nbsp;&#34;, &#34; &#34;)
    plain = re.sub(r&#34;\&lt;b\&gt;\s*\&lt;\/b\&gt;&#34;, &#34;&#34;, plain)
    plain = re.sub(r&#34;\&lt;i\&gt;\s*\&lt;\/i\&gt;&#34;, &#34;&#34;, plain)
    plain = re.sub(r&#34;\&lt;div\&gt;\s*\&lt;\/div\&gt;&#34;, &#34;&#34;, plain)

    # Convert newlines to `&lt;br&gt;` tags.
    if not re.search(HTML_REGEX, plain):
        plain = plain.replace(&#34;\n&#34;, &#34;&lt;br&gt;&#34;)

    return plain.strip()


@curried
@beartype
def update_field(decknote: DeckNote, note: Note, key: str, field: str) -&gt; None:
    &#34;&#34;&#34;Update a field contained in `note`.&#34;&#34;&#34;
    try:
        note[key] = plain_to_html(field)
    except IndexError as err:
        raise AnkiDBNoteMissingFieldsError(decknote, note.id, key) from err


@beartype
def update_note(
    note: Note, decknote: DeckNote, old_notetype: Notetype, new_notetype: Notetype
) -&gt; Iterable[Warning]:
    &#34;&#34;&#34;
    Change all the data of `note` to that given in `decknote`.

    This is only to be called on notes whose nid already exists in the
    database.  Creates a new deck if `decknote.deck` doesn&#39;t exist.  Assumes
    that the model has already been added to the collection, and raises an
    exception if it finds otherwise.  Changes notetype to that specified by
    `decknote.model`.  Overwrites all fields with `decknote.fields`.

    Updates:
    - tags
    - deck
    - model
    - fields
    &#34;&#34;&#34;

    # Check that the passed argument `new_notetype` has a name consistent with
    # the model specified in `decknote`. The former should be derived from the
    # latter, and if they don&#39;t match, there is a bug in the caller.
    if decknote.model != new_notetype.name:
        raise NotetypeMismatchError(decknote, new_notetype)

    nid = note.id
    note.tags = decknote.tags
    note.flush()

    # Set the deck of the given note, as well as all its cards, and create a
    # deck with this name if it doesn&#39;t already exist. See the
    # comments/docstrings in the implementation of the
    # `anki.decks.DeckManager.id()` method.
    newdid: int = note.col.decks.id(decknote.deck, create=True)
    cids = [c.id for c in note.cards()]
    if cids:
        note.col.set_deck(cids, newdid)

    # Set notetype (also clears all fields).
    if old_notetype.id != new_notetype.id:
        fmap = {field.ord: None for field in old_notetype.flds}
        note.col.models.change(old_notetype.dict, [nid], new_notetype.dict, fmap, None)
        note.load()

    # Validate field keys against notetype.
    warnings: List[Warning] = validate_decknote_fields(new_notetype, decknote)
    if len(warnings) &gt; 0:
        return warnings

    # Set field values and flush to collection database. This is correct
    # because every field name that appears in `new_notetype` is contained in
    # `decknote.fields`, or else we would have printed a warning and returned
    # above.
    missing = {key for key in decknote.fields if key not in note}
    warnings = map(lambda k: NoteFieldValidationWarning(nid, k, new_notetype), missing)
    fields = [(key, field) for key, field in decknote.fields.items() if key in note]
    stardo(update_field(decknote, note), fields)
    note.flush()

    # Remove if unhealthy.
    fwarns: List[Warning] = check_fields_health(note)
    if len(fwarns) &gt; 0:
        note.col.remove_notes([nid])
    return chain(warnings, fwarns)


@beartype
def validate_decknote_fields(notetype: Notetype, decknote: DeckNote) -&gt; List[Warning]:
    &#34;&#34;&#34;Validate that the fields given in the note match the notetype.&#34;&#34;&#34;
    warnings: List[Warning] = []
    names: List[str] = [field.name for field in notetype.flds]

    # TODO: It might also be nice to print the path of the note in the
    # repository. This would have to be added to the `DeckNote` spec.
    if len(decknote.fields.keys()) != len(names):
        warnings.append(WrongFieldCountWarning(decknote, names))

    mk_warning = lambda n, k: InconsistentFieldNamesWarning(n, k, decknote)
    names_and_keys = F.starfilter(
        lambda n, k: n != k, zip(names, decknote.fields.keys())
    )
    return warnings + list(starmap(mk_warning, names_and_keys))


@beartype
def get_note_path(colnote: ColNote, deck_dir: Dir, card_name: str = &#34;&#34;) -&gt; NoFile:
    &#34;&#34;&#34;Get note path from sort field text.&#34;&#34;&#34;
    field_text = colnote.sortf_text

    # Construct filename, stripping HTML tags and sanitizing (quickly).
    field_text = plain_to_html(field_text)
    field_text = re.sub(&#34;&lt;[^&lt;]+?&gt;&#34;, &#34;&#34;, field_text)

    # If the HTML stripping removed all text, we just slugify the raw sort
    # field text.
    if len(field_text) == 0:
        field_text = colnote.sortf_text

    name = field_text[:MAX_FILENAME_LEN]
    slug = F.slugify(name)

    # If the slug is still empty, use all the fields.
    if len(slug) == 0:
        contents = &#34; &#34;.join(colnote.n.values())
        name = contents[:MAX_FILENAME_LEN]
        slug = F.slugify(name)

    # Make it so `slug` cannot possibly be an empty string, because then we get
    # a `Path(&#39;.&#39;)` which is a bug, and causes a runtime exception. If all else
    # fails, use the notetype name, hash of the payload, and creation date.
    if len(slug) == 0:
        blake2 = hashlib.blake2s()
        blake2.update(colnote.n.guid.encode(UTF8))
        slug: str = f&#34;{colnote.notetype.name}--{blake2.hexdigest()}&#34;

        # Note IDs are in milliseconds.
        dt = datetime.datetime.fromtimestamp(colnote.n.id / 1000.0)
        slug += &#34;--&#34; + dt.strftime(&#34;%Y-%m-%d--%Hh-%Mm-%Ss&#34;)
        F.yellow(f&#34;Slug for note with guid &#39;{colnote.n.guid}&#39; is empty...&#34;)
        F.yellow(f&#34;Using blake2 hash of guid as filename: &#39;{slug}&#39;&#34;)

    if card_name != &#34;&#34;:
        slug = f&#34;{slug}_{card_name}&#34;
    filename: str = f&#34;{slug}{MD}&#34;
    note_path = F.chk(deck_dir / filename, resolve=False)

    i = 1
    while not isinstance(note_path, NoFile):
        filename = f&#34;{slug}_{i}{MD}&#34;
        note_path = F.chk(deck_dir / filename, resolve=False)
        i += 1

    return note_path


@beartype
def backup(kirepo: KiRepo) -&gt; int:
    &#34;&#34;&#34;Backup collection to `.ki/backups`.&#34;&#34;&#34;
    md5sum = F.md5(kirepo.col_file)
    name = f&#34;{md5sum}.anki2&#34;
    backup_file = F.chk(kirepo.backups_dir / name)

    # We assume here that no one would ever make e.g. a directory called
    # `name`, since `name` contains the md5sum of the collection file, and
    # thus that is extraordinarily improbable. So the only thing we have to
    # check for is that we haven&#39;t already written a backup file to this
    # location.
    if isinstance(backup_file, File):
        return 1

    F.copyfile(kirepo.col_file, F.chk(kirepo.backups_dir / name))
    return 0


@beartype
def append_md5sum(dotki: Dir, tag: str, md5sum: str) -&gt; None:
    &#34;&#34;&#34;Append an md5sum hash to the hashes file.&#34;&#34;&#34;
    hashes_file = dotki / HASHES_FILE
    with open(hashes_file, &#34;a+&#34;, encoding=UTF8) as hashes_f:
        hashes_f.write(f&#34;{md5sum}  {tag}\n&#34;)


@beartype
def get_field_note_id(nid: int, fieldname: str) -&gt; str:
    &#34;&#34;&#34;A str ID that uniquely identifies field-note pairs.&#34;&#34;&#34;
    return f&#34;{nid}{F.slugify(fieldname)}&#34;


@beartype
def add_db_note(
    col: Collection,
    nid: int,
    guid: str,
    mid: int,
    mod: int,
    usn: int,
    tags: List[str],
    fields: List[str],
    sfld: str,
    csum: int,
    flags: int,
    data: str,
) -&gt; Note:
    &#34;&#34;&#34;Add a note to the database directly, with a SQL INSERT.&#34;&#34;&#34;
    importer = NoteImporter(col, &#34;&#34;)
    importer.addNew(
        [
            (
                nid,
                guid,
                mid,
                mod,
                usn,
                &#34; &#34; + &#34; &#34;.join(tags) + &#34; &#34;,
                &#34;\x1f&#34;.join(fields),
                sfld,
                csum,
                flags,
                data,
            )
        ]
    )

    # All the `mark_modified` flag does is update `mod`. Since we always set
    # `mod` to the current timestamp anyway, this doesn&#39;t matter, so may as
    # well set it to `True` to reflect the semantics of the operation we&#39;re
    # performing. This may present issues down the road since newly imported
    # cards from cloned submodules will be marked modified on import/push,
    # which is not exactly right. The anki2 importer does *not* mark as
    # modified, because importing a new note does not modify its content. We
    # would need to have `mod` data inside the note grammar in order for this
    # to make sense, which may be more trouble than it&#39;s worth. Users writing
    # new notes as markdown files would have to set the `mod` to some default
    # value, or leave it blank. Assuming people don&#39;t do this nearly as often
    # as they will export or push notes they&#39;ve created in Anki, then it might
    # make sense.
    col.after_note_updates([nid], mark_modified=True)
    return col.get_note(nid)


@curried
@beartype
def push_note(
    col: Collection,
    timestamp_ns: int,
    guids: Dict[str, NoteMetadata],
    new_nids: Iterator[int],
    decknote: DeckNote,
) -&gt; Iterable[Warning]:
    &#34;&#34;&#34;
    Update the Anki `Note` object in `col` corresponding to `decknote`,
    creating it if it does not already exist.

    Raises
    ------
    MissingNotetypeError
        If we can&#39;t find a notetype with the name provided in `decknote`.
    &#34;&#34;&#34;
    # Notetype/model names are privileged in Anki, so if we don&#39;t find the
    # right name, we raise an error.
    model_id: Optional[int] = col.models.id_for_name(decknote.model)
    if model_id is None:
        raise MissingNotetypeError(decknote.model)

    if decknote.guid in guids:
        nid: int = guids[decknote.guid].nid
        try:
            note: Note = col.get_note(nid)
        except NotFoundError as err:
            print(f&#34;{nid = }&#34;)
            print(f&#34;{decknote.guid = }&#34;)
            raise err
    else:
        nid: int = next(new_nids)
        note: Note = add_db_note(
            col,
            nid,
            decknote.guid,
            model_id,
            mod=int(timestamp_ns // 1e9),
            usn=-1,
            tags=decknote.tags,
            fields=list(decknote.fields.values()),
            sfld=&#34;&#34;,
            csum=0,
            flags=0,
            data=&#34;&#34;,
        )

    # If we are updating an existing note, we need to know the old and new
    # notetypes, and then update the notetype (and the rest of the note data)
    # accordingly.
    old_notetype: Notetype = M.notetype(note.note_type())
    new_notetype: Notetype = M.notetype(col.models.get(model_id))
    return update_note(note, decknote, old_notetype, new_notetype)


@beartype
def get_header_lines(colnote) -&gt; List[str]:
    &#34;&#34;&#34;Get header of markdown representation of note.&#34;&#34;&#34;
    lines = [
        &#34;# Note&#34;,
        &#34;```&#34;,
        f&#34;guid: {colnote.n.guid}&#34;,
        f&#34;notetype: {colnote.notetype.name}&#34;,
        &#34;```&#34;,
        &#34;&#34;,
        &#34;### Tags&#34;,
        &#34;```&#34;,
    ]
    lines += colnote.n.tags
    lines += [&#34;```&#34;, &#34;&#34;]
    return lines


@curried
@beartype
def localmedia(s: str, regex: str) -&gt; Iterable[str]:
    &#34;&#34;&#34;Return local media filenames matching the given regex pattern.&#34;&#34;&#34;
    fnames = map(lambda m: m.group(&#34;fname&#34;), re.finditer(regex, s))
    fnames = map(lambda s: s.strip(), fnames)
    return filter(lambda x: not re.match(URLS, x.lower()), fnames)


@beartype
def media_filenames_in_field(col: Collection, s: str) -&gt; Iterable[str]:
    &#34;&#34;&#34;A copy of `MediaManager.files_in_str()`, but without LaTeX rendering.&#34;&#34;&#34;
    s = (s.strip()).replace(&#39;&#34;&#39;, &#34;&#34;)
    return F.cat(map(localmedia(s), col.media.regexps))


@curried
@beartype
def copy_note_media(
    col: Collection, src: Dir, tgt: Dir, row: NoteDBRow
) -&gt; FrozenSet[File]:
    &#34;&#34;&#34;
    Copy a single note&#39;s media files and return the copies as a set. We do this
    by first filtering for only &#39;rootfiles&#39;, i.e. excluding media files in
    subdirectories of the media directory. Then we take only those which exist,
    i.e. typecheck as `File`. Then we construct the source and destination
    paths, and finally actually perform the copy op, returning the result.

    Note that `src` is the media directory where the files originate, and `tgt`
    is the media directory we&#39;re copying to.
    &#34;&#34;&#34;
    files: Iterable[str] = media_filenames_in_field(col, row.flds)
    rootfiles = filter(lambda f: f == os.path.basename(f), files)
    medias: Iterable[File] = filter(F.isfile, map(lambda f: F.chk(src / f), rootfiles))
    srcdsts = map(lambda file: (file, F.chk(tgt / file.name)), medias)
    return frozenset(starmap(F.copyfile, srcdsts))


@curried
@beartype
def copy_notetype_media(
    src: Dir, tgt: Dir, paths: Set[Path], m: NotetypeDict
) -&gt; FrozenSet[File]:
    &#34;&#34;&#34;Copy media from notetype `m` from source to target, returning set of copies.&#34;&#34;&#34;
    matches: Iterable[Path] = filter(lambda p: hasmedia(m, str(p)), paths)
    medias = filter(F.isfile, map(lambda p: F.chk(src / p), matches))
    srcdsts = map(lambda f: (f, F.chk(tgt / f.name)), medias)
    return frozenset(starmap(F.copyfile, srcdsts))


@beartype
def copy_media_files(
    col: Collection,
    media_target_dir: EmptyDir,
) -&gt; Dict[int, Set[File]]:
    &#34;&#34;&#34;
    Get a list of extant media files used in notes and notetypes, copy those
    media files to the top-level `_media/` directory in the repository root,
    and return a map sending note ids to sets of copied media files.

    Adapted from code in `anki/pylib/anki/exporting.py`. Specifically, the
    `AnkiExporter.exportInto()` function.

    Parameters
    ----------
    col
        Anki collection.
    media_target_dir
        Where media files are to be copied to.
    &#34;&#34;&#34;
    # All note ids as a string for the SQL query.
    strnids = ids2str(list(col.find_notes(query=&#34;&#34;)))

    # This is the path to the media directory. In the original implementation
    # of `AnkiExporter.exportInto()`, there is check made of the form
    #
    #   if self.mediaDir:
    #
    # before doing path manipulation with this string.
    #
    # Examining the `__init__()` function of `MediaManager`, we can see that
    # `col.media.dir()` will only be `None` in the case where `server=True` is
    # passed to the `Collection` constructor. But since we do the construction
    # within ki, we have a guarantee that this will never be true, and thus we
    # can assume it is a nonempty string, which is all we need for the
    # following code to be safe.
    media_dir = F.chk(Path(col.media.dir()))
    if not isinstance(media_dir, Dir):
        raise MissingMediaDirectoryError(col.path, media_dir)

    # Find media files that appear in note fields and copy them to the target.
    query: str = &#34;select * from notes where id in &#34; + strnids
    rows: List[NoteDBRow] = [NoteDBRow(*row) for row in col.db.all(query)]
    rows = TQ(rows, &#34;Media&#34;)
    copy_fn = copy_note_media(col, media_dir, media_target_dir)
    media = {row.nid: copy_fn(row) for row in rows}
    mids = col.db.list(&#34;select distinct mid from notes where id in &#34; + strnids)

    # Copy notetype template media files.
    _, _, files = F.shallow_walk(media_dir)
    paths: Iterable[Path] = map(lambda f: Path(f.name), files)
    paths = set(filter(lambda f: str(f).startswith(&#34;_&#34;), paths))
    models = filter(lambda m: int(m[&#34;id&#34;]) in mids, col.models.all())

    mediasets = map(copy_notetype_media(media_dir, media_target_dir, paths), models)
    media[NOTETYPE_NID] = reduce(lambda x, y: x.union(y), mediasets, set())

    return media


@beartype
def hasmedia(model: NotetypeDict, fname: str) -&gt; bool:
    &#34;&#34;&#34;
    Check if a notetype has media.

    Adapted from `anki.exporting.AnkiExporter._modelHasMedia()`, which is an
    instance method, but does not make any use of `self`, and so could be a
    staticmethod. It is a pure function.
    &#34;&#34;&#34;
    # First check the styling.
    if fname in model[&#34;css&#34;]:
        return True
    # If no reference to fname then check the templates as well.
    return any(map(lambda t: fname in t[&#34;qfmt&#34;] or fname in t[&#34;afmt&#34;], model[&#34;tmpls&#34;]))


@curried
@beartype
def write_fields(root: Dir, n: Note) -&gt; Iterable[Tuple[str, File]]:
    &#34;&#34;&#34;Write a note&#39;s fields to be tidied.&#34;&#34;&#34;
    return filter(None, starmap(write_field(root, n.id), n.items()))


@curried
@beartype
def write_field(
    root: Dir, nid: int, name: str, text: str
) -&gt; Optional[Tuple[str, File]]:
    &#34;&#34;&#34;Write a field to a file (if tidying is needed) given its name and text.&#34;&#34;&#34;
    text: str = html_to_screen(text)
    if re.search(HTML_REGEX, text):
        fid: str = get_field_note_id(nid, name)
        return fid, F.write(F.chk(root / fid), text)
    return None


@beartype
def write_repository(
    col_file: File,
    targetdir: Dir,
    dotki: DotKi,
    media_target_dir: EmptyDir,
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;Write notes to appropriate directories in `targetdir`.&#34;&#34;&#34;
    # Create config file.
    config = configparser.ConfigParser()
    config[&#34;remote&#34;] = {&#34;path&#34;: col_file}
    with open(dotki.config, &#34;w&#34;, encoding=UTF8) as config_f:
        config.write(config_f)

    # Create temp directory for htmlfield text files.
    tempdir: EmptyDir = F.mkdtemp()
    root: EmptyDir = F.mksubdir(tempdir, FIELD_HTML_SUFFIX)

    # ColNote-containing data structure, to be passed to `write_decks()`.
    col: Collection = M.collection(col_file)
    nids: Iterable[int] = TQ(col.find_notes(query=&#34;&#34;), &#34;Notes&#34;)
    colnotes: Dict[int, ColNote] = {nid: M.colnote(col, nid) for nid in nids}
    media: Dict[int, Set[File]] = copy_media_files(col, media_target_dir)
    ns: Iterable[Note] = map(lambda c: c.n, colnotes.values())
    fieldfiles = dict(F.cat(map(write_fields(root), TQ(ns, &#34;Fields&#34;))))
    tidy_html_recursively(root)

    windows_links: Set[WindowsLink] = write_decks(
        col=col,
        targetdir=targetdir,
        colnotes=colnotes,
        media=media,
        tidy_field_files=fieldfiles,
    )

    F.rmtree(root)
    col.close(save=False)

    return windows_links


@beartype
def postorder(node: Union[Root, Deck]) -&gt; List[Deck]:
    &#34;&#34;&#34;
    Post-order traversal. Guarantees that we won&#39;t process a node until we&#39;ve
    processed all its children.
    &#34;&#34;&#34;
    descendants: List[Deck] = reduce(lambda xs, x: xs + postorder(x), node.children, [])
    return descendants if isinstance(node, Root) else descendants + [node]


@beartype
def preorder(node: Union[Root, Deck]) -&gt; List[Deck]:
    &#34;&#34;&#34;
    Pre-order traversal. Guarantees that we won&#39;t process a node until
    we&#39;ve processed all its ancestors.
    &#34;&#34;&#34;
    descendants: List[Deck] = reduce(lambda xs, x: xs + preorder(x), node.children, [])
    return descendants if isinstance(node, Root) else [node] + descendants


@beartype
def write_decks(
    col: Collection,
    targetdir: Dir,
    colnotes: Dict[int, ColNote],
    media: Dict[int, Set[File]],
    tidy_field_files: Dict[str, File],
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;
    The proper way to do this is a DFS traversal, perhaps recursively, which
    will make it easier to keep things purely functional, accumulating the
    model ids of the children in each node. For this, we must construct a tree
    from the deck names.

    Implement new `ColNote`-writing procedure, using `DeckTreeNode`s.

    It must do the following for each deck:
    - create the deck directory
    - write the models.json file
    - create and populate the media directory
    - write the note payload for each note in the correct deck, exactly once

    In other words, for each deck, we need to write all of its:
    - models
    - media
    - notes

    The first two are cumulative: we want the models and media of subdecks to
    be included in their ancestors. The notes, however, should not be
    cumulative. Indeed, we want each note to appear exactly once in the
    entire repository, making allowances for the case where a single note&#39;s
    cards are spread across multiple decks, in which case we must create a
    symlink.

    And actually, both of these cases are nicely taken care of for us by the
    `DeckManager.cids()` function, which has a `children: bool` parameter
    which toggles whether or not to get the card ids of subdecks or not.

    Return all windows symlinks created on Windows whose file modes we must set.
    &#34;&#34;&#34;
    # pylint: disable=too-many-locals
    #
    # Accumulate pairs of model ids and notetype maps. The return type of the
    # `ModelManager.get()` call below indicates that it may return `None`,
    # but we know it will not because we are getting the notetype id straight
    # from the Anki DB.
    #
    # Dump the models file for the whole repository.
    models = {m.id: col.models.get(m.id) for m in col.models.all_names_and_ids()}
    with open(targetdir / MODELS_FILE, &#34;w&#34;, encoding=UTF8) as f:
        json.dump(models, f, ensure_ascii=False, indent=4, sort_keys=True)

    # Construct an iterable of all decks except the trivial deck.
    root: Deck = M.tree(col, targetdir, col.decks.deck_tree())
    collisions, decks = F.part(lambda d: MEDIA in d.fullname, postorder(root))
    if any(True for _ in collisions):
        warn(MediaDirectoryDeckNameCollisionWarning())
    decks = TQ(list(decks), &#34;Decks&#34;)

    # Write cards and models to disk for each deck.
    write = write_deck(col, targetdir, colnotes, tidy_field_files)
    notefiles: Dict[NoteId, CardFileMap] = reduce(write, decks, {})
    do(write_models(col, models), decks)

    # Get all POSIX-style symlinks created on Windows.
    cardfiles = F.cat(F.cat(map(lambda x: x.values(), notefiles.values())))
    links: Iterable[WindowsLink] = set(filter(None, map(lambda c: c.link, cardfiles)))

    return links | symlink_media(col, root, targetdir, media)


@curried
@beartype
def write_deck(
    col: Collection,
    targetd: Dir,
    colnotes: Dict[int, ColNote],
    fieldfiles: Dict[str, File],
    notefiles: Dict[NoteId, CardFileMap],
    deck: Deck,
) -&gt; Dict[NoteId, CardFileMap]:
    &#34;&#34;&#34;Write all the cards to disk for a single deck.&#34;&#34;&#34;
    did: DeckId = deck.did
    cards: Iterable[Card] = map(col.get_card, col.decks.cids(did=did, children=False))
    write = write_card(colnotes, fieldfiles, targetd, deck.deckd)
    return reduce(write, cards, notefiles)


@curried
@beartype
def write_card(
    colnotes: Dict[int, ColNote],
    fieldfiles: Dict[str, File],
    targetd: Dir,
    deckd: Dir,
    notefiles: Dict[NoteId, CardFileMap],
    card: Card,
) -&gt; Dict[NoteId, CardFileMap]:
    &#34;&#34;&#34;Write a single card to disk.&#34;&#34;&#34;
    colnote: ColNote = colnotes[card.nid]
    cardfile_map: Dict[DeckId, List[CardFile]] = notefiles.get(card.nid, {})
    cardfiles: List[CardFile] = cardfile_map.get(card.did, [])
    if len(cardfile_map) == 0:
        payload: str = get_note_payload(colnote, fieldfiles)
        note_path: NoFile = get_note_path(colnote, deckd)
        file, link = F.write(note_path, payload), None
    elif len(cardfiles) &gt; 0:
        file, link = cardfiles[0].file, cardfiles[0].link
    else:
        existing: CardFile = list(cardfile_map.values())[0][0]
        file: File = existing.file
        link: Optional[WindowsLink] = get_link(targetd, colnote, deckd, card, file)
    cardfile = CardFile(card, link=link, file=file)
    return notefiles | {card.nid: cardfile_map | {card.did: cardfiles + [cardfile]}}


@curried
@beartype
def write_models(col: Collection, models: Dict[int, NotetypeDict], deck: Deck) -&gt; None:
    &#34;&#34;&#34;Write the `models.json` file for the given deck.&#34;&#34;&#34;
    did: int = deck.did
    deckd: Dir = deck.deckd
    descendants: List[CardId] = col.decks.cids(did=did, children=True)
    cards: List[Card] = list(map(col.get_card, descendants))
    descendant_mids: Set[int] = {c.note().mid for c in cards}

    # Write `models.json` for current deck.
    deck_models = {mid: models[mid] for mid in descendant_mids}
    with open(deckd / MODELS_FILE, &#34;w&#34;, encoding=UTF8) as f:
        json.dump(deck_models, f, ensure_ascii=False, indent=4, sort_keys=True)


@beartype
def get_link(
    targetd: Dir, colnote: ColNote, deckd: Dir, card: Card, file: File
) -&gt; Optional[WindowsLink]:
    &#34;&#34;&#34;Return a windows link for a card if one is necessary.&#34;&#34;&#34;
    note_path: NoFile = get_note_path(colnote, deckd, card.template()[&#34;name&#34;])
    return M.winlink(targetd, PlannedLink(link=note_path, tgt=file))


@beartype
def parentmap(root: Union[Root, Deck]) -&gt; Dict[str, Union[Root, Deck]]:
    &#34;&#34;&#34;Map deck fullnames to parent `Deck`s.&#34;&#34;&#34;
    parents = {child.fullname: root for child in root.children}
    return parents | reduce(lambda x, y: x | y, map(parentmap, root.children), {})


@curried
@beartype
def planned_link(
    parents: Dict[str, Union[Root, Deck]], deck: Deck, media_file: File
) -&gt; Optional[PlannedLink]:
    &#34;&#34;&#34;Get the target of the to-be-created media symlink.&#34;&#34;&#34;
    link: Path = F.chk(deck.mediad / media_file.name, resolve=False)
    if not isinstance(link, NoFile):
        return None

    parent: Union[Root, Deck] = parents[deck.fullname]
    if isinstance(parent, Root):
        tgt = media_file
    else:
        tgt = F.chk(parent.mediad / media_file.name, resolve=False)
    return PlannedLink(link=link, tgt=tgt)


@curried
@beartype
def symlink_deck_media(
    col: Collection,
    targetd: Dir,
    media: Dict[int, Set[File]],
    parents: Dict[str, Union[Root, Deck]],
    deck: Deck,
) -&gt; Iterable[WindowsLink]:
    &#34;&#34;&#34;Create chained symlinks for a single deck.&#34;&#34;&#34;
    # Get nids for all descendant notes with media.
    descendants: List[CardId] = col.decks.cids(did=deck.did, children=True)
    cards: Iterable[Card] = map(col.get_card, descendants)
    nids: Set[NoteId] = {NOTETYPE_NID} | set(map(lambda c: c.nid, cards))

    # Get link path and target for each media file, and create the links.
    files = F.cat(map(lambda nid: media[nid], filter(lambda nid: nid in media, nids)))
    plinks = filter(None, map(planned_link(parents, deck), files))
    return filter(None, map(M.winlink(targetd), plinks))


@beartype
def symlink_media(
    col: Collection,
    root: Root,
    targetd: Dir,
    media: Dict[int, Set[File]],
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;Chain symlinks up the deck tree into top-level `&lt;collection&gt;/_media/`.&#34;&#34;&#34;
    decks: List[Deck] = preorder(root)
    parents: Dict[str, Union[Root, Deck]] = parentmap(root)
    return set(F.cat(map(symlink_deck_media(col, targetd, media, parents), decks)))


@beartype
def html_to_screen(html: str) -&gt; str:
    &#34;&#34;&#34;
    Convert html for a *single field* into plaintext, to be displayed within a
    markdown file.

    Does very litle (just converts HTML-escaped special characters like `&lt;br&gt;`
    tags or `&amp;nbsp;`s to their UTF-8 equivalents).
    &#34;&#34;&#34;
    html = re.sub(r&#34;\&lt;style\&gt;.*\&lt;\/style\&gt;&#34;, &#34;&#34;, html, flags=re.S)
    plain = html

    # For convenience: Un-escape some common LaTeX constructs.
    plain = plain.replace(r&#34;\\\\&#34;, r&#34;\\&#34;)
    plain = plain.replace(r&#34;\\{&#34;, r&#34;\{&#34;)
    plain = plain.replace(r&#34;\\}&#34;, r&#34;\}&#34;)
    plain = plain.replace(r&#34;\*}&#34;, r&#34;*}&#34;)

    plain = plain.replace(r&#34;&amp;lt;&#34;, &#34;&lt;&#34;)
    plain = plain.replace(r&#34;&amp;gt;&#34;, &#34;&gt;&#34;)
    plain = plain.replace(r&#34;&amp;amp;&#34;, &#34;&amp;&#34;)
    plain = plain.replace(r&#34;&amp;nbsp;&#34;, &#34; &#34;)

    plain = plain.replace(&#34;&lt;br&gt;&#34;, &#34;\n&#34;)
    plain = plain.replace(&#34;&lt;br/&gt;&#34;, &#34;\n&#34;)
    plain = plain.replace(&#34;&lt;br /&gt;&#34;, &#34;\n&#34;)

    # Unbreak lines within src attributes.
    plain = re.sub(&#39;src= ?\n&#34;&#39;, &#39;src=&#34;&#39;, plain)

    plain = re.sub(r&#34;\&lt;b\&gt;\s*\&lt;\/b\&gt;&#34;, &#34;&#34;, plain)
    return plain.strip()


@beartype
def get_note_payload(colnote: ColNote, tidy_field_files: Dict[str, File]) -&gt; str:
    &#34;&#34;&#34;
    Return the markdown-converted contents of the Anki note represented by
    `colnote` as a string.

    Given a `ColNote`, which is a dataclass wrapper around a `Note` object
    which has been loaded from the DB, and a mapping from `fid`s (unique
    identifiers of field-note pairs) to paths, we check for each field of each
    note whether that field&#39;s `fid` is contained in `tidy_field_files`. If so,
    that means that the caller dumped the contents of this field to a file (the
    file with this path, in fact) in order to autoformat the HTML source. If
    this field was tidied/autoformatted, we read from that path to get the
    tidied source, otherwise, we use the field content present in the
    `ColNote`.
    &#34;&#34;&#34;
    # Get tidied html if it exists.
    tidy_fields = {}
    for field_name, field_text in colnote.n.items():
        fid = get_field_note_id(colnote.n.id, field_name)
        if fid in tidy_field_files:
            # HTML5-tidy adds a newline after `&lt;br&gt;` in indent mode, so we
            # remove these, because `html_to_screen()` converts `&lt;br&gt;` tags to
            # newlines anyway.
            tidied_field_text: str = tidy_field_files[fid].read_text(encoding=UTF8)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br&gt;\n&#34;, &#34;\n&#34;)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br/&gt;\n&#34;, &#34;\n&#34;)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br /&gt;\n&#34;, &#34;\n&#34;)
            tidy_fields[field_name] = tidied_field_text
        else:
            tidy_fields[field_name] = field_text

    lines = get_header_lines(colnote)
    for field_name, field_text in tidy_fields.items():
        lines.append(&#34;## &#34; + field_name)
        screen_text = html_to_screen(field_text)
        text = colnote.n.col.media.escape_media_filenames(screen_text, unescape=True)
        lines.append(text)
        lines.append(&#34;&#34;)

    return &#34;\n&#34;.join(lines)


@beartype
def git_pull(remote: str, branch: str, cwd: Dir) -&gt; str:
    &#34;&#34;&#34;Pull remote into branch using a subprocess call.&#34;&#34;&#34;
    args = [&#34;git&#34;, &#34;pull&#34;, &#34;-v&#34;, remote, branch]
    p = subprocess.run(args, check=False, cwd=cwd, capture_output=True)
    return f&#34;{p.stdout.decode()}\n{p.stderr.decode()}&#34;


@beartype
def echo(string: str, silent: bool = False) -&gt; None:
    &#34;&#34;&#34;Call `click.secho()` with formatting.&#34;&#34;&#34;
    if not silent:
        click.secho(string, bold=True)


@beartype
def warn(w: Warning) -&gt; None:
    &#34;&#34;&#34;Call `click.secho()` with formatting (yellow).&#34;&#34;&#34;
    click.secho(f&#34;WARNING: {str(w)}&#34;, bold=True, fg=&#34;yellow&#34;)


@beartype
def tidy_html_recursively(root: Dir) -&gt; None:
    &#34;&#34;&#34;Call html5-tidy on each file in `root`, editing in-place.&#34;&#34;&#34;
    # Spin up subprocesses for tidying field HTML in-place.
    for batch in F.get_batches(F.rglob(root, &#34;*&#34;), BATCH_SIZE):
        command: List[str] = TIDY_CMD.split() + TIDY_OPTS.split() + batch
        try:
            subprocess.run(command, check=False, capture_output=True)
        except FileNotFoundError as err:
            raise MissingTidyExecutableError(err) from err


@beartype
def get_target(cwd: Dir, col_file: File, directory: str) -&gt; Tuple[EmptyDir, bool]:
    &#34;&#34;&#34;Create default target directory.&#34;&#34;&#34;
    path = F.chk(Path(directory) if directory != &#34;&#34; else cwd / col_file.stem)
    new: bool = True
    if isinstance(path, NoPath):
        path.mkdir(parents=True)
        return M.emptydir(path), new
    if isinstance(path, EmptyDir):
        new = False
        return path, new
    raise TargetExistsError(path)


@beartype
def echo_note_change_types(deltas: Iterable[Delta]) -&gt; None:
    &#34;&#34;&#34;Write a table of git change types for notes to stdout.&#34;&#34;&#34;
    # pylint: disable=too-many-locals
    is_change_type = lambda t: lambda d: d.status == t

    vs, ws, xs, ys, zs = tee(deltas, 5)
    adds = list(filter(is_change_type(ADDED), vs))
    deletes = list(filter(is_change_type(DELETED), ws))
    renames = list(filter(is_change_type(RENAMED), xs))
    modifies = list(filter(is_change_type(MODIFIED), ys))
    types = list(filter(is_change_type(TYPECHANGED), zs))

    LPAD, RPAD = 15, 9
    add_info: str = &#34;ADD&#34;.ljust(LPAD) + str(len(adds)).rjust(RPAD)
    delete_info: str = &#34;DELETE&#34;.ljust(LPAD) + str(len(deletes)).rjust(RPAD)
    modification_info: str = &#34;MODIFY&#34;.ljust(LPAD) + str(len(modifies)).rjust(RPAD)
    rename_info: str = &#34;RENAME&#34;.ljust(LPAD) + str(len(renames)).rjust(RPAD)
    type_info: str = &#34;TYPE CHANGE&#34;.ljust(LPAD) + str(len(types)).rjust(RPAD)

    echo(&#34;=&#34; * (LPAD + RPAD))
    echo(&#34;Note change types&#34;)
    echo(&#34;-&#34; * (LPAD + RPAD))
    echo(f&#34;{add_info}\n{delete_info}\n{modification_info}\n{rename_info}\n{type_info}&#34;)
    echo(&#34;=&#34; * (LPAD + RPAD))


@curried
@beartype
def add_model(col: Collection, model: Notetype) -&gt; None:
    &#34;&#34;&#34;Add a model to the database.&#34;&#34;&#34;
    # Check if a model already exists with this name, and get its `mid`.
    mid: Optional[int] = col.models.id_for_name(model.name)

    # TODO: This function is unfinished. We need to add new notetypes (and
    # rename them) only if they are &#39;new&#39;, where new means they are different
    # from anything else already in the DB, in the content-addressed sense. If
    # they are new, then we must indicate that the notes we are adding actually
    # have these new notetypes. For this, it may make sense to use the hash of
    # the notetype everywhere (i.e. in the note file) rather than the name or
    # mid.
    #
    # If a model already exists with this name, parse it, and check if its hash
    # is identical to the model we are trying to add.
    if mid is not None:
        nt: NotetypeDict = col.models.get(mid)

        # If we are trying to add a model that has the exact same content and
        # name as an existing model, skip it.
        existing: Notetype = M.notetype(nt)
        if notetype_json(model) == notetype_json(existing):
            return

        # If the hashes don&#39;t match, then we somehow need to update
        # `decknote.model` for the relevant notes.
        warn(NotetypeCollisionWarning(model, existing))

    nt_copy: NotetypeDict = copy.deepcopy(model.dict)
    nt_copy[&#34;id&#34;] = 0
    changes: OpChangesWithId = col.models.add_dict(nt_copy)
    nt: NotetypeDict = col.models.get(changes.id)
    model: Notetype = M.notetype(nt)
    echo(f&#34;Added model &#39;{model.name}&#39;&#34;)


@beartype
def mediadata(col: Collection, fname: str) -&gt; bytes:
    &#34;&#34;&#34;Get media file content as bytes (empty if missing).&#34;&#34;&#34;
    if not col.media.have(fname):
        return b&#34;&#34;
    path = os.path.join(col.media.dir(), fname)
    try:
        with open(path, &#34;rb&#34;) as f:
            return f.read()
    except OSError:
        return b&#34;&#34;


@beartype
def unquote_diff_path(path: str) -&gt; str:
    &#34;&#34;&#34;Unquote a diff/patch path.&#34;&#34;&#34;
    if len(path) &lt;= 4:
        return path
    if path[0] == &#39;&#34;&#39; and path[-1] == &#39;&#34;&#39;:
        path = path.lstrip(&#39;&#34;&#39;).rstrip(&#39;&#34;&#39;)
    if path[:2] in (&#34;a/&#34;, &#34;b/&#34;):
        path = path[2:]
    return path


@beartype
def get_patches(unsub_repo: git.Repo) -&gt; Iterable[Patch]:
    &#34;&#34;&#34;Get all patches from HEAD to FETCH_HEAD in a flattened git repository.&#34;&#34;&#34;
    raw_unified_patch = unsub_repo.git.diff([&#34;HEAD&#34;, &#34;FETCH_HEAD&#34;], binary=True)

    # Construct patches for every file in the flattenened/unsubmoduled checkout
    # of the revision of the last successful `ki push`. Each patch is the diff
    # between the relevant file in the flattened (all submodules converted to
    # ordinary directories) repository and the same file in the Anki remote (a
    # fresh `ki clone` of the current database).
    patches: List[Patch] = []
    f = io.StringIO()
    with redirect_stdout(f):
        for diff in whatthepatch.parse_patch(raw_unified_patch):
            a_path = unquote_diff_path(diff.header.old_path)
            b_path = unquote_diff_path(diff.header.new_path)
            if a_path == DEV_NULL:
                a_path = b_path
            if b_path == DEV_NULL:
                b_path = a_path
            patch = Patch(Path(a_path), Path(b_path), diff)
            patches.append(patch)
    return patches


@curried
@beartype
def rm_remote_sm(repo: git.Repo, sub: Submodule) -&gt; Submodule:
    &#34;&#34;&#34;Remove submodule directory from given repo.&#34;&#34;&#34;
    if os.path.isdir(F.root(repo) / sub.rel_root):
        repo.git.rm([&#34;-r&#34;, str(sub.rel_root)])
    return sub


@beartype
def has_patch(patch: Patch, sm_rel_root: Path) -&gt; bool:
    &#34;&#34;&#34;Check if patch path is relative to the given root.&#34;&#34;&#34;
    # TODO: We must also treat case where we moved a file into or out of a
    # submodule, but we just do this for now. In this case, we may have
    # `patch.a` not be relative to the submodule root (if we moved a file into
    # the sm dir), or vice-versa.
    a_in_submodule: bool = patch.a.is_relative_to(sm_rel_root)
    b_in_submodule: bool = patch.b.is_relative_to(sm_rel_root)
    return a_in_submodule and b_in_submodule


@curried
@beartype
def apply(subrepos: Dict[Path, Submodule], patch: Patch) -&gt; Iterable[Path]:
    &#34;&#34;&#34;Apply a patch within the relevant submodule repositories.&#34;&#34;&#34;
    # Consider only repos containing patch, ignore submodule &#39;file&#39; itself.
    subs = filter(lambda s: has_patch(patch, s.rel_root), subrepos.values())
    subs = filter(lambda s: s.rel_root not in (patch.a, patch.b), subs)
    patch_dir: Dir = F.mkdtemp()
    return map(apply_in_subrepo(patch_dir, patch), subs)


@curried
@beartype
def apply_in_subrepo(
    patch_dir: Dir,
    patch: Patch,
    sub: Submodule,
) -&gt; Path:
    &#34;&#34;&#34;Apply a patch within a submodule.&#34;&#34;&#34;
    # Hash the patch to use as a filename.
    blake2 = hashlib.blake2s()
    blake2.update(patch.diff.text.encode())
    patch_hash: str = blake2.hexdigest()
    patch_path: NoFile = F.chk(patch_dir / patch_hash)

    # We write as bytes so that it is not necessary to strip trailing linefeeds
    # from each line so that `git apply` is happy on Windows (equivalent to
    # running `dos2unix`).
    patch_b: bytes = patch.diff.text.encode(&#34;UTF-8&#34;)
    F.writeb(patch_path, patch_b)

    # Number of leading path components to drop from diff paths.
    parts: str = str(len(sub.rel_root.parts) + 1)

    # TODO: More tests are needed to make sure that the `git apply` call is not
    # flaky. In particular, we must treat new and deleted files.
    #
    # Note that it is unnecessary to use `--3way` here, because this submodule
    # is supposed to represent a fast-forward from the last successful push to
    # the current state of the remote.  There should be no nontrivial merging
    # involved.
    #
    # Then -p&lt;n&gt; flag tells `git apply` to drop the first n leading path
    # components from both diff paths. So if n is 2, we map `a/dog/cat` -&gt;
    # `cat`.
    sub.sm_repo.git.apply(patch_path, p=parts, allow_empty=True, verbose=True)
    return patch.a


@curried
@beartype
def pull_sm(
    subrepos: Dict[Path, git.Repo],
    sub: Submodule,
) -&gt; Submodule:
    &#34;&#34;&#34;
    Safely pull changes within a submodule.

    New commits in submodules within `lca_repo` are be pulled into the
    submodules within `kirepo.repo`. This is done by adding a remote pointing
    to the patched submodule in each corresponding submodule in the main
    repository, and then pulling from that remote. Then the remote is deleted.
    &#34;&#34;&#34;
    # TODO: What if a submodule was deleted entirely? (Note that we treat the
    # case where submodules are added in the caller.)
    sm_repo = sub.sm_repo
    sm_rel_root = sub.rel_root
    remote_sm: git.Repo = subrepos[sm_rel_root].sm_repo
    branch: str = sub.branch

    # TODO: What&#39;s in `upstream` that isn&#39;t already in `branch`?
    remote_sm.git.branch(&#34;upstream&#34;)

    # Simulate a `git merge --strategy=theirs upstream`.
    remote_sm.git.checkout([&#34;-b&#34;, &#34;tmp&#34;, &#34;upstream&#34;])
    remote_sm.git.merge([&#34;-s&#34;, &#34;ours&#34;, branch])
    remote_sm.git.checkout(branch)
    remote_sm.git.merge(&#34;tmp&#34;)
    remote_sm.git.branch([&#34;-D&#34;, &#34;tmp&#34;])

    sm_remote = sm_repo.create_remote(REMOTE_NAME, F.gitd(remote_sm))
    echo(git_pull(REMOTE_NAME, branch, F.root(sm_repo)))
    sm_repo.delete_remote(sm_remote)
    remote_sm.close()
    sm_repo.close()
    return sub


@beartype
def get_note_metadata(col: Collection) -&gt; Dict[str, NoteMetadata]:
    &#34;&#34;&#34;
    Construct a map from guid -&gt; (nid, mod, mid), adapted from
    `Anki2Importer._import_notes()`. Note that `mod` is the modification
    timestamp, in epoch seconds (timestamp of when the note was last modified).
    &#34;&#34;&#34;
    guids: Dict[str, NoteMetadata] = {}
    for nid, guid, mod, mid in col.db.execute(&#34;select id, guid, mod, mid from notes&#34;):
        guids[guid] = NoteMetadata(nid, mod, mid)
    return guids


@curried
@beartype
def mediabytes(col: Collection, file: File) -&gt; MediaBytes:
    &#34;&#34;&#34;Get old bytes (from collection) and new bytes (from file) for media file.&#34;&#34;&#34;
    old: bytes = mediadata(col, file.name)
    new: bytes = file.read_bytes()
    return MediaBytes(file=file, old=old, new=new)


@curried
@beartype
def addmedia(col: Collection, m: MediaBytes) -&gt; AddedMedia:
    &#34;&#34;&#34;Add a media file to collection (possibly renaming).&#34;&#34;&#34;
    return AddedMedia(file=m.file, new_name=col.media.add_file(m.file))


@beartype
def commit_hashes_file(kirepo: KiRepo) -&gt; None:
    &#34;&#34;&#34;Add and commit hashes file.&#34;&#34;&#34;
    kirepo.repo.index.add(f&#34;{KI}/{HASHES_FILE}&#34;)
    kirepo.repo.index.commit(&#34;Update collection hashes file.&#34;)


@curried
@beartype
def set_120000(repo: git.Repo, root: Dir, abslink: WindowsLink) -&gt; None:
    &#34;&#34;&#34;Use `git update-index` to set 120000 file mode on a windows symlink.&#34;&#34;&#34;
    # Convert to POSIX pathseps since that&#39;s what `git` wants.
    link: str = abslink.relative_to(root).as_posix()
    githash = repo.git.hash_object([&#34;-w&#34;, f&#34;{link}&#34;])
    target = f&#34;120000,{githash},{link}&#34;
    repo.git.update_index(target, add=True, cacheinfo=True)


@curried
@beartype
def backupd(tmpdir: Dir, lca_repo: git.Repo, p: Path) -&gt; Dir:
    &#34;&#34;&#34;Move a relative directory to a temporary location.&#34;&#34;&#34;
    return F.movetree(F.chk(F.root(lca_repo) / p), F.chk(tmpdir / p))


@curried
@beartype
def merge_new_sm(x: Tuple[Dir, Submodule]) -&gt; None:
    &#34;&#34;&#34;Merge backed-up files into a new submodule.&#34;&#34;&#34;
    sm_dir, sm = x
    sm_backup_repo, branch = F.init(sm_dir)
    sm_backup_repo.git.add(all=True)
    sm_backup_repo.index.commit(&#34;Submodule merge&#34;)
    remote = sm.sm_repo.create_remote(&#34;sm-back&#34;, sm_backup_repo.git_dir)
    sm.sm_repo.git.fetch(&#34;sm-back&#34;)
    sm.sm_repo.git.merge(
        [f&#34;sm-back/{branch}&#34;], no_edit=True, allow_unrelated_histories=True
    )
    sm.sm_repo.delete_remote(remote)


@click.group()
@click.version_option()
@beartype
def ki() -&gt; None:
    &#34;&#34;&#34;
    The universal CLI entry point for `ki`.

    Takes no arguments, only has three subcommands (clone, pull, push).
    &#34;&#34;&#34;
    return


@ki.command()
@click.argument(&#34;collection&#34;)
@click.argument(&#34;directory&#34;, required=False, default=&#34;&#34;)
def clone(collection: str, directory: str = &#34;&#34;) -&gt; None:
    &#34;&#34;&#34;
    Clone an Anki collection into a directory.

    Parameters
    ----------
    collection : str
        The path to an `.anki2` collection file.
    directory : str, default=&#34;&#34;
        An optional path to a directory to clone the collection into.
        Note: we check that this directory does not yet exist.
    &#34;&#34;&#34;
    col_file: File = M.xfile(Path(collection))

    @beartype
    def cleanup(targetdir: Dir, new: bool) -&gt; Union[Dir, EmptyDir, NoPath]:
        &#34;&#34;&#34;Cleans up after failed clone operations.&#34;&#34;&#34;
        try:
            if new:
                return F.rmtree(targetdir)
            _, dirs, files = F.shallow_walk(targetdir)
            do(F.rmtree, dirs)
            do(os.remove, files)
        except PermissionError as _:
            pass
        return F.chk(targetdir)

    # Write all files to `targetdir`, and instantiate a `KiRepo` object.
    targetdir, new = get_target(F.cwd(), col_file, directory)
    try:
        _, _ = _clone(col_file, targetdir, msg=&#34;Initial commit&#34;, silent=False)
        kirepo: KiRepo = M.kirepo(targetdir)
        kirepo.repo.create_tag(LCA)
        kirepo.repo.close()
        gc.collect()
    except Exception as err:
        cleanup(targetdir, new)
        raise err


@beartype
def _clone(
    col_file: File,
    targetdir: EmptyDir,
    msg: str,
    silent: bool,
) -&gt; Tuple[git.Repo, str]:
    &#34;&#34;&#34;
    Clone an Anki collection into a directory.

    The caller expects that `targetdir` will be the root of a valid ki
    repository after this function is called, so we need to do our repo
    initialization with gitpython in here, as opposed to in `clone()`.

    Parameters
    ----------
    col_file : pathlib.Path
        The path to an `.anki2` collection file.
    targetdir : pathlib.Path
        A path to a directory to clone the collection into.
        Note: we check that this directory is empty.
    msg : str
        Message for initial commit.
    silent : bool
        Whether to suppress progress information printed to stdout.

    Returns
    -------
    repo : git.Repo
        The cloned repository.
    branch_name : str
        The name of the default branch.
    &#34;&#34;&#34;
    kidir, mediadir = M.empty_kirepo(targetdir)
    dotki: DotKi = M.dotki(kidir)
    md5sum = F.md5(col_file)
    echo(f&#34;Cloning into &#39;{targetdir}&#39;...&#34;, silent=silent)
    (targetdir / GITIGNORE_FILE).write_text(f&#34;{KI}/{BACKUPS_DIR}\n&#34;)

    # Write note files to disk and commit.
    windows_links = write_repository(col_file, targetdir, dotki, mediadir)
    repo, branch = F.init(targetdir)
    F.commitall(repo, msg)
    do(set_120000(repo, F.root(repo)), windows_links)

    # We do *not* call `git.add()` here since we call `git.update_index()` above.
    repo.index.commit(msg)

    # On Windows, there are changes left in the working tree at this point
    # (because git sees that the mode of the actual underlying file is 100644),
    # so we must stash them in order to ensure the repo is not left dirty.
    repo.git.stash(&#34;save&#34;)
    if repo.is_dirty():
        raise NonEmptyWorkingTreeError(repo)

    # Store a checksum of the Anki collection file in the hashes file.
    append_md5sum(kidir, col_file.name, md5sum)

    # Squash last two commits together.
    repo.git.add([KI])
    repo.git.reset([&#34;--soft&#34;, &#34;HEAD~1&#34;])
    repo.git.commit(message=msg, amend=True)

    return repo, branch


@ki.command()
@beartype
def pull() -&gt; None:
    &#34;&#34;&#34;
    Pull from a preconfigured remote Anki collection into an existing ki
    repository.
    &#34;&#34;&#34;
    # Check that we are inside a ki repository, and get the associated collection.
    kirepo: KiRepo = M.kirepo(F.cwd())
    con: sqlite3.Connection = lock(kirepo.col_file)
    md5sum: str = F.md5(kirepo.col_file)
    hashes: List[str] = kirepo.hashes_file.read_text(encoding=UTF8).split(&#34;\n&#34;)
    hashes = list(filter(lambda l: l != &#34;&#34;, hashes))
    if md5sum in hashes[-1]:
        echo(&#34;ki pull: up to date.&#34;)
        return

    _pull(kirepo)
    unlock(con)


@beartype
def _pull(kirepo: KiRepo) -&gt; None:
    &#34;&#34;&#34;
    Pull into `kirepo` without checking if we are already up-to-date.

    Load the git repository at `anki_remote_root`, force pull (preferring
    &#39;theirs&#39;, i.e. the new stuff from the sqlite3 database) changes from that
    repository (which is cloned straight from the collection, which in general
    may have new changes) into `lca_repo`, and then pull `lca_repo` into the
    main repository.

    We pull in this sequence in order to avoid merge conflicts. Since we first
    pull into a snapshot of the repository as it looked when we last pushed to
    the database, we know that there cannot be any merge conflicts, because to
    git, it just looks like we haven&#39;t made any changes since then. Then we
    pull the result of that merge into our actual repository. So there could
    still be merge conflicts at that point, but they will only be &#39;genuine&#39;
    merge conflicts in some sense, because as a result of using this snapshot
    strategy, we give the anki collection the appearance of being a persistent
    remote git repo. If we didn&#39;t do this, the fact that we did a fresh clone
    of the database every time would mean that everything would look like a
    merge conflict, because there is no shared history.

    Parameters
    ----------
    kirepo : KiRepo
        A dataclass representing the Ki repository in the cwd.

    Raises
    ------
    CollectionChecksumError
        If the Anki collection file was modified while pulling changes. This is
        very unlikely, since the caller acquires a lock on the SQLite3
        database.
    &#34;&#34;&#34;
    # pylint: disable=too-many-locals
    md5sum: str = F.md5(kirepo.col_file)

    # Copy `repo` into a temp directory and `reset --hard` at rev of last
    # successful `push()`, which is the last common ancestor, or &#39;LCA&#39;.
    head: Rev = M.head(kirepo.repo)
    rev: Rev = M.rev(kirepo.repo, sha=kirepo.repo.tag(LCA).commit.hexsha)
    lca_repo: git.Repo = cp_repo(rev, f&#34;{LOCAL_SUFFIX}-{md5sum}&#34;)
    unsub_repo: git.Repo = cp_repo(rev, f&#34;unsub-{LOCAL_SUFFIX}-{md5sum}&#34;)

    # Clone collection into a temp directory at `anki_remote_root`.
    anki_remote_root: EmptyDir = F.mksubdir(F.mkdtemp(), REMOTE_SUFFIX / md5sum)
    msg = f&#34;Fetch changes from DB at `{kirepo.col_file}` with md5sum `{md5sum}`&#34;
    remote_repo, branch = _clone(kirepo.col_file, anki_remote_root, msg, silent=False)

    # Create git remote pointing to `remote_repo`, which represents the current
    # state of the Anki SQLite3 database, and pull it into `lca_repo`.
    anki_remote = lca_repo.create_remote(REMOTE_NAME, F.gitd(remote_repo))
    unsub_remote = unsub_repo.create_remote(REMOTE_NAME, F.gitd(remote_repo))

    # =================== NEW PULL ARCHITECTURE ====================
    # Update all submodules in `unsub_repo`. This is critically important,
    # because it essentially &#39;rolls-back&#39; commits made in submodules since the
    # last successful ki push in the main repository. Our `cp_repo()` call does
    # a `reset --hard` to the commit of the last push, but this does *not* do
    # an equivalent rollback for submodules. So they may contain new local
    # changes that we don&#39;t want. Calling `git submodule update` here checks
    # out the commit that *was* recorded in the submodule file at the rev of
    # the last push.
    unsub_repo.git.submodule(&#34;update&#34;)
    lca_repo.git.submodule(&#34;update&#34;)
    unsub_repo = F.unsubmodule(unsub_repo)
    anki_remote.fetch()
    unsub_remote.fetch()
    patches: Iterable[Patch] = get_patches(unsub_repo)

    # Remove submodules from `remote_repo` and map the roots of each submodule
    # (relative to the working directory of `lca_repo`) to the submodule repos
    # themselves.
    subrepos: Dict[Path, Submodule] = M.submodules(lca_repo)
    do(rm_remote_sm(remote_repo), subrepos.values())
    if len(lca_repo.submodules) &gt; 0:
        F.commitall(remote_repo, msg=&#34;Remove submodule directories.&#34;)

    # Apply and commit patches within submodules.
    patch_paths = set(F.cat(map(apply(subrepos), patches)))
    msg = &#34;Applying patches:\n\n&#34; + &#34;&#34;.join(map(lambda p: f&#34;  `{p}`\n&#34;, patch_paths))
    do(lambda s: F.commitall(s.sm_repo, msg), subrepos.values())

    # Pull changes from remote into each submodule.
    sms: Dict[Path, Submodule] = M.submodules(kirepo.repo)
    subs = filter(lambda s: s.rel_root in subrepos, sms.values())
    do(pull_sm(subrepos), subs)

    # Commit new submodules commits in `lca_repo`.
    if len(patch_paths) &gt; 0:
        F.commitall(lca_repo, msg=msg)

    # Handle deleted files, preferring `theirs`.
    diffidx = lca_repo.commit(&#34;HEAD&#34;).diff(lca_repo.commit(&#34;FETCH_HEAD&#34;))
    dels: Iterable[git.Diff] = diffidx.iter_change_type(DELETED.value)
    dels = filter(lambda d: d.a_path != GITMODULES_FILE, dels)
    dels = filter(lambda d: F.isfile(F.chk(F.root(lca_repo) / d.a_path)), dels)
    a_paths: Iterable[str] = set(map(F.git_rm(lca_repo), map(lambda d: d.a_path, dels)))

    if len(a_paths) &gt; 0:
        details: str = &#34;&#34;.join(map(lambda a: f&#34;Remove &#39;{a}&#39;\n&#34;, a_paths))
        F.commitall(lca_repo, msg=f&#34;Remove files deleted in remote.\n\n{details}&#34;)

    # =================== NEW PULL ARCHITECTURE ====================

    # TODO: There is an unsub-like process above performed on `remote_repo`,
    # can we just pass unsub=True here instead?
    remote_root: Dir = F.root(remote_repo)
    lca_repo = M.gitcopy(lca_repo, remote_root, unsub=False)
    F.commitall(lca_repo, f&#34;Pull changes from repository at `{remote_root}`&#34;)

    # For each submodule that is new, `deinit` it.
    new_sms = {k: v for k, v in sms.items() if v.rel_root not in subrepos}
    do(lambda p: kirepo.repo.git.submodule([&#34;deinit&#34;, str(p)]), new_sms.keys())

    # Move all files in the LCA repo that reside in directories corresponding
    # to new submodules into temporary locations, and commit the removals.
    sm_backup_dir: Dir = F.mkdtemp()
    tmps: Set[Dir] = set(map(backupd(sm_backup_dir, lca_repo), new_sms.keys()))
    msg = &#34;&#39;Remove new submodule directories from LCA repo&#39;&#34;
    lca_repo.git.add(all=True)
    lca_repo.git.commit([&#34;--allow-empty&#34;, &#34;-m&#34;, msg])

    # Create remote pointing to `lca_repo` and pull into `repo`. Note
    # that this `git pull` may not always create a merge commit, because a
    # fast-forward only updates the branch pointer.
    lca_remote = kirepo.repo.create_remote(REMOTE_NAME, lca_repo.git_dir)
    kirepo.repo.git.config(&#34;pull.rebase&#34;, &#34;false&#34;)
    out = git_pull(REMOTE_NAME, branch, kirepo.root)
    echo(out)
    kirepo.repo.delete_remote(lca_remote)

    # Submodule sync, `update --init`, and merge backup files.
    sync = lambda p: kirepo.repo.git.submodule([&#34;sync&#34;, str(p)])
    update = lambda p: kirepo.repo.git.submodule([&#34;update&#34;, &#34;--init&#34;, str(p)])
    do(sync, new_sms.keys())
    do(update, new_sms.keys())
    do(merge_new_sm, zip(tmps, new_sms.values()))

    # The merge will have overwritten the hashes file with only the collection
    # hash from the fresh clone of the remote, so we checkout its state from
    # before the merge.
    kirepo.repo.git.checkout([head.sha, &#34;--&#34;, f&#34;{KI}/{HASHES_FILE}&#34;])

    # Raise an error if the collection was modified during pull.
    if F.md5(kirepo.col_file) != md5sum:
        raise CollectionChecksumError(kirepo.col_file)

    # Append the hash of the collection to the hashes file.
    if &#34;Aborting&#34; not in out:
        append_md5sum(kirepo.ki, kirepo.col_file.name, md5sum)
        commit_hashes_file(kirepo)


# PUSH


@ki.command()
@beartype
def push() -&gt; PushResult:
    &#34;&#34;&#34;
    Push a ki repository into a .anki2 file.

    Consists of the following operations:

        - Clone collection into a temp directory
        - Delete all files and folders except `.git/`
        - Copy into this temp directory all files and folders from the current
          repository checked out at HEAD (excluding `.git*` stuff).
        - Unsubmodule repo
        - Add and commit everything
        - Take diff from `HEAD~1` to `HEAD`.

    Returns
    -------
    PushResult
        An `Enum` indicating whether the push was nontrivial.

    Raises
    ------
    UpdatesRejectedError
        If the user needs to pull remote changes first.
    &#34;&#34;&#34;
    # pylint: disable=too-many-locals
    # Check that we are inside a ki repository, and load collection.
    kirepo: KiRepo = M.kirepo(F.cwd())
    con: sqlite3.Connection = lock(kirepo.col_file)

    md5sum: str = F.md5(kirepo.col_file)
    hashes: List[str] = kirepo.hashes_file.read_text(encoding=UTF8).split(&#34;\n&#34;)
    hashes = list(filter(lambda l: l != &#34;&#34;, hashes))
    if md5sum not in hashes[-1]:
        raise UpdatesRejectedError(kirepo.col_file)

    # =================== NEW PUSH ARCHITECTURE ====================
    head_kirepo: KiRepo = cp_ki(M.head_ki(kirepo), f&#34;{HEAD_SUFFIX}-{md5sum}&#34;)
    remote_root: EmptyDir = F.mksubdir(F.mkdtemp(), REMOTE_SUFFIX / md5sum)

    msg = f&#34;Fetch changes from collection &#39;{kirepo.col_file}&#39; with md5sum &#39;{md5sum}&#39;&#34;
    remote_repo, _ = _clone(kirepo.col_file, remote_root, msg, silent=True)

    remote_repo = M.gitcopy(remote_repo, head_kirepo.root, unsub=True)
    F.commitall(remote_repo, f&#34;Pull changes from repository at `{kirepo.root}`&#34;)
    # =================== NEW PUSH ARCHITECTURE ====================

    parse: Callable[[Delta], DeckNote] = parse_note(*M.parser_and_transformer())
    deltas, warnings = F.part(lambda x: isinstance(x, Delta), diff2(remote_repo, parse))
    do(warn, warnings)

    # If there are no changes, quit.
    if len(set(deltas)) == 0:
        echo(&#34;ki push: up to date.&#34;)
        return PushResult.UP_TO_DATE

    echo(f&#34;Pushing to &#39;{kirepo.col_file}&#39;&#34;)
    models: Dict[str, Notetype] = get_models_recursively(head_kirepo)
    return write_collection(deltas, models, kirepo, parse, head_kirepo, con)


@beartype
def write_collection(
    deltas: Iterable[Delta],
    models: Dict[str, Notetype],
    kirepo: KiRepo,
    parse: Callable[[Delta], DeckNote],
    head_kirepo: KiRepo,
    con: sqlite3.Connection,
) -&gt; PushResult:
    &#34;&#34;&#34;Push a list of `Delta`s to an Anki collection.&#34;&#34;&#34;
    # pylint: disable=too-many-locals
    # Copy collection to a temp directory.
    temp_col_dir: Dir = F.mkdtemp()
    new_col_file = temp_col_dir / kirepo.col_file.name
    col_name: str = kirepo.col_file.name
    new_col_file: NoFile = F.chk(temp_col_dir / col_name)
    new_col_file: File = F.copyfile(kirepo.col_file, new_col_file)

    # Open collection and add new models to root `models.json` file.
    col: Collection = M.collection(new_col_file)
    do(add_model(col), models.values())

    # Stash both unstaged and staged files (including untracked).
    head_kirepo.repo.git.stash(include_untracked=True, keep_index=True)
    head_kirepo.repo.git.reset(&#34;HEAD&#34;, hard=True)

    # Display table of note change type counts and partition deltas into
    # &#39;deletes&#39; and &#39;not deletes&#39;.
    xs, ys, zs = tee(deltas, 3)
    echo_note_change_types(xs)
    dels: Iterable[Delta] = filter(lambda d: d.status == DELETED, ys)
    deltas: Iterable[Delta] = filter(lambda d: d.status != DELETED, zs)

    # Map guid -&gt; (nid, mod, mid).
    guids: Dict[str, NoteMetadata] = get_note_metadata(col)

    # Parse to-be-deleted notes and remove them from collection.
    del_guids: Iterable[str] = map(lambda dd: dd.guid, map(parse, dels))
    del_guids = set(filter(lambda g: g in guids, del_guids))
    del_nids: Iterable[NoteId] = map(lambda g: guids[g].nid, del_guids)
    col.remove_notes(list(del_nids))

    # Push changes for all other notes.
    guids = {k: v for k, v in guids.items() if k not in del_guids}
    timestamp_ns: int = time.time_ns()
    new_nids: Iterator[int] = itertools.count(int(timestamp_ns / 1e6))
    decknotes: Iterable[DeckNote] = map(parse, deltas)
    do(warn, F.cat(map(push_note(col, timestamp_ns, guids, new_nids), decknotes)))

    # It is always safe to save changes to the DB, since the DB is a copy.
    col.close(save=True)

    # Backup collection file and overwrite collection.
    backup(kirepo)
    F.copyfile(new_col_file, kirepo.col_file)
    echo(f&#34;Overwrote &#39;{kirepo.col_file}&#39;&#34;)

    # Add media files to collection and follow windows symlinks.
    col: Collection = M.collection(kirepo.col_file)
    media_files = F.rglob(head_kirepo.root, MEDIA_FILE_RECURSIVE_PATTERN)
    media_files = map(M.linktarget, media_files)
    mbytes: Iterable[MediaBytes] = map(mediabytes(col), media_files)

    # Skip media files whose twin in collection has same name and same data.
    mbytes = filter(lambda m: m.old == b&#34;&#34; or m.old != m.new, mbytes)

    # Add (and possibly rename) media paths.
    renames = filter(lambda a: a.file.name != a.new_name, map(addmedia(col), mbytes))
    warnings = map(lambda r: RenamedMediaFileWarning(r.file.name, r.new_name), renames)
    do(warn, warnings)
    col.close(save=True)

    # Append and commit collection checksum to hashes file.
    append_md5sum(kirepo.ki, kirepo.col_file.name, F.md5(kirepo.col_file))
    commit_hashes_file(kirepo)

    # Update commit SHA of most recent successful PUSH and unlock SQLite DB.
    kirepo.repo.delete_tag(LCA)
    kirepo.repo.create_tag(LCA)
    unlock(con)
    return PushResult.NONTRIVIAL</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="ki.functional" href="functional.html">ki.functional</a></code></dt>
<dd>
<div class="desc"><p>Type-safe, non Anki-specific functions.</p></div>
</dd>
<dt><code class="name"><a title="ki.maybes" href="maybes.html">ki.maybes</a></code></dt>
<dd>
<div class="desc"><p>Factory functions for safely handling errors in type construction.</p></div>
</dd>
<dt><code class="name"><a title="ki.transformer" href="transformer.html">ki.transformer</a></code></dt>
<dd>
<div class="desc"><p>A Lark transformer for the ki note grammar.</p></div>
</dd>
<dt><code class="name"><a title="ki.types" href="types.html">ki.types</a></code></dt>
<dd>
<div class="desc"><p>Types for ki.</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ki.add_db_note"><code class="name flex">
<span>def <span class="ident">add_db_note</span></span>(<span>col:Â anki.collection.Collection, nid:Â int, guid:Â str, mid:Â int, mod:Â int, usn:Â int, tags:Â list[str], fields:Â list[str], sfld:Â str, csum:Â int, flags:Â int, data:Â str) â€‘>Â anki.notes.Note</span>
</code></dt>
<dd>
<div class="desc"><p>Add a note to the database directly, with a SQL INSERT.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def add_db_note(
    col: Collection,
    nid: int,
    guid: str,
    mid: int,
    mod: int,
    usn: int,
    tags: List[str],
    fields: List[str],
    sfld: str,
    csum: int,
    flags: int,
    data: str,
) -&gt; Note:
    &#34;&#34;&#34;Add a note to the database directly, with a SQL INSERT.&#34;&#34;&#34;
    importer = NoteImporter(col, &#34;&#34;)
    importer.addNew(
        [
            (
                nid,
                guid,
                mid,
                mod,
                usn,
                &#34; &#34; + &#34; &#34;.join(tags) + &#34; &#34;,
                &#34;\x1f&#34;.join(fields),
                sfld,
                csum,
                flags,
                data,
            )
        ]
    )

    # All the `mark_modified` flag does is update `mod`. Since we always set
    # `mod` to the current timestamp anyway, this doesn&#39;t matter, so may as
    # well set it to `True` to reflect the semantics of the operation we&#39;re
    # performing. This may present issues down the road since newly imported
    # cards from cloned submodules will be marked modified on import/push,
    # which is not exactly right. The anki2 importer does *not* mark as
    # modified, because importing a new note does not modify its content. We
    # would need to have `mod` data inside the note grammar in order for this
    # to make sense, which may be more trouble than it&#39;s worth. Users writing
    # new notes as markdown files would have to set the `mod` to some default
    # value, or leave it blank. Assuming people don&#39;t do this nearly as often
    # as they will export or push notes they&#39;ve created in Anki, then it might
    # make sense.
    col.after_note_updates([nid], mark_modified=True)
    return col.get_note(nid)</code></pre>
</details>
</dd>
<dt id="ki.add_model"><code class="name flex">
<span>def <span class="ident">add_model</span></span>(<span>col:Â anki.collection.Collection, model:Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Add a model to the database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def add_model(col: Collection, model: Notetype) -&gt; None:
    &#34;&#34;&#34;Add a model to the database.&#34;&#34;&#34;
    # Check if a model already exists with this name, and get its `mid`.
    mid: Optional[int] = col.models.id_for_name(model.name)

    # TODO: This function is unfinished. We need to add new notetypes (and
    # rename them) only if they are &#39;new&#39;, where new means they are different
    # from anything else already in the DB, in the content-addressed sense. If
    # they are new, then we must indicate that the notes we are adding actually
    # have these new notetypes. For this, it may make sense to use the hash of
    # the notetype everywhere (i.e. in the note file) rather than the name or
    # mid.
    #
    # If a model already exists with this name, parse it, and check if its hash
    # is identical to the model we are trying to add.
    if mid is not None:
        nt: NotetypeDict = col.models.get(mid)

        # If we are trying to add a model that has the exact same content and
        # name as an existing model, skip it.
        existing: Notetype = M.notetype(nt)
        if notetype_json(model) == notetype_json(existing):
            return

        # If the hashes don&#39;t match, then we somehow need to update
        # `decknote.model` for the relevant notes.
        warn(NotetypeCollisionWarning(model, existing))

    nt_copy: NotetypeDict = copy.deepcopy(model.dict)
    nt_copy[&#34;id&#34;] = 0
    changes: OpChangesWithId = col.models.add_dict(nt_copy)
    nt: NotetypeDict = col.models.get(changes.id)
    model: Notetype = M.notetype(nt)
    echo(f&#34;Added model &#39;{model.name}&#39;&#34;)</code></pre>
</details>
</dd>
<dt id="ki.addmedia"><code class="name flex">
<span>def <span class="ident">addmedia</span></span>(<span>col:Â anki.collection.Collection, m:Â <a title="ki.types.MediaBytes" href="types.html#ki.types.MediaBytes">MediaBytes</a>) â€‘>Â <a title="ki.types.AddedMedia" href="types.html#ki.types.AddedMedia">AddedMedia</a></span>
</code></dt>
<dd>
<div class="desc"><p>Add a media file to collection (possibly renaming).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def addmedia(col: Collection, m: MediaBytes) -&gt; AddedMedia:
    &#34;&#34;&#34;Add a media file to collection (possibly renaming).&#34;&#34;&#34;
    return AddedMedia(file=m.file, new_name=col.media.add_file(m.file))</code></pre>
</details>
</dd>
<dt id="ki.append_md5sum"><code class="name flex">
<span>def <span class="ident">append_md5sum</span></span>(<span>dotki:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, tag:Â str, md5sum:Â str) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Append an md5sum hash to the hashes file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def append_md5sum(dotki: Dir, tag: str, md5sum: str) -&gt; None:
    &#34;&#34;&#34;Append an md5sum hash to the hashes file.&#34;&#34;&#34;
    hashes_file = dotki / HASHES_FILE
    with open(hashes_file, &#34;a+&#34;, encoding=UTF8) as hashes_f:
        hashes_f.write(f&#34;{md5sum}  {tag}\n&#34;)</code></pre>
</details>
</dd>
<dt id="ki.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>subrepos:Â dict[pathlib.Path,Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a>], patch:Â <a title="ki.types.Patch" href="types.html#ki.types.Patch">Patch</a>) â€‘>Â collections.abc.Iterable[pathlib.Path]</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a patch within the relevant submodule repositories.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def apply(subrepos: Dict[Path, Submodule], patch: Patch) -&gt; Iterable[Path]:
    &#34;&#34;&#34;Apply a patch within the relevant submodule repositories.&#34;&#34;&#34;
    # Consider only repos containing patch, ignore submodule &#39;file&#39; itself.
    subs = filter(lambda s: has_patch(patch, s.rel_root), subrepos.values())
    subs = filter(lambda s: s.rel_root not in (patch.a, patch.b), subs)
    patch_dir: Dir = F.mkdtemp()
    return map(apply_in_subrepo(patch_dir, patch), subs)</code></pre>
</details>
</dd>
<dt id="ki.apply_in_subrepo"><code class="name flex">
<span>def <span class="ident">apply_in_subrepo</span></span>(<span>patch_dir:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, patch:Â <a title="ki.types.Patch" href="types.html#ki.types.Patch">Patch</a>, sub:Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a>) â€‘>Â pathlib.Path</span>
</code></dt>
<dd>
<div class="desc"><p>Apply a patch within a submodule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def apply_in_subrepo(
    patch_dir: Dir,
    patch: Patch,
    sub: Submodule,
) -&gt; Path:
    &#34;&#34;&#34;Apply a patch within a submodule.&#34;&#34;&#34;
    # Hash the patch to use as a filename.
    blake2 = hashlib.blake2s()
    blake2.update(patch.diff.text.encode())
    patch_hash: str = blake2.hexdigest()
    patch_path: NoFile = F.chk(patch_dir / patch_hash)

    # We write as bytes so that it is not necessary to strip trailing linefeeds
    # from each line so that `git apply` is happy on Windows (equivalent to
    # running `dos2unix`).
    patch_b: bytes = patch.diff.text.encode(&#34;UTF-8&#34;)
    F.writeb(patch_path, patch_b)

    # Number of leading path components to drop from diff paths.
    parts: str = str(len(sub.rel_root.parts) + 1)

    # TODO: More tests are needed to make sure that the `git apply` call is not
    # flaky. In particular, we must treat new and deleted files.
    #
    # Note that it is unnecessary to use `--3way` here, because this submodule
    # is supposed to represent a fast-forward from the last successful push to
    # the current state of the remote.  There should be no nontrivial merging
    # involved.
    #
    # Then -p&lt;n&gt; flag tells `git apply` to drop the first n leading path
    # components from both diff paths. So if n is 2, we map `a/dog/cat` -&gt;
    # `cat`.
    sub.sm_repo.git.apply(patch_path, p=parts, allow_empty=True, verbose=True)
    return patch.a</code></pre>
</details>
</dd>
<dt id="ki.backup"><code class="name flex">
<span>def <span class="ident">backup</span></span>(<span>kirepo:Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a>) â€‘>Â int</span>
</code></dt>
<dd>
<div class="desc"><p>Backup collection to <code>.ki/backups</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def backup(kirepo: KiRepo) -&gt; int:
    &#34;&#34;&#34;Backup collection to `.ki/backups`.&#34;&#34;&#34;
    md5sum = F.md5(kirepo.col_file)
    name = f&#34;{md5sum}.anki2&#34;
    backup_file = F.chk(kirepo.backups_dir / name)

    # We assume here that no one would ever make e.g. a directory called
    # `name`, since `name` contains the md5sum of the collection file, and
    # thus that is extraordinarily improbable. So the only thing we have to
    # check for is that we haven&#39;t already written a backup file to this
    # location.
    if isinstance(backup_file, File):
        return 1

    F.copyfile(kirepo.col_file, F.chk(kirepo.backups_dir / name))
    return 0</code></pre>
</details>
</dd>
<dt id="ki.backupd"><code class="name flex">
<span>def <span class="ident">backupd</span></span>(<span>tmpdir:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, lca_repo:Â git.repo.base.Repo, p:Â pathlib.Path) â€‘>Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a></span>
</code></dt>
<dd>
<div class="desc"><p>Move a relative directory to a temporary location.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def backupd(tmpdir: Dir, lca_repo: git.Repo, p: Path) -&gt; Dir:
    &#34;&#34;&#34;Move a relative directory to a temporary location.&#34;&#34;&#34;
    return F.movetree(F.chk(F.root(lca_repo) / p), F.chk(tmpdir / p))</code></pre>
</details>
</dd>
<dt id="ki.check_fields_health"><code class="name flex">
<span>def <span class="ident">check_fields_health</span></span>(<span>note:Â anki.notes.Note) â€‘>Â list[Warning]</span>
</code></dt>
<dd>
<div class="desc"><p>Construct warnings when Anki's fields health check fails.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def check_fields_health(note: Note) -&gt; List[Warning]:
    &#34;&#34;&#34;Construct warnings when Anki&#39;s fields health check fails.&#34;&#34;&#34;
    health = note.fields_check()
    if health == 1:
        return [EmptyNoteWarning(note, health)]
    if health == 2:
        return [DuplicateNoteWarning(note, health, html_to_screen(note.fields[0]))]
    if health != 0:
        return [UnhealthyNoteWarning(note, health)]
    return []</code></pre>
</details>
</dd>
<dt id="ki.commit_hashes_file"><code class="name flex">
<span>def <span class="ident">commit_hashes_file</span></span>(<span>kirepo:Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Add and commit hashes file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def commit_hashes_file(kirepo: KiRepo) -&gt; None:
    &#34;&#34;&#34;Add and commit hashes file.&#34;&#34;&#34;
    kirepo.repo.index.add(f&#34;{KI}/{HASHES_FILE}&#34;)
    kirepo.repo.index.commit(&#34;Update collection hashes file.&#34;)</code></pre>
</details>
</dd>
<dt id="ki.copy_media_files"><code class="name flex">
<span>def <span class="ident">copy_media_files</span></span>(<span>col:Â anki.collection.Collection, media_target_dir:Â <a title="ki.types.EmptyDir" href="types.html#ki.types.EmptyDir">EmptyDir</a>) â€‘>Â dict[int,Â set[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get a list of extant media files used in notes and notetypes, copy those
media files to the top-level <code>_media/</code> directory in the repository root,
and return a map sending note ids to sets of copied media files.</p>
<p>Adapted from code in <code>anki/pylib/anki/exporting.py</code>. Specifically, the
<code>AnkiExporter.exportInto()</code> function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>col</code></strong></dt>
<dd>Anki collection.</dd>
<dt><strong><code>media_target_dir</code></strong></dt>
<dd>Where media files are to be copied to.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def copy_media_files(
    col: Collection,
    media_target_dir: EmptyDir,
) -&gt; Dict[int, Set[File]]:
    &#34;&#34;&#34;
    Get a list of extant media files used in notes and notetypes, copy those
    media files to the top-level `_media/` directory in the repository root,
    and return a map sending note ids to sets of copied media files.

    Adapted from code in `anki/pylib/anki/exporting.py`. Specifically, the
    `AnkiExporter.exportInto()` function.

    Parameters
    ----------
    col
        Anki collection.
    media_target_dir
        Where media files are to be copied to.
    &#34;&#34;&#34;
    # All note ids as a string for the SQL query.
    strnids = ids2str(list(col.find_notes(query=&#34;&#34;)))

    # This is the path to the media directory. In the original implementation
    # of `AnkiExporter.exportInto()`, there is check made of the form
    #
    #   if self.mediaDir:
    #
    # before doing path manipulation with this string.
    #
    # Examining the `__init__()` function of `MediaManager`, we can see that
    # `col.media.dir()` will only be `None` in the case where `server=True` is
    # passed to the `Collection` constructor. But since we do the construction
    # within ki, we have a guarantee that this will never be true, and thus we
    # can assume it is a nonempty string, which is all we need for the
    # following code to be safe.
    media_dir = F.chk(Path(col.media.dir()))
    if not isinstance(media_dir, Dir):
        raise MissingMediaDirectoryError(col.path, media_dir)

    # Find media files that appear in note fields and copy them to the target.
    query: str = &#34;select * from notes where id in &#34; + strnids
    rows: List[NoteDBRow] = [NoteDBRow(*row) for row in col.db.all(query)]
    rows = TQ(rows, &#34;Media&#34;)
    copy_fn = copy_note_media(col, media_dir, media_target_dir)
    media = {row.nid: copy_fn(row) for row in rows}
    mids = col.db.list(&#34;select distinct mid from notes where id in &#34; + strnids)

    # Copy notetype template media files.
    _, _, files = F.shallow_walk(media_dir)
    paths: Iterable[Path] = map(lambda f: Path(f.name), files)
    paths = set(filter(lambda f: str(f).startswith(&#34;_&#34;), paths))
    models = filter(lambda m: int(m[&#34;id&#34;]) in mids, col.models.all())

    mediasets = map(copy_notetype_media(media_dir, media_target_dir, paths), models)
    media[NOTETYPE_NID] = reduce(lambda x, y: x.union(y), mediasets, set())

    return media</code></pre>
</details>
</dd>
<dt id="ki.copy_note_media"><code class="name flex">
<span>def <span class="ident">copy_note_media</span></span>(<span>col:Â anki.collection.Collection, src:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, tgt:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, row:Â <a title="ki.types.NoteDBRow" href="types.html#ki.types.NoteDBRow">NoteDBRow</a>) â€‘>Â frozenset[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Copy a single note's media files and return the copies as a set. We do this
by first filtering for only 'rootfiles', i.e. excluding media files in
subdirectories of the media directory. Then we take only those which exist,
i.e. typecheck as <code>File</code>. Then we construct the source and destination
paths, and finally actually perform the copy op, returning the result.</p>
<p>Note that <code>src</code> is the media directory where the files originate, and <code>tgt</code>
is the media directory we're copying to.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def copy_note_media(
    col: Collection, src: Dir, tgt: Dir, row: NoteDBRow
) -&gt; FrozenSet[File]:
    &#34;&#34;&#34;
    Copy a single note&#39;s media files and return the copies as a set. We do this
    by first filtering for only &#39;rootfiles&#39;, i.e. excluding media files in
    subdirectories of the media directory. Then we take only those which exist,
    i.e. typecheck as `File`. Then we construct the source and destination
    paths, and finally actually perform the copy op, returning the result.

    Note that `src` is the media directory where the files originate, and `tgt`
    is the media directory we&#39;re copying to.
    &#34;&#34;&#34;
    files: Iterable[str] = media_filenames_in_field(col, row.flds)
    rootfiles = filter(lambda f: f == os.path.basename(f), files)
    medias: Iterable[File] = filter(F.isfile, map(lambda f: F.chk(src / f), rootfiles))
    srcdsts = map(lambda file: (file, F.chk(tgt / file.name)), medias)
    return frozenset(starmap(F.copyfile, srcdsts))</code></pre>
</details>
</dd>
<dt id="ki.copy_notetype_media"><code class="name flex">
<span>def <span class="ident">copy_notetype_media</span></span>(<span>src:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, tgt:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, paths:Â set[pathlib.Path], m:Â dict[str,Â typing.Any]) â€‘>Â frozenset[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Copy media from notetype <code>m</code> from source to target, returning set of copies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def copy_notetype_media(
    src: Dir, tgt: Dir, paths: Set[Path], m: NotetypeDict
) -&gt; FrozenSet[File]:
    &#34;&#34;&#34;Copy media from notetype `m` from source to target, returning set of copies.&#34;&#34;&#34;
    matches: Iterable[Path] = filter(lambda p: hasmedia(m, str(p)), paths)
    medias = filter(F.isfile, map(lambda p: F.chk(src / p), matches))
    srcdsts = map(lambda f: (f, F.chk(tgt / f.name)), medias)
    return frozenset(starmap(F.copyfile, srcdsts))</code></pre>
</details>
</dd>
<dt id="ki.cp_ki"><code class="name flex">
<span>def <span class="ident">cp_ki</span></span>(<span>ki_rev:Â <a title="ki.types.KiRev" href="types.html#ki.types.KiRev">KiRev</a>, suffix:Â str) â€‘>Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a></span>
</code></dt>
<dd>
<div class="desc"><p>Given a KiRev, i.e. a pair of the form (kirepo, SHA), we clone
<code>kirepo.repo</code> into a temp directory and hard reset to the given commit
hash. Copies the .ki/ directory from <code>ki_rev.kirepo</code> without making any
changes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ki_rev</code></strong> :&ensp;<code>KiRev</code></dt>
<dd>The ki repository to clone, and a commit for it.</dd>
<dt><strong><code>suffix</code></strong> :&ensp;<code>str</code></dt>
<dd>/tmp/&hellip;/ path suffix, e.g. <code>ki/local/</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>KiRepo</code></dt>
<dd>The copied ki repository.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def cp_ki(ki_rev: KiRev, suffix: str) -&gt; KiRepo:
    &#34;&#34;&#34;
    Given a KiRev, i.e. a pair of the form (kirepo, SHA), we clone
    `kirepo.repo` into a temp directory and hard reset to the given commit
    hash. Copies the .ki/ directory from `ki_rev.kirepo` without making any
    changes.

    Parameters
    ----------
    ki_rev : KiRev
        The ki repository to clone, and a commit for it.
    suffix : str
        /tmp/.../ path suffix, e.g. `ki/local/`.

    Returns
    -------
    KiRepo
        The copied ki repository.
    &#34;&#34;&#34;
    rev: Rev = F.ki_rev_to_rev(ki_rev)
    print(F.root(rev.repo))
    ephem: git.Repo = cp_repo(rev, suffix)
    F.force_mkdir(F.root(ephem) / KI / BACKUPS_DIR)
    kirepo: KiRepo = M.kirepo(F.root(ephem))
    return kirepo</code></pre>
</details>
</dd>
<dt id="ki.cp_repo"><code class="name flex">
<span>def <span class="ident">cp_repo</span></span>(<span>rev:Â <a title="ki.types.Rev" href="types.html#ki.types.Rev">Rev</a>, suffix:Â str) â€‘>Â git.repo.base.Repo</span>
</code></dt>
<dd>
<div class="desc"><p>Get a temporary copy of a git repository in /tmp/<suffix>/.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def cp_repo(rev: Rev, suffix: str) -&gt; git.Repo:
    &#34;&#34;&#34;Get a temporary copy of a git repository in /tmp/&lt;suffix&gt;/.&#34;&#34;&#34;
    # Copy the entire repo into a temp directory ending in `../suffix/`.
    target: NoFile = F.chk(F.mkdtemp() / suffix)
    ephem = git.Repo(F.copytree(F.root(rev.repo), target))

    # Do a reset --hard to the given SHA.
    ephem.git.reset(rev.sha, hard=True)
    return ephem</code></pre>
</details>
</dd>
<dt id="ki.diff2"><code class="name flex">
<span>def <span class="ident">diff2</span></span>(<span>repo:Â git.repo.base.Repo, parse:Â collections.abc.Callable[[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>],Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>]) â€‘>Â collections.abc.Iterable[typing.Union[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>,Â Warning]]</span>
</code></dt>
<dd>
<div class="desc"><p>Diff <code>repo</code> from <code>HEAD~1</code> to <code>HEAD</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def diff2(
    repo: git.Repo,
    parse: Callable[[Delta], DeckNote],
) -&gt; Iterable[Union[Delta, Warning]]:
    &#34;&#34;&#34;Diff `repo` from `HEAD~1` to `HEAD`.&#34;&#34;&#34;
    # We diff from A~B.
    head1: Rev = M.rev(repo, repo.commit(&#34;HEAD~1&#34;).hexsha)
    uuid = hex(random.randrange(16**4))[2:]
    head1_repo = cp_repo(head1, suffix=f&#34;HEAD~1-{uuid}&#34;)
    a_root, b_root = F.root(head1_repo), F.root(repo)
    diffidx = repo.commit(&#34;HEAD~1&#34;).diff(repo.commit(&#34;HEAD&#34;))

    # Get the diffs for each change type (e.g. &#39;DELETED&#39;).
    return chain(*map(mungediff(parse, a_root, b_root), diffidx))</code></pre>
</details>
</dd>
<dt id="ki.do"><code class="name flex">
<span>def <span class="ident">do</span></span>(<span>f:Â collections.abc.Callable[[typing.Any],Â typing.Any], xs:Â collections.abc.Iterable[typing.Any]) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Perform some action on an iterable.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def do(f: Callable[[Any], Any], xs: Iterable[Any]) -&gt; None:
    &#34;&#34;&#34;Perform some action on an iterable.&#34;&#34;&#34;
    set(map(f, xs))</code></pre>
</details>
</dd>
<dt id="ki.echo"><code class="name flex">
<span>def <span class="ident">echo</span></span>(<span>string:Â str, silent:Â boolÂ =Â False) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Call <code>click.secho()</code> with formatting.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def echo(string: str, silent: bool = False) -&gt; None:
    &#34;&#34;&#34;Call `click.secho()` with formatting.&#34;&#34;&#34;
    if not silent:
        click.secho(string, bold=True)</code></pre>
</details>
</dd>
<dt id="ki.echo_note_change_types"><code class="name flex">
<span>def <span class="ident">echo_note_change_types</span></span>(<span>deltas:Â collections.abc.Iterable[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>]) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Write a table of git change types for notes to stdout.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def echo_note_change_types(deltas: Iterable[Delta]) -&gt; None:
    &#34;&#34;&#34;Write a table of git change types for notes to stdout.&#34;&#34;&#34;
    # pylint: disable=too-many-locals
    is_change_type = lambda t: lambda d: d.status == t

    vs, ws, xs, ys, zs = tee(deltas, 5)
    adds = list(filter(is_change_type(ADDED), vs))
    deletes = list(filter(is_change_type(DELETED), ws))
    renames = list(filter(is_change_type(RENAMED), xs))
    modifies = list(filter(is_change_type(MODIFIED), ys))
    types = list(filter(is_change_type(TYPECHANGED), zs))

    LPAD, RPAD = 15, 9
    add_info: str = &#34;ADD&#34;.ljust(LPAD) + str(len(adds)).rjust(RPAD)
    delete_info: str = &#34;DELETE&#34;.ljust(LPAD) + str(len(deletes)).rjust(RPAD)
    modification_info: str = &#34;MODIFY&#34;.ljust(LPAD) + str(len(modifies)).rjust(RPAD)
    rename_info: str = &#34;RENAME&#34;.ljust(LPAD) + str(len(renames)).rjust(RPAD)
    type_info: str = &#34;TYPE CHANGE&#34;.ljust(LPAD) + str(len(types)).rjust(RPAD)

    echo(&#34;=&#34; * (LPAD + RPAD))
    echo(&#34;Note change types&#34;)
    echo(&#34;-&#34; * (LPAD + RPAD))
    echo(f&#34;{add_info}\n{delete_info}\n{modification_info}\n{rename_info}\n{type_info}&#34;)
    echo(&#34;=&#34; * (LPAD + RPAD))</code></pre>
</details>
</dd>
<dt id="ki.get_field_note_id"><code class="name flex">
<span>def <span class="ident">get_field_note_id</span></span>(<span>nid:Â int, fieldname:Â str) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>A str ID that uniquely identifies field-note pairs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_field_note_id(nid: int, fieldname: str) -&gt; str:
    &#34;&#34;&#34;A str ID that uniquely identifies field-note pairs.&#34;&#34;&#34;
    return f&#34;{nid}{F.slugify(fieldname)}&#34;</code></pre>
</details>
</dd>
<dt id="ki.get_guid"><code class="name flex">
<span>def <span class="ident">get_guid</span></span>(<span>fields:Â list[str]) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Construct a new GUID for a note. Adapted from genanki's <code>guid_for()</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_guid(fields: List[str]) -&gt; str:
    &#34;&#34;&#34;Construct a new GUID for a note. Adapted from genanki&#39;s `guid_for()`.&#34;&#34;&#34;
    # Get the first 8 bytes of the SHA256 of `contents` as an int.
    m = hashlib.sha256()
    m.update(&#34;__&#34;.join(fields).encode(&#34;utf-8&#34;))
    x = reduce(lambda h, b: (h &lt;&lt; 8) + b, m.digest()[:8], 0)

    # convert to the weird base91 format that Anki uses
    chars = []
    while x &gt; 0:
        chars.append(BASE91_TABLE[x % len(BASE91_TABLE)])
        x //= len(BASE91_TABLE)
    return &#34;&#34;.join(reversed(chars))</code></pre>
</details>
</dd>
<dt id="ki.get_header_lines"><code class="name flex">
<span>def <span class="ident">get_header_lines</span></span>(<span>colnote) â€‘>Â list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Get header of markdown representation of note.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_header_lines(colnote) -&gt; List[str]:
    &#34;&#34;&#34;Get header of markdown representation of note.&#34;&#34;&#34;
    lines = [
        &#34;# Note&#34;,
        &#34;```&#34;,
        f&#34;guid: {colnote.n.guid}&#34;,
        f&#34;notetype: {colnote.notetype.name}&#34;,
        &#34;```&#34;,
        &#34;&#34;,
        &#34;### Tags&#34;,
        &#34;```&#34;,
    ]
    lines += colnote.n.tags
    lines += [&#34;```&#34;, &#34;&#34;]
    return lines</code></pre>
</details>
</dd>
<dt id="ki.get_link"><code class="name flex">
<span>def <span class="ident">get_link</span></span>(<span>targetd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, colnote:Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>, deckd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, card:Â anki.cards.Card, file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>) â€‘>Â Optional[<a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Return a windows link for a card if one is necessary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_link(
    targetd: Dir, colnote: ColNote, deckd: Dir, card: Card, file: File
) -&gt; Optional[WindowsLink]:
    &#34;&#34;&#34;Return a windows link for a card if one is necessary.&#34;&#34;&#34;
    note_path: NoFile = get_note_path(colnote, deckd, card.template()[&#34;name&#34;])
    return M.winlink(targetd, PlannedLink(link=note_path, tgt=file))</code></pre>
</details>
</dd>
<dt id="ki.get_models_recursively"><code class="name flex">
<span>def <span class="ident">get_models_recursively</span></span>(<span>kirepo:Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a>) â€‘>Â dict[str,Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Find and merge all <code>models.json</code> files recursively. Returns a dictionary
sending model names to Notetypes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_models_recursively(kirepo: KiRepo) -&gt; Dict[str, Notetype]:
    &#34;&#34;&#34;
    Find and merge all `models.json` files recursively. Returns a dictionary
    sending model names to Notetypes.
    &#34;&#34;&#34;

    @beartype
    def load(file: File) -&gt; Iterable[Notetype]:
        &#34;&#34;&#34;Load a models file.&#34;&#34;&#34;
        with open(file, &#34;r&#34;, encoding=UTF8) as f:
            return map(M.notetype, json.load(f).values())

    notetypes = F.cat(map(load, F.rglob(kirepo.root, MODELS_FILE)))
    return {notetype.name: notetype for notetype in notetypes}</code></pre>
</details>
</dd>
<dt id="ki.get_note_metadata"><code class="name flex">
<span>def <span class="ident">get_note_metadata</span></span>(<span>col:Â anki.collection.Collection) â€‘>Â dict[str,Â <a title="ki.types.NoteMetadata" href="types.html#ki.types.NoteMetadata">NoteMetadata</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Construct a map from guid -&gt; (nid, mod, mid), adapted from
<code>Anki2Importer._import_notes()</code>. Note that <code>mod</code> is the modification
timestamp, in epoch seconds (timestamp of when the note was last modified).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_note_metadata(col: Collection) -&gt; Dict[str, NoteMetadata]:
    &#34;&#34;&#34;
    Construct a map from guid -&gt; (nid, mod, mid), adapted from
    `Anki2Importer._import_notes()`. Note that `mod` is the modification
    timestamp, in epoch seconds (timestamp of when the note was last modified).
    &#34;&#34;&#34;
    guids: Dict[str, NoteMetadata] = {}
    for nid, guid, mod, mid in col.db.execute(&#34;select id, guid, mod, mid from notes&#34;):
        guids[guid] = NoteMetadata(nid, mod, mid)
    return guids</code></pre>
</details>
</dd>
<dt id="ki.get_note_path"><code class="name flex">
<span>def <span class="ident">get_note_path</span></span>(<span>colnote:Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>, deck_dir:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, card_name:Â strÂ =Â '') â€‘>Â <a title="ki.types.NoFile" href="types.html#ki.types.NoFile">NoFile</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get note path from sort field text.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_note_path(colnote: ColNote, deck_dir: Dir, card_name: str = &#34;&#34;) -&gt; NoFile:
    &#34;&#34;&#34;Get note path from sort field text.&#34;&#34;&#34;
    field_text = colnote.sortf_text

    # Construct filename, stripping HTML tags and sanitizing (quickly).
    field_text = plain_to_html(field_text)
    field_text = re.sub(&#34;&lt;[^&lt;]+?&gt;&#34;, &#34;&#34;, field_text)

    # If the HTML stripping removed all text, we just slugify the raw sort
    # field text.
    if len(field_text) == 0:
        field_text = colnote.sortf_text

    name = field_text[:MAX_FILENAME_LEN]
    slug = F.slugify(name)

    # If the slug is still empty, use all the fields.
    if len(slug) == 0:
        contents = &#34; &#34;.join(colnote.n.values())
        name = contents[:MAX_FILENAME_LEN]
        slug = F.slugify(name)

    # Make it so `slug` cannot possibly be an empty string, because then we get
    # a `Path(&#39;.&#39;)` which is a bug, and causes a runtime exception. If all else
    # fails, use the notetype name, hash of the payload, and creation date.
    if len(slug) == 0:
        blake2 = hashlib.blake2s()
        blake2.update(colnote.n.guid.encode(UTF8))
        slug: str = f&#34;{colnote.notetype.name}--{blake2.hexdigest()}&#34;

        # Note IDs are in milliseconds.
        dt = datetime.datetime.fromtimestamp(colnote.n.id / 1000.0)
        slug += &#34;--&#34; + dt.strftime(&#34;%Y-%m-%d--%Hh-%Mm-%Ss&#34;)
        F.yellow(f&#34;Slug for note with guid &#39;{colnote.n.guid}&#39; is empty...&#34;)
        F.yellow(f&#34;Using blake2 hash of guid as filename: &#39;{slug}&#39;&#34;)

    if card_name != &#34;&#34;:
        slug = f&#34;{slug}_{card_name}&#34;
    filename: str = f&#34;{slug}{MD}&#34;
    note_path = F.chk(deck_dir / filename, resolve=False)

    i = 1
    while not isinstance(note_path, NoFile):
        filename = f&#34;{slug}_{i}{MD}&#34;
        note_path = F.chk(deck_dir / filename, resolve=False)
        i += 1

    return note_path</code></pre>
</details>
</dd>
<dt id="ki.get_note_payload"><code class="name flex">
<span>def <span class="ident">get_note_payload</span></span>(<span>colnote:Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>, tidy_field_files:Â dict[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>]) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Return the markdown-converted contents of the Anki note represented by
<code>colnote</code> as a string.</p>
<p>Given a <code>ColNote</code>, which is a dataclass wrapper around a <code>Note</code> object
which has been loaded from the DB, and a mapping from <code>fid</code>s (unique
identifiers of field-note pairs) to paths, we check for each field of each
note whether that field's <code>fid</code> is contained in <code>tidy_field_files</code>. If so,
that means that the caller dumped the contents of this field to a file (the
file with this path, in fact) in order to autoformat the HTML source. If
this field was tidied/autoformatted, we read from that path to get the
tidied source, otherwise, we use the field content present in the
<code>ColNote</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_note_payload(colnote: ColNote, tidy_field_files: Dict[str, File]) -&gt; str:
    &#34;&#34;&#34;
    Return the markdown-converted contents of the Anki note represented by
    `colnote` as a string.

    Given a `ColNote`, which is a dataclass wrapper around a `Note` object
    which has been loaded from the DB, and a mapping from `fid`s (unique
    identifiers of field-note pairs) to paths, we check for each field of each
    note whether that field&#39;s `fid` is contained in `tidy_field_files`. If so,
    that means that the caller dumped the contents of this field to a file (the
    file with this path, in fact) in order to autoformat the HTML source. If
    this field was tidied/autoformatted, we read from that path to get the
    tidied source, otherwise, we use the field content present in the
    `ColNote`.
    &#34;&#34;&#34;
    # Get tidied html if it exists.
    tidy_fields = {}
    for field_name, field_text in colnote.n.items():
        fid = get_field_note_id(colnote.n.id, field_name)
        if fid in tidy_field_files:
            # HTML5-tidy adds a newline after `&lt;br&gt;` in indent mode, so we
            # remove these, because `html_to_screen()` converts `&lt;br&gt;` tags to
            # newlines anyway.
            tidied_field_text: str = tidy_field_files[fid].read_text(encoding=UTF8)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br&gt;\n&#34;, &#34;\n&#34;)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br/&gt;\n&#34;, &#34;\n&#34;)
            tidied_field_text = tidied_field_text.replace(&#34;&lt;br /&gt;\n&#34;, &#34;\n&#34;)
            tidy_fields[field_name] = tidied_field_text
        else:
            tidy_fields[field_name] = field_text

    lines = get_header_lines(colnote)
    for field_name, field_text in tidy_fields.items():
        lines.append(&#34;## &#34; + field_name)
        screen_text = html_to_screen(field_text)
        text = colnote.n.col.media.escape_media_filenames(screen_text, unescape=True)
        lines.append(text)
        lines.append(&#34;&#34;)

    return &#34;\n&#34;.join(lines)</code></pre>
</details>
</dd>
<dt id="ki.get_patches"><code class="name flex">
<span>def <span class="ident">get_patches</span></span>(<span>unsub_repo:Â git.repo.base.Repo) â€‘>Â collections.abc.Iterable[<a title="ki.types.Patch" href="types.html#ki.types.Patch">Patch</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Get all patches from HEAD to FETCH_HEAD in a flattened git repository.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_patches(unsub_repo: git.Repo) -&gt; Iterable[Patch]:
    &#34;&#34;&#34;Get all patches from HEAD to FETCH_HEAD in a flattened git repository.&#34;&#34;&#34;
    raw_unified_patch = unsub_repo.git.diff([&#34;HEAD&#34;, &#34;FETCH_HEAD&#34;], binary=True)

    # Construct patches for every file in the flattenened/unsubmoduled checkout
    # of the revision of the last successful `ki push`. Each patch is the diff
    # between the relevant file in the flattened (all submodules converted to
    # ordinary directories) repository and the same file in the Anki remote (a
    # fresh `ki clone` of the current database).
    patches: List[Patch] = []
    f = io.StringIO()
    with redirect_stdout(f):
        for diff in whatthepatch.parse_patch(raw_unified_patch):
            a_path = unquote_diff_path(diff.header.old_path)
            b_path = unquote_diff_path(diff.header.new_path)
            if a_path == DEV_NULL:
                a_path = b_path
            if b_path == DEV_NULL:
                b_path = a_path
            patch = Patch(Path(a_path), Path(b_path), diff)
            patches.append(patch)
    return patches</code></pre>
</details>
</dd>
<dt id="ki.get_target"><code class="name flex">
<span>def <span class="ident">get_target</span></span>(<span>cwd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, col_file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>, directory:Â str) â€‘>Â tuple[<a title="ki.types.EmptyDir" href="types.html#ki.types.EmptyDir">EmptyDir</a>,Â bool]</span>
</code></dt>
<dd>
<div class="desc"><p>Create default target directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def get_target(cwd: Dir, col_file: File, directory: str) -&gt; Tuple[EmptyDir, bool]:
    &#34;&#34;&#34;Create default target directory.&#34;&#34;&#34;
    path = F.chk(Path(directory) if directory != &#34;&#34; else cwd / col_file.stem)
    new: bool = True
    if isinstance(path, NoPath):
        path.mkdir(parents=True)
        return M.emptydir(path), new
    if isinstance(path, EmptyDir):
        new = False
        return path, new
    raise TargetExistsError(path)</code></pre>
</details>
</dd>
<dt id="ki.git_pull"><code class="name flex">
<span>def <span class="ident">git_pull</span></span>(<span>remote:Â str, branch:Â str, cwd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Pull remote into branch using a subprocess call.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def git_pull(remote: str, branch: str, cwd: Dir) -&gt; str:
    &#34;&#34;&#34;Pull remote into branch using a subprocess call.&#34;&#34;&#34;
    args = [&#34;git&#34;, &#34;pull&#34;, &#34;-v&#34;, remote, branch]
    p = subprocess.run(args, check=False, cwd=cwd, capture_output=True)
    return f&#34;{p.stdout.decode()}\n{p.stderr.decode()}&#34;</code></pre>
</details>
</dd>
<dt id="ki.has_patch"><code class="name flex">
<span>def <span class="ident">has_patch</span></span>(<span>patch:Â <a title="ki.types.Patch" href="types.html#ki.types.Patch">Patch</a>, sm_rel_root:Â pathlib.Path) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Check if patch path is relative to the given root.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def has_patch(patch: Patch, sm_rel_root: Path) -&gt; bool:
    &#34;&#34;&#34;Check if patch path is relative to the given root.&#34;&#34;&#34;
    # TODO: We must also treat case where we moved a file into or out of a
    # submodule, but we just do this for now. In this case, we may have
    # `patch.a` not be relative to the submodule root (if we moved a file into
    # the sm dir), or vice-versa.
    a_in_submodule: bool = patch.a.is_relative_to(sm_rel_root)
    b_in_submodule: bool = patch.b.is_relative_to(sm_rel_root)
    return a_in_submodule and b_in_submodule</code></pre>
</details>
</dd>
<dt id="ki.hasmedia"><code class="name flex">
<span>def <span class="ident">hasmedia</span></span>(<span>model:Â dict[str,Â typing.Any], fname:Â str) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Check if a notetype has media.</p>
<p>Adapted from <code>anki.exporting.AnkiExporter._modelHasMedia()</code>, which is an
instance method, but does not make any use of <code>self</code>, and so could be a
staticmethod. It is a pure function.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def hasmedia(model: NotetypeDict, fname: str) -&gt; bool:
    &#34;&#34;&#34;
    Check if a notetype has media.

    Adapted from `anki.exporting.AnkiExporter._modelHasMedia()`, which is an
    instance method, but does not make any use of `self`, and so could be a
    staticmethod. It is a pure function.
    &#34;&#34;&#34;
    # First check the styling.
    if fname in model[&#34;css&#34;]:
        return True
    # If no reference to fname then check the templates as well.
    return any(map(lambda t: fname in t[&#34;qfmt&#34;] or fname in t[&#34;afmt&#34;], model[&#34;tmpls&#34;]))</code></pre>
</details>
</dd>
<dt id="ki.html_to_screen"><code class="name flex">
<span>def <span class="ident">html_to_screen</span></span>(<span>html:Â str) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Convert html for a <em>single field</em> into plaintext, to be displayed within a
markdown file.</p>
<p>Does very litle (just converts HTML-escaped special characters like <code>&lt;br&gt;</code>
tags or <code>&amp;nbsp;</code>s to their UTF-8 equivalents).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def html_to_screen(html: str) -&gt; str:
    &#34;&#34;&#34;
    Convert html for a *single field* into plaintext, to be displayed within a
    markdown file.

    Does very litle (just converts HTML-escaped special characters like `&lt;br&gt;`
    tags or `&amp;nbsp;`s to their UTF-8 equivalents).
    &#34;&#34;&#34;
    html = re.sub(r&#34;\&lt;style\&gt;.*\&lt;\/style\&gt;&#34;, &#34;&#34;, html, flags=re.S)
    plain = html

    # For convenience: Un-escape some common LaTeX constructs.
    plain = plain.replace(r&#34;\\\\&#34;, r&#34;\\&#34;)
    plain = plain.replace(r&#34;\\{&#34;, r&#34;\{&#34;)
    plain = plain.replace(r&#34;\\}&#34;, r&#34;\}&#34;)
    plain = plain.replace(r&#34;\*}&#34;, r&#34;*}&#34;)

    plain = plain.replace(r&#34;&amp;lt;&#34;, &#34;&lt;&#34;)
    plain = plain.replace(r&#34;&amp;gt;&#34;, &#34;&gt;&#34;)
    plain = plain.replace(r&#34;&amp;amp;&#34;, &#34;&amp;&#34;)
    plain = plain.replace(r&#34;&amp;nbsp;&#34;, &#34; &#34;)

    plain = plain.replace(&#34;&lt;br&gt;&#34;, &#34;\n&#34;)
    plain = plain.replace(&#34;&lt;br/&gt;&#34;, &#34;\n&#34;)
    plain = plain.replace(&#34;&lt;br /&gt;&#34;, &#34;\n&#34;)

    # Unbreak lines within src attributes.
    plain = re.sub(&#39;src= ?\n&#34;&#39;, &#39;src=&#34;&#39;, plain)

    plain = re.sub(r&#34;\&lt;b\&gt;\s*\&lt;\/b\&gt;&#34;, &#34;&#34;, plain)
    return plain.strip()</code></pre>
</details>
</dd>
<dt id="ki.is_anki_note"><code class="name flex">
<span>def <span class="ident">is_anki_note</span></span>(<span>path:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Check if file is a <code><a title="ki" href="#ki">ki</a></code>-style markdown note.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def is_anki_note(path: File) -&gt; bool:
    &#34;&#34;&#34;Check if file is a `ki`-style markdown note.&#34;&#34;&#34;
    # Ought to have markdown file extension.
    if path.suffix != &#34;.md&#34;:
        return False
    with open(path, &#34;r&#34;, encoding=UTF8) as md_f:
        lines = md_f.readlines()
    if len(lines) &lt; 8:
        return False
    if lines[0] != &#34;# Note\n&#34;:
        return False
    if lines[1] != &#34;```\n&#34;:
        return False
    if not re.match(r&#34;^guid: &#34;, lines[2]):
        return False
    return True</code></pre>
</details>
</dd>
<dt id="ki.is_ignorable"><code class="name flex">
<span>def <span class="ident">is_ignorable</span></span>(<span>root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, path:Â pathlib.Path) â€‘>Â bool</span>
</code></dt>
<dd>
<div class="desc"><p>Filter out paths in a git repository diff that do not correspond to Anki
notes.</p>
<p>We could do this purely using calls to <code><a title="ki.is_anki_note" href="#ki.is_anki_note">is_anki_note()</a></code>, but these are
expensive, so we try to find matches without opening any files first.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def is_ignorable(root: Dir, path: Path) -&gt; bool:
    &#34;&#34;&#34;
    Filter out paths in a git repository diff that do not correspond to Anki
    notes.

    We could do this purely using calls to `is_anki_note()`, but these are
    expensive, so we try to find matches without opening any files first.
    &#34;&#34;&#34;
    # Ignore if `path` is an exact match for any of the patterns Since the
    # contents of a git repository diff are always going to be files, this
    # alone will not correctly ignore directory names given in `patterns`.
    #
    # If any of the patterns in `dirnames` resolve to one of the parents of
    # `path`, return a warning, so that we are able to filter out entire
    # directories.
    filenames, dirnames = IGNORE_FILES, IGNORE_DIRS
    if path.name in filenames | dirnames or len(set(path.parts) &amp; dirnames) &gt; 0:
        return True

    # If `path` is an extant file (not a directory) and *not* a note, ignore it.
    file = F.chk(root / path)
    if isinstance(file, File) and not is_anki_note(file):
        return True
    return False</code></pre>
</details>
</dd>
<dt id="ki.localmedia"><code class="name flex">
<span>def <span class="ident">localmedia</span></span>(<span>s:Â str, regex:Â str) â€‘>Â collections.abc.Iterable[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Return local media filenames matching the given regex pattern.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def localmedia(s: str, regex: str) -&gt; Iterable[str]:
    &#34;&#34;&#34;Return local media filenames matching the given regex pattern.&#34;&#34;&#34;
    fnames = map(lambda m: m.group(&#34;fname&#34;), re.finditer(regex, s))
    fnames = map(lambda s: s.strip(), fnames)
    return filter(lambda x: not re.match(URLS, x.lower()), fnames)</code></pre>
</details>
</dd>
<dt id="ki.lock"><code class="name flex">
<span>def <span class="ident">lock</span></span>(<span>col_file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>) â€‘>Â sqlite3.Connection</span>
</code></dt>
<dd>
<div class="desc"><p>Check that lock can be acquired on a SQLite3 database given a path.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def lock(col_file: File) -&gt; sqlite3.Connection:
    &#34;&#34;&#34;Check that lock can be acquired on a SQLite3 database given a path.&#34;&#34;&#34;
    try:
        con = sqlite3.connect(col_file, timeout=0.1)
        con.isolation_level = &#34;EXCLUSIVE&#34;
        con.execute(&#34;BEGIN EXCLUSIVE&#34;)
    except sqlite3.DatabaseError as err:
        raise SQLiteLockError(col_file, err) from err
    if sys.platform == &#34;win32&#34;:
        con.commit()
        con.close()
    return con</code></pre>
</details>
</dd>
<dt id="ki.media_filenames_in_field"><code class="name flex">
<span>def <span class="ident">media_filenames_in_field</span></span>(<span>col:Â anki.collection.Collection, s:Â str) â€‘>Â collections.abc.Iterable[str]</span>
</code></dt>
<dd>
<div class="desc"><p>A copy of <code>MediaManager.files_in_str()</code>, but without LaTeX rendering.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def media_filenames_in_field(col: Collection, s: str) -&gt; Iterable[str]:
    &#34;&#34;&#34;A copy of `MediaManager.files_in_str()`, but without LaTeX rendering.&#34;&#34;&#34;
    s = (s.strip()).replace(&#39;&#34;&#39;, &#34;&#34;)
    return F.cat(map(localmedia(s), col.media.regexps))</code></pre>
</details>
</dd>
<dt id="ki.mediabytes"><code class="name flex">
<span>def <span class="ident">mediabytes</span></span>(<span>col:Â anki.collection.Collection, file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>) â€‘>Â <a title="ki.types.MediaBytes" href="types.html#ki.types.MediaBytes">MediaBytes</a></span>
</code></dt>
<dd>
<div class="desc"><p>Get old bytes (from collection) and new bytes (from file) for media file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def mediabytes(col: Collection, file: File) -&gt; MediaBytes:
    &#34;&#34;&#34;Get old bytes (from collection) and new bytes (from file) for media file.&#34;&#34;&#34;
    old: bytes = mediadata(col, file.name)
    new: bytes = file.read_bytes()
    return MediaBytes(file=file, old=old, new=new)</code></pre>
</details>
</dd>
<dt id="ki.mediadata"><code class="name flex">
<span>def <span class="ident">mediadata</span></span>(<span>col:Â anki.collection.Collection, fname:Â str) â€‘>Â bytes</span>
</code></dt>
<dd>
<div class="desc"><p>Get media file content as bytes (empty if missing).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def mediadata(col: Collection, fname: str) -&gt; bytes:
    &#34;&#34;&#34;Get media file content as bytes (empty if missing).&#34;&#34;&#34;
    if not col.media.have(fname):
        return b&#34;&#34;
    path = os.path.join(col.media.dir(), fname)
    try:
        with open(path, &#34;rb&#34;) as f:
            return f.read()
    except OSError:
        return b&#34;&#34;</code></pre>
</details>
</dd>
<dt id="ki.merge_new_sm"><code class="name flex">
<span>def <span class="ident">merge_new_sm</span></span>(<span>x:Â tuple[<a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>,Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a>]) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Merge backed-up files into a new submodule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def merge_new_sm(x: Tuple[Dir, Submodule]) -&gt; None:
    &#34;&#34;&#34;Merge backed-up files into a new submodule.&#34;&#34;&#34;
    sm_dir, sm = x
    sm_backup_repo, branch = F.init(sm_dir)
    sm_backup_repo.git.add(all=True)
    sm_backup_repo.index.commit(&#34;Submodule merge&#34;)
    remote = sm.sm_repo.create_remote(&#34;sm-back&#34;, sm_backup_repo.git_dir)
    sm.sm_repo.git.fetch(&#34;sm-back&#34;)
    sm.sm_repo.git.merge(
        [f&#34;sm-back/{branch}&#34;], no_edit=True, allow_unrelated_histories=True
    )
    sm.sm_repo.delete_remote(remote)</code></pre>
</details>
</dd>
<dt id="ki.mungediff"><code class="name flex">
<span>def <span class="ident">mungediff</span></span>(<span>parse:Â collections.abc.Callable[[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>],Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>], a_root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, b_root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, d:Â git.diff.Diff) â€‘>Â collections.abc.Iterable[typing.Union[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>,Â Warning]]</span>
</code></dt>
<dd>
<div class="desc"><p>Extract deltas and warnings from a collection of diffs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def mungediff(
    parse: Callable[[Delta], DeckNote], a_root: Dir, b_root: Dir, d: git.Diff
) -&gt; Iterable[Union[Delta, Warning]]:
    &#34;&#34;&#34;Extract deltas and warnings from a collection of diffs.&#34;&#34;&#34;
    a, b = d.a_path, d.b_path
    a, b = a if a else b, b if b else a
    if is_ignorable(a_root, Path(a)) or is_ignorable(b_root, Path(b)):
        return []

    # Get absolute and relative paths to &#39;a&#39; and &#39;b&#39;.
    AB = namedtuple(&#34;AB&#34;, &#34;a b&#34;)
    files = AB(F.chk(a_root / a), F.chk(b_root / b))
    rels = AB(Path(a), Path(b))

    if d.change_type == DELETED.value:
        if not F.isfile(files.a):
            return [DeletedFileNotFoundWarning(rels.a)]
        return [Delta(GitChangeType.DELETED, files.a, rels.a)]
    if not F.isfile(files.b):
        return [DiffTargetFileNotFoundWarning(rels.b)]
    if d.change_type == RENAMED.value:
        a_delta = Delta(GitChangeType.DELETED, files.a, rels.a)
        b_delta = Delta(GitChangeType.ADDED, files.b, rels.b)
        a_decknote, b_decknote = parse(a_delta), parse(b_delta)
        if a_decknote.guid != b_decknote.guid:
            return [a_delta, b_delta]
    return [Delta(GitChangeType(d.change_type), files.b, rels.b)]</code></pre>
</details>
</dd>
<dt id="ki.parentmap"><code class="name flex">
<span>def <span class="ident">parentmap</span></span>(<span>root:Â Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]) â€‘>Â dict[str,Â typing.Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Map deck fullnames to parent <code>Deck</code>s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def parentmap(root: Union[Root, Deck]) -&gt; Dict[str, Union[Root, Deck]]:
    &#34;&#34;&#34;Map deck fullnames to parent `Deck`s.&#34;&#34;&#34;
    parents = {child.fullname: root for child in root.children}
    return parents | reduce(lambda x, y: x | y, map(parentmap, root.children), {})</code></pre>
</details>
</dd>
<dt id="ki.parse_note"><code class="name flex">
<span>def <span class="ident">parse_note</span></span>(<span>parser:Â lark.lark.Lark, transformer:Â <a title="ki.transformer.NoteTransformer" href="transformer.html#ki.transformer.NoteTransformer">NoteTransformer</a>, delta:Â <a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>) â€‘>Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a></span>
</code></dt>
<dd>
<div class="desc"><p>Parse with lark.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def parse_note(parser: Lark, transformer: NoteTransformer, delta: Delta) -&gt; DeckNote:
    &#34;&#34;&#34;Parse with lark.&#34;&#34;&#34;
    tree = parser.parse(delta.path.read_text(encoding=UTF8))
    flatnote: FlatNote = transformer.transform(tree)
    parts: Tuple[str, ...] = delta.relpath.parent.parts
    deck: str = &#34;::&#34;.join(parts)

    # Generate a GUID from the hash of the field contents if the `guid` field
    # in the note file was left blank.
    fields = list(flatnote.fields.values())
    guid = flatnote.guid if flatnote.guid != &#34;&#34; else get_guid(fields)

    return DeckNote(
        title=flatnote.title,
        guid=guid,
        deck=deck,
        model=flatnote.model,
        tags=flatnote.tags,
        fields=flatnote.fields,
    )</code></pre>
</details>
</dd>
<dt id="ki.plain_to_html"><code class="name flex">
<span>def <span class="ident">plain_to_html</span></span>(<span>plain:Â str) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Convert plain text to html</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def plain_to_html(plain: str) -&gt; str:
    &#34;&#34;&#34;Convert plain text to html&#34;&#34;&#34;
    # Minor clean up
    plain = plain.replace(r&#34;&amp;lt;&#34;, &#34;&lt;&#34;)
    plain = plain.replace(r&#34;&amp;gt;&#34;, &#34;&gt;&#34;)
    plain = plain.replace(r&#34;&amp;amp;&#34;, &#34;&amp;&#34;)
    plain = plain.replace(r&#34;&amp;nbsp;&#34;, &#34; &#34;)
    plain = re.sub(r&#34;\&lt;b\&gt;\s*\&lt;\/b\&gt;&#34;, &#34;&#34;, plain)
    plain = re.sub(r&#34;\&lt;i\&gt;\s*\&lt;\/i\&gt;&#34;, &#34;&#34;, plain)
    plain = re.sub(r&#34;\&lt;div\&gt;\s*\&lt;\/div\&gt;&#34;, &#34;&#34;, plain)

    # Convert newlines to `&lt;br&gt;` tags.
    if not re.search(HTML_REGEX, plain):
        plain = plain.replace(&#34;\n&#34;, &#34;&lt;br&gt;&#34;)

    return plain.strip()</code></pre>
</details>
</dd>
<dt id="ki.planned_link"><code class="name flex">
<span>def <span class="ident">planned_link</span></span>(<span>parents:Â dict[str,Â typing.Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]], deck:Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>, media_file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>) â€‘>Â Optional[<a title="ki.types.PlannedLink" href="types.html#ki.types.PlannedLink">PlannedLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the target of the to-be-created media symlink.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def planned_link(
    parents: Dict[str, Union[Root, Deck]], deck: Deck, media_file: File
) -&gt; Optional[PlannedLink]:
    &#34;&#34;&#34;Get the target of the to-be-created media symlink.&#34;&#34;&#34;
    link: Path = F.chk(deck.mediad / media_file.name, resolve=False)
    if not isinstance(link, NoFile):
        return None

    parent: Union[Root, Deck] = parents[deck.fullname]
    if isinstance(parent, Root):
        tgt = media_file
    else:
        tgt = F.chk(parent.mediad / media_file.name, resolve=False)
    return PlannedLink(link=link, tgt=tgt)</code></pre>
</details>
</dd>
<dt id="ki.postorder"><code class="name flex">
<span>def <span class="ident">postorder</span></span>(<span>node:Â Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]) â€‘>Â list[<a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Post-order traversal. Guarantees that we won't process a node until we've
processed all its children.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def postorder(node: Union[Root, Deck]) -&gt; List[Deck]:
    &#34;&#34;&#34;
    Post-order traversal. Guarantees that we won&#39;t process a node until we&#39;ve
    processed all its children.
    &#34;&#34;&#34;
    descendants: List[Deck] = reduce(lambda xs, x: xs + postorder(x), node.children, [])
    return descendants if isinstance(node, Root) else descendants + [node]</code></pre>
</details>
</dd>
<dt id="ki.preorder"><code class="name flex">
<span>def <span class="ident">preorder</span></span>(<span>node:Â Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]) â€‘>Â list[<a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Pre-order traversal. Guarantees that we won't process a node until
we've processed all its ancestors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def preorder(node: Union[Root, Deck]) -&gt; List[Deck]:
    &#34;&#34;&#34;
    Pre-order traversal. Guarantees that we won&#39;t process a node until
    we&#39;ve processed all its ancestors.
    &#34;&#34;&#34;
    descendants: List[Deck] = reduce(lambda xs, x: xs + preorder(x), node.children, [])
    return descendants if isinstance(node, Root) else [node] + descendants</code></pre>
</details>
</dd>
<dt id="ki.pull_sm"><code class="name flex">
<span>def <span class="ident">pull_sm</span></span>(<span>subrepos:Â dict[pathlib.Path,Â git.repo.base.Repo], sub:Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a>) â€‘>Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a></span>
</code></dt>
<dd>
<div class="desc"><p>Safely pull changes within a submodule.</p>
<p>New commits in submodules within <code>lca_repo</code> are be pulled into the
submodules within <code>kirepo.repo</code>. This is done by adding a remote pointing
to the patched submodule in each corresponding submodule in the main
repository, and then pulling from that remote. Then the remote is deleted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def pull_sm(
    subrepos: Dict[Path, git.Repo],
    sub: Submodule,
) -&gt; Submodule:
    &#34;&#34;&#34;
    Safely pull changes within a submodule.

    New commits in submodules within `lca_repo` are be pulled into the
    submodules within `kirepo.repo`. This is done by adding a remote pointing
    to the patched submodule in each corresponding submodule in the main
    repository, and then pulling from that remote. Then the remote is deleted.
    &#34;&#34;&#34;
    # TODO: What if a submodule was deleted entirely? (Note that we treat the
    # case where submodules are added in the caller.)
    sm_repo = sub.sm_repo
    sm_rel_root = sub.rel_root
    remote_sm: git.Repo = subrepos[sm_rel_root].sm_repo
    branch: str = sub.branch

    # TODO: What&#39;s in `upstream` that isn&#39;t already in `branch`?
    remote_sm.git.branch(&#34;upstream&#34;)

    # Simulate a `git merge --strategy=theirs upstream`.
    remote_sm.git.checkout([&#34;-b&#34;, &#34;tmp&#34;, &#34;upstream&#34;])
    remote_sm.git.merge([&#34;-s&#34;, &#34;ours&#34;, branch])
    remote_sm.git.checkout(branch)
    remote_sm.git.merge(&#34;tmp&#34;)
    remote_sm.git.branch([&#34;-D&#34;, &#34;tmp&#34;])

    sm_remote = sm_repo.create_remote(REMOTE_NAME, F.gitd(remote_sm))
    echo(git_pull(REMOTE_NAME, branch, F.root(sm_repo)))
    sm_repo.delete_remote(sm_remote)
    remote_sm.close()
    sm_repo.close()
    return sub</code></pre>
</details>
</dd>
<dt id="ki.push_note"><code class="name flex">
<span>def <span class="ident">push_note</span></span>(<span>col:Â anki.collection.Collection, timestamp_ns:Â int, guids:Â dict[str,Â <a title="ki.types.NoteMetadata" href="types.html#ki.types.NoteMetadata">NoteMetadata</a>], new_nids:Â collections.abc.Iterator[int], decknote:Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>) â€‘>Â collections.abc.Iterable[Warning]</span>
</code></dt>
<dd>
<div class="desc"><p>Update the Anki <code>Note</code> object in <code>col</code> corresponding to <code>decknote</code>,
creating it if it does not already exist.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>MissingNotetypeError</code></dt>
<dd>If we can't find a notetype with the name provided in <code>decknote</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def push_note(
    col: Collection,
    timestamp_ns: int,
    guids: Dict[str, NoteMetadata],
    new_nids: Iterator[int],
    decknote: DeckNote,
) -&gt; Iterable[Warning]:
    &#34;&#34;&#34;
    Update the Anki `Note` object in `col` corresponding to `decknote`,
    creating it if it does not already exist.

    Raises
    ------
    MissingNotetypeError
        If we can&#39;t find a notetype with the name provided in `decknote`.
    &#34;&#34;&#34;
    # Notetype/model names are privileged in Anki, so if we don&#39;t find the
    # right name, we raise an error.
    model_id: Optional[int] = col.models.id_for_name(decknote.model)
    if model_id is None:
        raise MissingNotetypeError(decknote.model)

    if decknote.guid in guids:
        nid: int = guids[decknote.guid].nid
        try:
            note: Note = col.get_note(nid)
        except NotFoundError as err:
            print(f&#34;{nid = }&#34;)
            print(f&#34;{decknote.guid = }&#34;)
            raise err
    else:
        nid: int = next(new_nids)
        note: Note = add_db_note(
            col,
            nid,
            decknote.guid,
            model_id,
            mod=int(timestamp_ns // 1e9),
            usn=-1,
            tags=decknote.tags,
            fields=list(decknote.fields.values()),
            sfld=&#34;&#34;,
            csum=0,
            flags=0,
            data=&#34;&#34;,
        )

    # If we are updating an existing note, we need to know the old and new
    # notetypes, and then update the notetype (and the rest of the note data)
    # accordingly.
    old_notetype: Notetype = M.notetype(note.note_type())
    new_notetype: Notetype = M.notetype(col.models.get(model_id))
    return update_note(note, decknote, old_notetype, new_notetype)</code></pre>
</details>
</dd>
<dt id="ki.rm_remote_sm"><code class="name flex">
<span>def <span class="ident">rm_remote_sm</span></span>(<span>repo:Â git.repo.base.Repo, sub:Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a>) â€‘>Â <a title="ki.types.Submodule" href="types.html#ki.types.Submodule">Submodule</a></span>
</code></dt>
<dd>
<div class="desc"><p>Remove submodule directory from given repo.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def rm_remote_sm(repo: git.Repo, sub: Submodule) -&gt; Submodule:
    &#34;&#34;&#34;Remove submodule directory from given repo.&#34;&#34;&#34;
    if os.path.isdir(F.root(repo) / sub.rel_root):
        repo.git.rm([&#34;-r&#34;, str(sub.rel_root)])
    return sub</code></pre>
</details>
</dd>
<dt id="ki.set_120000"><code class="name flex">
<span>def <span class="ident">set_120000</span></span>(<span>repo:Â git.repo.base.Repo, root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, abslink:Â <a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Use <code>git update-index</code> to set 120000 file mode on a windows symlink.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def set_120000(repo: git.Repo, root: Dir, abslink: WindowsLink) -&gt; None:
    &#34;&#34;&#34;Use `git update-index` to set 120000 file mode on a windows symlink.&#34;&#34;&#34;
    # Convert to POSIX pathseps since that&#39;s what `git` wants.
    link: str = abslink.relative_to(root).as_posix()
    githash = repo.git.hash_object([&#34;-w&#34;, f&#34;{link}&#34;])
    target = f&#34;120000,{githash},{link}&#34;
    repo.git.update_index(target, add=True, cacheinfo=True)</code></pre>
</details>
</dd>
<dt id="ki.stardo"><code class="name flex">
<span>def <span class="ident">stardo</span></span>(<span>f:Â collections.abc.Callable[[typing.Any],Â typing.Any], xs:Â collections.abc.Iterable[typing.Any]) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Perform some action on an iterable of tuples, unpacking arguments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def stardo(f: Callable[[Any], Any], xs: Iterable[Any]) -&gt; None:
    &#34;&#34;&#34;Perform some action on an iterable of tuples, unpacking arguments.&#34;&#34;&#34;
    set(starmap(f, xs))</code></pre>
</details>
</dd>
<dt id="ki.symlink_deck_media"><code class="name flex">
<span>def <span class="ident">symlink_deck_media</span></span>(<span>col:Â anki.collection.Collection, targetd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, media:Â dict[int,Â set[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]], parents:Â dict[str,Â typing.Union[<a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>,Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>]], deck:Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>) â€‘>Â collections.abc.Iterable[<a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Create chained symlinks for a single deck.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def symlink_deck_media(
    col: Collection,
    targetd: Dir,
    media: Dict[int, Set[File]],
    parents: Dict[str, Union[Root, Deck]],
    deck: Deck,
) -&gt; Iterable[WindowsLink]:
    &#34;&#34;&#34;Create chained symlinks for a single deck.&#34;&#34;&#34;
    # Get nids for all descendant notes with media.
    descendants: List[CardId] = col.decks.cids(did=deck.did, children=True)
    cards: Iterable[Card] = map(col.get_card, descendants)
    nids: Set[NoteId] = {NOTETYPE_NID} | set(map(lambda c: c.nid, cards))

    # Get link path and target for each media file, and create the links.
    files = F.cat(map(lambda nid: media[nid], filter(lambda nid: nid in media, nids)))
    plinks = filter(None, map(planned_link(parents, deck), files))
    return filter(None, map(M.winlink(targetd), plinks))</code></pre>
</details>
</dd>
<dt id="ki.symlink_media"><code class="name flex">
<span>def <span class="ident">symlink_media</span></span>(<span>col:Â anki.collection.Collection, root:Â <a title="ki.types.Root" href="types.html#ki.types.Root">Root</a>, targetd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, media:Â dict[int,Â set[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]]) â€‘>Â set[<a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Chain symlinks up the deck tree into top-level <code>&lt;collection&gt;/_media/</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def symlink_media(
    col: Collection,
    root: Root,
    targetd: Dir,
    media: Dict[int, Set[File]],
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;Chain symlinks up the deck tree into top-level `&lt;collection&gt;/_media/`.&#34;&#34;&#34;
    decks: List[Deck] = preorder(root)
    parents: Dict[str, Union[Root, Deck]] = parentmap(root)
    return set(F.cat(map(symlink_deck_media(col, targetd, media, parents), decks)))</code></pre>
</details>
</dd>
<dt id="ki.tidy_html_recursively"><code class="name flex">
<span>def <span class="ident">tidy_html_recursively</span></span>(<span>root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Call html5-tidy on each file in <code>root</code>, editing in-place.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def tidy_html_recursively(root: Dir) -&gt; None:
    &#34;&#34;&#34;Call html5-tidy on each file in `root`, editing in-place.&#34;&#34;&#34;
    # Spin up subprocesses for tidying field HTML in-place.
    for batch in F.get_batches(F.rglob(root, &#34;*&#34;), BATCH_SIZE):
        command: List[str] = TIDY_CMD.split() + TIDY_OPTS.split() + batch
        try:
            subprocess.run(command, check=False, capture_output=True)
        except FileNotFoundError as err:
            raise MissingTidyExecutableError(err) from err</code></pre>
</details>
</dd>
<dt id="ki.unlock"><code class="name flex">
<span>def <span class="ident">unlock</span></span>(<span>con:Â sqlite3.Connection) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Unlock a SQLite3 database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def unlock(con: sqlite3.Connection) -&gt; None:
    &#34;&#34;&#34;Unlock a SQLite3 database.&#34;&#34;&#34;
    if sys.platform == &#34;win32&#34;:
        return
    con.commit()
    con.close()</code></pre>
</details>
</dd>
<dt id="ki.unquote_diff_path"><code class="name flex">
<span>def <span class="ident">unquote_diff_path</span></span>(<span>path:Â str) â€‘>Â str</span>
</code></dt>
<dd>
<div class="desc"><p>Unquote a diff/patch path.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def unquote_diff_path(path: str) -&gt; str:
    &#34;&#34;&#34;Unquote a diff/patch path.&#34;&#34;&#34;
    if len(path) &lt;= 4:
        return path
    if path[0] == &#39;&#34;&#39; and path[-1] == &#39;&#34;&#39;:
        path = path.lstrip(&#39;&#34;&#39;).rstrip(&#39;&#34;&#39;)
    if path[:2] in (&#34;a/&#34;, &#34;b/&#34;):
        path = path[2:]
    return path</code></pre>
</details>
</dd>
<dt id="ki.update_field"><code class="name flex">
<span>def <span class="ident">update_field</span></span>(<span>decknote:Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>, note:Â anki.notes.Note, key:Â str, field:Â str) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Update a field contained in <code>note</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def update_field(decknote: DeckNote, note: Note, key: str, field: str) -&gt; None:
    &#34;&#34;&#34;Update a field contained in `note`.&#34;&#34;&#34;
    try:
        note[key] = plain_to_html(field)
    except IndexError as err:
        raise AnkiDBNoteMissingFieldsError(decknote, note.id, key) from err</code></pre>
</details>
</dd>
<dt id="ki.update_note"><code class="name flex">
<span>def <span class="ident">update_note</span></span>(<span>note:Â anki.notes.Note, decknote:Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>, old_notetype:Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>, new_notetype:Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>) â€‘>Â collections.abc.Iterable[Warning]</span>
</code></dt>
<dd>
<div class="desc"><p>Change all the data of <code>note</code> to that given in <code>decknote</code>.</p>
<p>This is only to be called on notes whose nid already exists in the
database.
Creates a new deck if <code>decknote.deck</code> doesn't exist.
Assumes
that the model has already been added to the collection, and raises an
exception if it finds otherwise.
Changes notetype to that specified by
<code>decknote.model</code>.
Overwrites all fields with <code>decknote.fields</code>.</p>
<p>Updates:
- tags
- deck
- model
- fields</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def update_note(
    note: Note, decknote: DeckNote, old_notetype: Notetype, new_notetype: Notetype
) -&gt; Iterable[Warning]:
    &#34;&#34;&#34;
    Change all the data of `note` to that given in `decknote`.

    This is only to be called on notes whose nid already exists in the
    database.  Creates a new deck if `decknote.deck` doesn&#39;t exist.  Assumes
    that the model has already been added to the collection, and raises an
    exception if it finds otherwise.  Changes notetype to that specified by
    `decknote.model`.  Overwrites all fields with `decknote.fields`.

    Updates:
    - tags
    - deck
    - model
    - fields
    &#34;&#34;&#34;

    # Check that the passed argument `new_notetype` has a name consistent with
    # the model specified in `decknote`. The former should be derived from the
    # latter, and if they don&#39;t match, there is a bug in the caller.
    if decknote.model != new_notetype.name:
        raise NotetypeMismatchError(decknote, new_notetype)

    nid = note.id
    note.tags = decknote.tags
    note.flush()

    # Set the deck of the given note, as well as all its cards, and create a
    # deck with this name if it doesn&#39;t already exist. See the
    # comments/docstrings in the implementation of the
    # `anki.decks.DeckManager.id()` method.
    newdid: int = note.col.decks.id(decknote.deck, create=True)
    cids = [c.id for c in note.cards()]
    if cids:
        note.col.set_deck(cids, newdid)

    # Set notetype (also clears all fields).
    if old_notetype.id != new_notetype.id:
        fmap = {field.ord: None for field in old_notetype.flds}
        note.col.models.change(old_notetype.dict, [nid], new_notetype.dict, fmap, None)
        note.load()

    # Validate field keys against notetype.
    warnings: List[Warning] = validate_decknote_fields(new_notetype, decknote)
    if len(warnings) &gt; 0:
        return warnings

    # Set field values and flush to collection database. This is correct
    # because every field name that appears in `new_notetype` is contained in
    # `decknote.fields`, or else we would have printed a warning and returned
    # above.
    missing = {key for key in decknote.fields if key not in note}
    warnings = map(lambda k: NoteFieldValidationWarning(nid, k, new_notetype), missing)
    fields = [(key, field) for key, field in decknote.fields.items() if key in note]
    stardo(update_field(decknote, note), fields)
    note.flush()

    # Remove if unhealthy.
    fwarns: List[Warning] = check_fields_health(note)
    if len(fwarns) &gt; 0:
        note.col.remove_notes([nid])
    return chain(warnings, fwarns)</code></pre>
</details>
</dd>
<dt id="ki.validate_decknote_fields"><code class="name flex">
<span>def <span class="ident">validate_decknote_fields</span></span>(<span>notetype:Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>, decknote:Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>) â€‘>Â list[Warning]</span>
</code></dt>
<dd>
<div class="desc"><p>Validate that the fields given in the note match the notetype.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def validate_decknote_fields(notetype: Notetype, decknote: DeckNote) -&gt; List[Warning]:
    &#34;&#34;&#34;Validate that the fields given in the note match the notetype.&#34;&#34;&#34;
    warnings: List[Warning] = []
    names: List[str] = [field.name for field in notetype.flds]

    # TODO: It might also be nice to print the path of the note in the
    # repository. This would have to be added to the `DeckNote` spec.
    if len(decknote.fields.keys()) != len(names):
        warnings.append(WrongFieldCountWarning(decknote, names))

    mk_warning = lambda n, k: InconsistentFieldNamesWarning(n, k, decknote)
    names_and_keys = F.starfilter(
        lambda n, k: n != k, zip(names, decknote.fields.keys())
    )
    return warnings + list(starmap(mk_warning, names_and_keys))</code></pre>
</details>
</dd>
<dt id="ki.warn"><code class="name flex">
<span>def <span class="ident">warn</span></span>(<span>w:Â Warning) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Call <code>click.secho()</code> with formatting (yellow).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def warn(w: Warning) -&gt; None:
    &#34;&#34;&#34;Call `click.secho()` with formatting (yellow).&#34;&#34;&#34;
    click.secho(f&#34;WARNING: {str(w)}&#34;, bold=True, fg=&#34;yellow&#34;)</code></pre>
</details>
</dd>
<dt id="ki.write_card"><code class="name flex">
<span>def <span class="ident">write_card</span></span>(<span>colnotes:Â dict[int,Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>], fieldfiles:Â dict[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>], targetd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, deckd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, notefiles:Â dict[int,Â dict[int,Â list[<a title="ki.types.CardFile" href="types.html#ki.types.CardFile">CardFile</a>]]], card:Â anki.cards.Card) â€‘>Â dict[int,Â dict[int,Â list[<a title="ki.types.CardFile" href="types.html#ki.types.CardFile">CardFile</a>]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Write a single card to disk.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def write_card(
    colnotes: Dict[int, ColNote],
    fieldfiles: Dict[str, File],
    targetd: Dir,
    deckd: Dir,
    notefiles: Dict[NoteId, CardFileMap],
    card: Card,
) -&gt; Dict[NoteId, CardFileMap]:
    &#34;&#34;&#34;Write a single card to disk.&#34;&#34;&#34;
    colnote: ColNote = colnotes[card.nid]
    cardfile_map: Dict[DeckId, List[CardFile]] = notefiles.get(card.nid, {})
    cardfiles: List[CardFile] = cardfile_map.get(card.did, [])
    if len(cardfile_map) == 0:
        payload: str = get_note_payload(colnote, fieldfiles)
        note_path: NoFile = get_note_path(colnote, deckd)
        file, link = F.write(note_path, payload), None
    elif len(cardfiles) &gt; 0:
        file, link = cardfiles[0].file, cardfiles[0].link
    else:
        existing: CardFile = list(cardfile_map.values())[0][0]
        file: File = existing.file
        link: Optional[WindowsLink] = get_link(targetd, colnote, deckd, card, file)
    cardfile = CardFile(card, link=link, file=file)
    return notefiles | {card.nid: cardfile_map | {card.did: cardfiles + [cardfile]}}</code></pre>
</details>
</dd>
<dt id="ki.write_collection"><code class="name flex">
<span>def <span class="ident">write_collection</span></span>(<span>deltas:Â collections.abc.Iterable[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>], models:Â dict[str,Â <a title="ki.types.Notetype" href="types.html#ki.types.Notetype">Notetype</a>], kirepo:Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a>, parse:Â collections.abc.Callable[[<a title="ki.types.Delta" href="types.html#ki.types.Delta">Delta</a>],Â <a title="ki.types.DeckNote" href="types.html#ki.types.DeckNote">DeckNote</a>], head_kirepo:Â <a title="ki.types.KiRepo" href="types.html#ki.types.KiRepo">KiRepo</a>, con:Â sqlite3.Connection) â€‘>Â <a title="ki.types.PushResult" href="types.html#ki.types.PushResult">PushResult</a></span>
</code></dt>
<dd>
<div class="desc"><p>Push a list of <code>Delta</code>s to an Anki collection.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def write_collection(
    deltas: Iterable[Delta],
    models: Dict[str, Notetype],
    kirepo: KiRepo,
    parse: Callable[[Delta], DeckNote],
    head_kirepo: KiRepo,
    con: sqlite3.Connection,
) -&gt; PushResult:
    &#34;&#34;&#34;Push a list of `Delta`s to an Anki collection.&#34;&#34;&#34;
    # pylint: disable=too-many-locals
    # Copy collection to a temp directory.
    temp_col_dir: Dir = F.mkdtemp()
    new_col_file = temp_col_dir / kirepo.col_file.name
    col_name: str = kirepo.col_file.name
    new_col_file: NoFile = F.chk(temp_col_dir / col_name)
    new_col_file: File = F.copyfile(kirepo.col_file, new_col_file)

    # Open collection and add new models to root `models.json` file.
    col: Collection = M.collection(new_col_file)
    do(add_model(col), models.values())

    # Stash both unstaged and staged files (including untracked).
    head_kirepo.repo.git.stash(include_untracked=True, keep_index=True)
    head_kirepo.repo.git.reset(&#34;HEAD&#34;, hard=True)

    # Display table of note change type counts and partition deltas into
    # &#39;deletes&#39; and &#39;not deletes&#39;.
    xs, ys, zs = tee(deltas, 3)
    echo_note_change_types(xs)
    dels: Iterable[Delta] = filter(lambda d: d.status == DELETED, ys)
    deltas: Iterable[Delta] = filter(lambda d: d.status != DELETED, zs)

    # Map guid -&gt; (nid, mod, mid).
    guids: Dict[str, NoteMetadata] = get_note_metadata(col)

    # Parse to-be-deleted notes and remove them from collection.
    del_guids: Iterable[str] = map(lambda dd: dd.guid, map(parse, dels))
    del_guids = set(filter(lambda g: g in guids, del_guids))
    del_nids: Iterable[NoteId] = map(lambda g: guids[g].nid, del_guids)
    col.remove_notes(list(del_nids))

    # Push changes for all other notes.
    guids = {k: v for k, v in guids.items() if k not in del_guids}
    timestamp_ns: int = time.time_ns()
    new_nids: Iterator[int] = itertools.count(int(timestamp_ns / 1e6))
    decknotes: Iterable[DeckNote] = map(parse, deltas)
    do(warn, F.cat(map(push_note(col, timestamp_ns, guids, new_nids), decknotes)))

    # It is always safe to save changes to the DB, since the DB is a copy.
    col.close(save=True)

    # Backup collection file and overwrite collection.
    backup(kirepo)
    F.copyfile(new_col_file, kirepo.col_file)
    echo(f&#34;Overwrote &#39;{kirepo.col_file}&#39;&#34;)

    # Add media files to collection and follow windows symlinks.
    col: Collection = M.collection(kirepo.col_file)
    media_files = F.rglob(head_kirepo.root, MEDIA_FILE_RECURSIVE_PATTERN)
    media_files = map(M.linktarget, media_files)
    mbytes: Iterable[MediaBytes] = map(mediabytes(col), media_files)

    # Skip media files whose twin in collection has same name and same data.
    mbytes = filter(lambda m: m.old == b&#34;&#34; or m.old != m.new, mbytes)

    # Add (and possibly rename) media paths.
    renames = filter(lambda a: a.file.name != a.new_name, map(addmedia(col), mbytes))
    warnings = map(lambda r: RenamedMediaFileWarning(r.file.name, r.new_name), renames)
    do(warn, warnings)
    col.close(save=True)

    # Append and commit collection checksum to hashes file.
    append_md5sum(kirepo.ki, kirepo.col_file.name, F.md5(kirepo.col_file))
    commit_hashes_file(kirepo)

    # Update commit SHA of most recent successful PUSH and unlock SQLite DB.
    kirepo.repo.delete_tag(LCA)
    kirepo.repo.create_tag(LCA)
    unlock(con)
    return PushResult.NONTRIVIAL</code></pre>
</details>
</dd>
<dt id="ki.write_deck"><code class="name flex">
<span>def <span class="ident">write_deck</span></span>(<span>col:Â anki.collection.Collection, targetd:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, colnotes:Â dict[int,Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>], fieldfiles:Â dict[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>], notefiles:Â dict[int,Â dict[int,Â list[<a title="ki.types.CardFile" href="types.html#ki.types.CardFile">CardFile</a>]]], deck:Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>) â€‘>Â dict[int,Â dict[int,Â list[<a title="ki.types.CardFile" href="types.html#ki.types.CardFile">CardFile</a>]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Write all the cards to disk for a single deck.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def write_deck(
    col: Collection,
    targetd: Dir,
    colnotes: Dict[int, ColNote],
    fieldfiles: Dict[str, File],
    notefiles: Dict[NoteId, CardFileMap],
    deck: Deck,
) -&gt; Dict[NoteId, CardFileMap]:
    &#34;&#34;&#34;Write all the cards to disk for a single deck.&#34;&#34;&#34;
    did: DeckId = deck.did
    cards: Iterable[Card] = map(col.get_card, col.decks.cids(did=did, children=False))
    write = write_card(colnotes, fieldfiles, targetd, deck.deckd)
    return reduce(write, cards, notefiles)</code></pre>
</details>
</dd>
<dt id="ki.write_decks"><code class="name flex">
<span>def <span class="ident">write_decks</span></span>(<span>col:Â anki.collection.Collection, targetdir:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, colnotes:Â dict[int,Â <a title="ki.types.ColNote" href="types.html#ki.types.ColNote">ColNote</a>], media:Â dict[int,Â set[<a title="ki.types.File" href="types.html#ki.types.File">File</a>]], tidy_field_files:Â dict[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>]) â€‘>Â set[<a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>The proper way to do this is a DFS traversal, perhaps recursively, which
will make it easier to keep things purely functional, accumulating the
model ids of the children in each node. For this, we must construct a tree
from the deck names.</p>
<p>Implement new <code>ColNote</code>-writing procedure, using <code>DeckTreeNode</code>s.</p>
<p>It must do the following for each deck:
- create the deck directory
- write the models.json file
- create and populate the media directory
- write the note payload for each note in the correct deck, exactly once</p>
<p>In other words, for each deck, we need to write all of its:
- models
- media
- notes</p>
<p>The first two are cumulative: we want the models and media of subdecks to
be included in their ancestors. The notes, however, should not be
cumulative. Indeed, we want each note to appear exactly once in the
entire repository, making allowances for the case where a single note's
cards are spread across multiple decks, in which case we must create a
symlink.</p>
<p>And actually, both of these cases are nicely taken care of for us by the
<code>DeckManager.cids()</code> function, which has a <code>children: bool</code> parameter
which toggles whether or not to get the card ids of subdecks or not.</p>
<p>Return all windows symlinks created on Windows whose file modes we must set.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def write_decks(
    col: Collection,
    targetdir: Dir,
    colnotes: Dict[int, ColNote],
    media: Dict[int, Set[File]],
    tidy_field_files: Dict[str, File],
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;
    The proper way to do this is a DFS traversal, perhaps recursively, which
    will make it easier to keep things purely functional, accumulating the
    model ids of the children in each node. For this, we must construct a tree
    from the deck names.

    Implement new `ColNote`-writing procedure, using `DeckTreeNode`s.

    It must do the following for each deck:
    - create the deck directory
    - write the models.json file
    - create and populate the media directory
    - write the note payload for each note in the correct deck, exactly once

    In other words, for each deck, we need to write all of its:
    - models
    - media
    - notes

    The first two are cumulative: we want the models and media of subdecks to
    be included in their ancestors. The notes, however, should not be
    cumulative. Indeed, we want each note to appear exactly once in the
    entire repository, making allowances for the case where a single note&#39;s
    cards are spread across multiple decks, in which case we must create a
    symlink.

    And actually, both of these cases are nicely taken care of for us by the
    `DeckManager.cids()` function, which has a `children: bool` parameter
    which toggles whether or not to get the card ids of subdecks or not.

    Return all windows symlinks created on Windows whose file modes we must set.
    &#34;&#34;&#34;
    # pylint: disable=too-many-locals
    #
    # Accumulate pairs of model ids and notetype maps. The return type of the
    # `ModelManager.get()` call below indicates that it may return `None`,
    # but we know it will not because we are getting the notetype id straight
    # from the Anki DB.
    #
    # Dump the models file for the whole repository.
    models = {m.id: col.models.get(m.id) for m in col.models.all_names_and_ids()}
    with open(targetdir / MODELS_FILE, &#34;w&#34;, encoding=UTF8) as f:
        json.dump(models, f, ensure_ascii=False, indent=4, sort_keys=True)

    # Construct an iterable of all decks except the trivial deck.
    root: Deck = M.tree(col, targetdir, col.decks.deck_tree())
    collisions, decks = F.part(lambda d: MEDIA in d.fullname, postorder(root))
    if any(True for _ in collisions):
        warn(MediaDirectoryDeckNameCollisionWarning())
    decks = TQ(list(decks), &#34;Decks&#34;)

    # Write cards and models to disk for each deck.
    write = write_deck(col, targetdir, colnotes, tidy_field_files)
    notefiles: Dict[NoteId, CardFileMap] = reduce(write, decks, {})
    do(write_models(col, models), decks)

    # Get all POSIX-style symlinks created on Windows.
    cardfiles = F.cat(F.cat(map(lambda x: x.values(), notefiles.values())))
    links: Iterable[WindowsLink] = set(filter(None, map(lambda c: c.link, cardfiles)))

    return links | symlink_media(col, root, targetdir, media)</code></pre>
</details>
</dd>
<dt id="ki.write_field"><code class="name flex">
<span>def <span class="ident">write_field</span></span>(<span>root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, nid:Â int, name:Â str, text:Â str) â€‘>Â Optional[tuple[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Write a field to a file (if tidying is needed) given its name and text.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def write_field(
    root: Dir, nid: int, name: str, text: str
) -&gt; Optional[Tuple[str, File]]:
    &#34;&#34;&#34;Write a field to a file (if tidying is needed) given its name and text.&#34;&#34;&#34;
    text: str = html_to_screen(text)
    if re.search(HTML_REGEX, text):
        fid: str = get_field_note_id(nid, name)
        return fid, F.write(F.chk(root / fid), text)
    return None</code></pre>
</details>
</dd>
<dt id="ki.write_fields"><code class="name flex">
<span>def <span class="ident">write_fields</span></span>(<span>root:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, n:Â anki.notes.Note) â€‘>Â collections.abc.Iterable[tuple[str,Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Write a note's fields to be tidied.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def write_fields(root: Dir, n: Note) -&gt; Iterable[Tuple[str, File]]:
    &#34;&#34;&#34;Write a note&#39;s fields to be tidied.&#34;&#34;&#34;
    return filter(None, starmap(write_field(root, n.id), n.items()))</code></pre>
</details>
</dd>
<dt id="ki.write_models"><code class="name flex">
<span>def <span class="ident">write_models</span></span>(<span>col:Â anki.collection.Collection, models:Â dict[int,Â dict[str,Â typing.Any]], deck:Â <a title="ki.types.Deck" href="types.html#ki.types.Deck">Deck</a>) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Write the <code>models.json</code> file for the given deck.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@curried
@beartype
def write_models(col: Collection, models: Dict[int, NotetypeDict], deck: Deck) -&gt; None:
    &#34;&#34;&#34;Write the `models.json` file for the given deck.&#34;&#34;&#34;
    did: int = deck.did
    deckd: Dir = deck.deckd
    descendants: List[CardId] = col.decks.cids(did=did, children=True)
    cards: List[Card] = list(map(col.get_card, descendants))
    descendant_mids: Set[int] = {c.note().mid for c in cards}

    # Write `models.json` for current deck.
    deck_models = {mid: models[mid] for mid in descendant_mids}
    with open(deckd / MODELS_FILE, &#34;w&#34;, encoding=UTF8) as f:
        json.dump(deck_models, f, ensure_ascii=False, indent=4, sort_keys=True)</code></pre>
</details>
</dd>
<dt id="ki.write_repository"><code class="name flex">
<span>def <span class="ident">write_repository</span></span>(<span>col_file:Â <a title="ki.types.File" href="types.html#ki.types.File">File</a>, targetdir:Â <a title="ki.types.Dir" href="types.html#ki.types.Dir">Dir</a>, dotki:Â <a title="ki.types.DotKi" href="types.html#ki.types.DotKi">DotKi</a>, media_target_dir:Â <a title="ki.types.EmptyDir" href="types.html#ki.types.EmptyDir">EmptyDir</a>) â€‘>Â set[<a title="ki.types.WindowsLink" href="types.html#ki.types.WindowsLink">WindowsLink</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Write notes to appropriate directories in <code>targetdir</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@beartype
def write_repository(
    col_file: File,
    targetdir: Dir,
    dotki: DotKi,
    media_target_dir: EmptyDir,
) -&gt; Set[WindowsLink]:
    &#34;&#34;&#34;Write notes to appropriate directories in `targetdir`.&#34;&#34;&#34;
    # Create config file.
    config = configparser.ConfigParser()
    config[&#34;remote&#34;] = {&#34;path&#34;: col_file}
    with open(dotki.config, &#34;w&#34;, encoding=UTF8) as config_f:
        config.write(config_f)

    # Create temp directory for htmlfield text files.
    tempdir: EmptyDir = F.mkdtemp()
    root: EmptyDir = F.mksubdir(tempdir, FIELD_HTML_SUFFIX)

    # ColNote-containing data structure, to be passed to `write_decks()`.
    col: Collection = M.collection(col_file)
    nids: Iterable[int] = TQ(col.find_notes(query=&#34;&#34;), &#34;Notes&#34;)
    colnotes: Dict[int, ColNote] = {nid: M.colnote(col, nid) for nid in nids}
    media: Dict[int, Set[File]] = copy_media_files(col, media_target_dir)
    ns: Iterable[Note] = map(lambda c: c.n, colnotes.values())
    fieldfiles = dict(F.cat(map(write_fields(root), TQ(ns, &#34;Fields&#34;))))
    tidy_html_recursively(root)

    windows_links: Set[WindowsLink] = write_decks(
        col=col,
        targetdir=targetdir,
        colnotes=colnotes,
        media=media,
        tidy_field_files=fieldfiles,
    )

    F.rmtree(root)
    col.close(save=False)

    return windows_links</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="ki Home" href="index.html">
<img src="u1F367-shavedice.svg" alt=""> ki
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#getting-started">Getting started</a><ul>
<li><a href="#finding-the-anki2-collection-file">Finding the .anki2 collection file</a><ul>
<li><a href="#macos">MacOS</a></li>
<li><a href="#windows">Windows</a></li>
<li><a href="#gnulinux">GNU/Linux</a></li>
<li><a href="#multiple-profiles">Multiple profiles</a></li>
</ul>
</li>
<li><a href="#running-the-clone-command">Running the clone command</a></li>
<li><a href="#editing-notes">Editing notes</a></li>
<li><a href="#pushing-committed-changes-back-to-anki">Pushing committed changes back to Anki</a></li>
<li><a href="#pulling-changes-from-anki-into-the-repository">Pulling changes from Anki into the repository</a><ul>
<li><a href="#merge-conflicts">Merge conflicts</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#usage-reference">Usage reference</a><ul>
<li><a href="#clone">Clone</a></li>
<li><a href="#pull">Pull</a></li>
<li><a href="#push">Push</a></li>
</ul>
</li>
<li><a href="#collaborative-decks">Collaborative decks</a><ul>
<li><a href="#cloning-a-collaborative-deck-from-github">Cloning a collaborative deck from GitHub</a><ul>
<li><a href="#adding-the-repository-as-a-git-submodule">Adding the repository as a git submodule</a></li>
</ul>
</li>
<li><a href="#editing-a-collaborative-deck">Editing a collaborative deck</a></li>
</ul>
</li>
<li><a href="#how-it-works">How it works</a></li>
<li><a href="#model">Model</a></li>
<li><a href="#generating-html">Generating html</a><ul>
<li><a href="#example-generating-syntax-highlighted-code-blocks">Example: generating syntax-highlighted code blocks</a><ul>
<li><a href="#adding-ki-html-attributes">Adding ki HTML attributes</a></li>
<li><a href="#source-code">Source code</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="ki.functional" href="functional.html">ki.functional</a></code></li>
<li><code><a title="ki.maybes" href="maybes.html">ki.maybes</a></code></li>
<li><code><a title="ki.transformer" href="transformer.html">ki.transformer</a></code></li>
<li><code><a title="ki.types" href="types.html">ki.types</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ki.add_db_note" href="#ki.add_db_note">add_db_note</a></code></li>
<li><code><a title="ki.add_model" href="#ki.add_model">add_model</a></code></li>
<li><code><a title="ki.addmedia" href="#ki.addmedia">addmedia</a></code></li>
<li><code><a title="ki.append_md5sum" href="#ki.append_md5sum">append_md5sum</a></code></li>
<li><code><a title="ki.apply" href="#ki.apply">apply</a></code></li>
<li><code><a title="ki.apply_in_subrepo" href="#ki.apply_in_subrepo">apply_in_subrepo</a></code></li>
<li><code><a title="ki.backup" href="#ki.backup">backup</a></code></li>
<li><code><a title="ki.backupd" href="#ki.backupd">backupd</a></code></li>
<li><code><a title="ki.check_fields_health" href="#ki.check_fields_health">check_fields_health</a></code></li>
<li><code><a title="ki.commit_hashes_file" href="#ki.commit_hashes_file">commit_hashes_file</a></code></li>
<li><code><a title="ki.copy_media_files" href="#ki.copy_media_files">copy_media_files</a></code></li>
<li><code><a title="ki.copy_note_media" href="#ki.copy_note_media">copy_note_media</a></code></li>
<li><code><a title="ki.copy_notetype_media" href="#ki.copy_notetype_media">copy_notetype_media</a></code></li>
<li><code><a title="ki.cp_ki" href="#ki.cp_ki">cp_ki</a></code></li>
<li><code><a title="ki.cp_repo" href="#ki.cp_repo">cp_repo</a></code></li>
<li><code><a title="ki.diff2" href="#ki.diff2">diff2</a></code></li>
<li><code><a title="ki.do" href="#ki.do">do</a></code></li>
<li><code><a title="ki.echo" href="#ki.echo">echo</a></code></li>
<li><code><a title="ki.echo_note_change_types" href="#ki.echo_note_change_types">echo_note_change_types</a></code></li>
<li><code><a title="ki.get_field_note_id" href="#ki.get_field_note_id">get_field_note_id</a></code></li>
<li><code><a title="ki.get_guid" href="#ki.get_guid">get_guid</a></code></li>
<li><code><a title="ki.get_header_lines" href="#ki.get_header_lines">get_header_lines</a></code></li>
<li><code><a title="ki.get_link" href="#ki.get_link">get_link</a></code></li>
<li><code><a title="ki.get_models_recursively" href="#ki.get_models_recursively">get_models_recursively</a></code></li>
<li><code><a title="ki.get_note_metadata" href="#ki.get_note_metadata">get_note_metadata</a></code></li>
<li><code><a title="ki.get_note_path" href="#ki.get_note_path">get_note_path</a></code></li>
<li><code><a title="ki.get_note_payload" href="#ki.get_note_payload">get_note_payload</a></code></li>
<li><code><a title="ki.get_patches" href="#ki.get_patches">get_patches</a></code></li>
<li><code><a title="ki.get_target" href="#ki.get_target">get_target</a></code></li>
<li><code><a title="ki.git_pull" href="#ki.git_pull">git_pull</a></code></li>
<li><code><a title="ki.has_patch" href="#ki.has_patch">has_patch</a></code></li>
<li><code><a title="ki.hasmedia" href="#ki.hasmedia">hasmedia</a></code></li>
<li><code><a title="ki.html_to_screen" href="#ki.html_to_screen">html_to_screen</a></code></li>
<li><code><a title="ki.is_anki_note" href="#ki.is_anki_note">is_anki_note</a></code></li>
<li><code><a title="ki.is_ignorable" href="#ki.is_ignorable">is_ignorable</a></code></li>
<li><code><a title="ki.localmedia" href="#ki.localmedia">localmedia</a></code></li>
<li><code><a title="ki.lock" href="#ki.lock">lock</a></code></li>
<li><code><a title="ki.media_filenames_in_field" href="#ki.media_filenames_in_field">media_filenames_in_field</a></code></li>
<li><code><a title="ki.mediabytes" href="#ki.mediabytes">mediabytes</a></code></li>
<li><code><a title="ki.mediadata" href="#ki.mediadata">mediadata</a></code></li>
<li><code><a title="ki.merge_new_sm" href="#ki.merge_new_sm">merge_new_sm</a></code></li>
<li><code><a title="ki.mungediff" href="#ki.mungediff">mungediff</a></code></li>
<li><code><a title="ki.parentmap" href="#ki.parentmap">parentmap</a></code></li>
<li><code><a title="ki.parse_note" href="#ki.parse_note">parse_note</a></code></li>
<li><code><a title="ki.plain_to_html" href="#ki.plain_to_html">plain_to_html</a></code></li>
<li><code><a title="ki.planned_link" href="#ki.planned_link">planned_link</a></code></li>
<li><code><a title="ki.postorder" href="#ki.postorder">postorder</a></code></li>
<li><code><a title="ki.preorder" href="#ki.preorder">preorder</a></code></li>
<li><code><a title="ki.pull_sm" href="#ki.pull_sm">pull_sm</a></code></li>
<li><code><a title="ki.push_note" href="#ki.push_note">push_note</a></code></li>
<li><code><a title="ki.rm_remote_sm" href="#ki.rm_remote_sm">rm_remote_sm</a></code></li>
<li><code><a title="ki.set_120000" href="#ki.set_120000">set_120000</a></code></li>
<li><code><a title="ki.stardo" href="#ki.stardo">stardo</a></code></li>
<li><code><a title="ki.symlink_deck_media" href="#ki.symlink_deck_media">symlink_deck_media</a></code></li>
<li><code><a title="ki.symlink_media" href="#ki.symlink_media">symlink_media</a></code></li>
<li><code><a title="ki.tidy_html_recursively" href="#ki.tidy_html_recursively">tidy_html_recursively</a></code></li>
<li><code><a title="ki.unlock" href="#ki.unlock">unlock</a></code></li>
<li><code><a title="ki.unquote_diff_path" href="#ki.unquote_diff_path">unquote_diff_path</a></code></li>
<li><code><a title="ki.update_field" href="#ki.update_field">update_field</a></code></li>
<li><code><a title="ki.update_note" href="#ki.update_note">update_note</a></code></li>
<li><code><a title="ki.validate_decknote_fields" href="#ki.validate_decknote_fields">validate_decknote_fields</a></code></li>
<li><code><a title="ki.warn" href="#ki.warn">warn</a></code></li>
<li><code><a title="ki.write_card" href="#ki.write_card">write_card</a></code></li>
<li><code><a title="ki.write_collection" href="#ki.write_collection">write_collection</a></code></li>
<li><code><a title="ki.write_deck" href="#ki.write_deck">write_deck</a></code></li>
<li><code><a title="ki.write_decks" href="#ki.write_decks">write_decks</a></code></li>
<li><code><a title="ki.write_field" href="#ki.write_field">write_field</a></code></li>
<li><code><a title="ki.write_fields" href="#ki.write_fields">write_fields</a></code></li>
<li><code><a title="ki.write_models" href="#ki.write_models">write_models</a></code></li>
<li><code><a title="ki.write_repository" href="#ki.write_repository">write_repository</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>